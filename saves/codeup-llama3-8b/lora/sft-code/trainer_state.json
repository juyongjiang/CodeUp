{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 4695,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006389776357827476,
      "grad_norm": 1.0089647769927979,
      "learning_rate": 2.1276595744680853e-06,
      "loss": 1.3208,
      "step": 10
    },
    {
      "epoch": 0.012779552715654952,
      "grad_norm": 0.8766931891441345,
      "learning_rate": 4.255319148936171e-06,
      "loss": 1.2846,
      "step": 20
    },
    {
      "epoch": 0.019169329073482427,
      "grad_norm": 0.8780839443206787,
      "learning_rate": 6.3829787234042555e-06,
      "loss": 1.2392,
      "step": 30
    },
    {
      "epoch": 0.025559105431309903,
      "grad_norm": 0.5254836678504944,
      "learning_rate": 8.510638297872341e-06,
      "loss": 1.1667,
      "step": 40
    },
    {
      "epoch": 0.03194888178913738,
      "grad_norm": 0.25511831045150757,
      "learning_rate": 1.0638297872340426e-05,
      "loss": 1.0885,
      "step": 50
    },
    {
      "epoch": 0.038338658146964855,
      "grad_norm": 0.30241745710372925,
      "learning_rate": 1.2765957446808511e-05,
      "loss": 1.067,
      "step": 60
    },
    {
      "epoch": 0.04472843450479233,
      "grad_norm": 0.24550634622573853,
      "learning_rate": 1.4893617021276596e-05,
      "loss": 1.0753,
      "step": 70
    },
    {
      "epoch": 0.051118210862619806,
      "grad_norm": 0.25158849358558655,
      "learning_rate": 1.7021276595744682e-05,
      "loss": 1.0123,
      "step": 80
    },
    {
      "epoch": 0.05750798722044728,
      "grad_norm": 0.2137189507484436,
      "learning_rate": 1.9148936170212766e-05,
      "loss": 1.0495,
      "step": 90
    },
    {
      "epoch": 0.06389776357827476,
      "grad_norm": 0.2231076955795288,
      "learning_rate": 2.1276595744680852e-05,
      "loss": 1.0409,
      "step": 100
    },
    {
      "epoch": 0.07028753993610223,
      "grad_norm": 0.23270778357982635,
      "learning_rate": 2.340425531914894e-05,
      "loss": 1.0718,
      "step": 110
    },
    {
      "epoch": 0.07667731629392971,
      "grad_norm": 0.21690690517425537,
      "learning_rate": 2.5531914893617022e-05,
      "loss": 0.9951,
      "step": 120
    },
    {
      "epoch": 0.08306709265175719,
      "grad_norm": 0.2545509934425354,
      "learning_rate": 2.765957446808511e-05,
      "loss": 1.0504,
      "step": 130
    },
    {
      "epoch": 0.08945686900958466,
      "grad_norm": 0.25604701042175293,
      "learning_rate": 2.9787234042553192e-05,
      "loss": 1.0152,
      "step": 140
    },
    {
      "epoch": 0.09584664536741214,
      "grad_norm": 0.24021248519420624,
      "learning_rate": 3.191489361702128e-05,
      "loss": 1.0472,
      "step": 150
    },
    {
      "epoch": 0.10223642172523961,
      "grad_norm": 0.2598375678062439,
      "learning_rate": 3.4042553191489365e-05,
      "loss": 1.0639,
      "step": 160
    },
    {
      "epoch": 0.10862619808306709,
      "grad_norm": 0.24710935354232788,
      "learning_rate": 3.617021276595745e-05,
      "loss": 1.0182,
      "step": 170
    },
    {
      "epoch": 0.11501597444089456,
      "grad_norm": 0.27845364809036255,
      "learning_rate": 3.829787234042553e-05,
      "loss": 1.0402,
      "step": 180
    },
    {
      "epoch": 0.12140575079872204,
      "grad_norm": 0.26594433188438416,
      "learning_rate": 4.0425531914893614e-05,
      "loss": 1.0254,
      "step": 190
    },
    {
      "epoch": 0.12779552715654952,
      "grad_norm": 0.25430387258529663,
      "learning_rate": 4.2553191489361704e-05,
      "loss": 1.0031,
      "step": 200
    },
    {
      "epoch": 0.134185303514377,
      "grad_norm": 0.26257824897766113,
      "learning_rate": 4.468085106382979e-05,
      "loss": 0.9862,
      "step": 210
    },
    {
      "epoch": 0.14057507987220447,
      "grad_norm": 0.2620280086994171,
      "learning_rate": 4.680851063829788e-05,
      "loss": 0.9912,
      "step": 220
    },
    {
      "epoch": 0.14696485623003194,
      "grad_norm": 0.25074830651283264,
      "learning_rate": 4.893617021276596e-05,
      "loss": 1.0309,
      "step": 230
    },
    {
      "epoch": 0.15335463258785942,
      "grad_norm": 0.29056304693222046,
      "learning_rate": 5.1063829787234044e-05,
      "loss": 1.035,
      "step": 240
    },
    {
      "epoch": 0.1597444089456869,
      "grad_norm": 0.2911895215511322,
      "learning_rate": 5.319148936170213e-05,
      "loss": 0.9891,
      "step": 250
    },
    {
      "epoch": 0.16613418530351437,
      "grad_norm": 0.2638428509235382,
      "learning_rate": 5.531914893617022e-05,
      "loss": 1.0317,
      "step": 260
    },
    {
      "epoch": 0.17252396166134185,
      "grad_norm": 0.2712332308292389,
      "learning_rate": 5.744680851063831e-05,
      "loss": 1.0356,
      "step": 270
    },
    {
      "epoch": 0.17891373801916932,
      "grad_norm": 0.27856749296188354,
      "learning_rate": 5.9574468085106384e-05,
      "loss": 1.0521,
      "step": 280
    },
    {
      "epoch": 0.1853035143769968,
      "grad_norm": 0.27594098448753357,
      "learning_rate": 6.170212765957447e-05,
      "loss": 1.0377,
      "step": 290
    },
    {
      "epoch": 0.19169329073482427,
      "grad_norm": 0.269014835357666,
      "learning_rate": 6.382978723404256e-05,
      "loss": 1.0259,
      "step": 300
    },
    {
      "epoch": 0.19808306709265175,
      "grad_norm": 0.25438639521598816,
      "learning_rate": 6.595744680851063e-05,
      "loss": 1.0292,
      "step": 310
    },
    {
      "epoch": 0.20447284345047922,
      "grad_norm": 0.23945452272891998,
      "learning_rate": 6.808510638297873e-05,
      "loss": 1.0036,
      "step": 320
    },
    {
      "epoch": 0.2108626198083067,
      "grad_norm": 0.2485591471195221,
      "learning_rate": 7.021276595744681e-05,
      "loss": 0.9764,
      "step": 330
    },
    {
      "epoch": 0.21725239616613418,
      "grad_norm": 0.25592538714408875,
      "learning_rate": 7.23404255319149e-05,
      "loss": 1.0178,
      "step": 340
    },
    {
      "epoch": 0.22364217252396165,
      "grad_norm": 0.24337507784366608,
      "learning_rate": 7.446808510638298e-05,
      "loss": 1.0134,
      "step": 350
    },
    {
      "epoch": 0.23003194888178913,
      "grad_norm": 0.2535225749015808,
      "learning_rate": 7.659574468085106e-05,
      "loss": 1.0125,
      "step": 360
    },
    {
      "epoch": 0.2364217252396166,
      "grad_norm": 0.26334330439567566,
      "learning_rate": 7.872340425531916e-05,
      "loss": 1.0301,
      "step": 370
    },
    {
      "epoch": 0.24281150159744408,
      "grad_norm": 0.24370183050632477,
      "learning_rate": 8.085106382978723e-05,
      "loss": 1.0029,
      "step": 380
    },
    {
      "epoch": 0.24920127795527156,
      "grad_norm": 0.24374891817569733,
      "learning_rate": 8.297872340425533e-05,
      "loss": 1.0006,
      "step": 390
    },
    {
      "epoch": 0.25559105431309903,
      "grad_norm": 0.22176343202590942,
      "learning_rate": 8.510638297872341e-05,
      "loss": 0.993,
      "step": 400
    },
    {
      "epoch": 0.26198083067092653,
      "grad_norm": 0.234650120139122,
      "learning_rate": 8.723404255319149e-05,
      "loss": 0.9882,
      "step": 410
    },
    {
      "epoch": 0.268370607028754,
      "grad_norm": 0.22922037541866302,
      "learning_rate": 8.936170212765958e-05,
      "loss": 1.0018,
      "step": 420
    },
    {
      "epoch": 0.2747603833865815,
      "grad_norm": 0.22452130913734436,
      "learning_rate": 9.148936170212766e-05,
      "loss": 0.9965,
      "step": 430
    },
    {
      "epoch": 0.28115015974440893,
      "grad_norm": 0.23251871764659882,
      "learning_rate": 9.361702127659576e-05,
      "loss": 1.0253,
      "step": 440
    },
    {
      "epoch": 0.28753993610223644,
      "grad_norm": 0.221387580037117,
      "learning_rate": 9.574468085106384e-05,
      "loss": 0.9826,
      "step": 450
    },
    {
      "epoch": 0.2939297124600639,
      "grad_norm": 0.2344844937324524,
      "learning_rate": 9.787234042553192e-05,
      "loss": 0.9847,
      "step": 460
    },
    {
      "epoch": 0.3003194888178914,
      "grad_norm": 0.22179102897644043,
      "learning_rate": 0.0001,
      "loss": 0.9799,
      "step": 470
    },
    {
      "epoch": 0.30670926517571884,
      "grad_norm": 0.2238358110189438,
      "learning_rate": 9.999861775723161e-05,
      "loss": 0.9907,
      "step": 480
    },
    {
      "epoch": 0.31309904153354634,
      "grad_norm": 0.23600204288959503,
      "learning_rate": 9.999447110535025e-05,
      "loss": 0.9914,
      "step": 490
    },
    {
      "epoch": 0.3194888178913738,
      "grad_norm": 0.2242172658443451,
      "learning_rate": 9.998756027362309e-05,
      "loss": 1.0211,
      "step": 500
    },
    {
      "epoch": 0.3194888178913738,
      "eval_loss": 0.9953587055206299,
      "eval_runtime": 291.2053,
      "eval_samples_per_second": 38.214,
      "eval_steps_per_second": 1.195,
      "step": 500
    },
    {
      "epoch": 0.3258785942492013,
      "grad_norm": 0.2326868176460266,
      "learning_rate": 9.9977885644148e-05,
      "loss": 0.9833,
      "step": 510
    },
    {
      "epoch": 0.33226837060702874,
      "grad_norm": 0.2368769496679306,
      "learning_rate": 9.99654477518325e-05,
      "loss": 0.9702,
      "step": 520
    },
    {
      "epoch": 0.33865814696485624,
      "grad_norm": 0.21315650641918182,
      "learning_rate": 9.995024728436402e-05,
      "loss": 0.9741,
      "step": 530
    },
    {
      "epoch": 0.3450479233226837,
      "grad_norm": 0.22160793840885162,
      "learning_rate": 9.993228508217201e-05,
      "loss": 0.9908,
      "step": 540
    },
    {
      "epoch": 0.3514376996805112,
      "grad_norm": 0.22031435370445251,
      "learning_rate": 9.991156213838142e-05,
      "loss": 0.9958,
      "step": 550
    },
    {
      "epoch": 0.35782747603833864,
      "grad_norm": 0.22062531113624573,
      "learning_rate": 9.988807959875786e-05,
      "loss": 0.9792,
      "step": 560
    },
    {
      "epoch": 0.36421725239616615,
      "grad_norm": 0.23002223670482635,
      "learning_rate": 9.986183876164412e-05,
      "loss": 0.994,
      "step": 570
    },
    {
      "epoch": 0.3706070287539936,
      "grad_norm": 0.22057312726974487,
      "learning_rate": 9.98328410778885e-05,
      "loss": 1.0219,
      "step": 580
    },
    {
      "epoch": 0.3769968051118211,
      "grad_norm": 0.22655436396598816,
      "learning_rate": 9.980108815076455e-05,
      "loss": 0.978,
      "step": 590
    },
    {
      "epoch": 0.38338658146964855,
      "grad_norm": 0.20907588303089142,
      "learning_rate": 9.976658173588244e-05,
      "loss": 1.0042,
      "step": 600
    },
    {
      "epoch": 0.38977635782747605,
      "grad_norm": 0.20880548655986786,
      "learning_rate": 9.972932374109184e-05,
      "loss": 0.9875,
      "step": 610
    },
    {
      "epoch": 0.3961661341853035,
      "grad_norm": 0.22198593616485596,
      "learning_rate": 9.968931622637652e-05,
      "loss": 0.9636,
      "step": 620
    },
    {
      "epoch": 0.402555910543131,
      "grad_norm": 0.23320874571800232,
      "learning_rate": 9.964656140374039e-05,
      "loss": 0.9912,
      "step": 630
    },
    {
      "epoch": 0.40894568690095845,
      "grad_norm": 0.22916780412197113,
      "learning_rate": 9.960106163708523e-05,
      "loss": 0.9622,
      "step": 640
    },
    {
      "epoch": 0.41533546325878595,
      "grad_norm": 0.21224090456962585,
      "learning_rate": 9.955281944207999e-05,
      "loss": 0.9733,
      "step": 650
    },
    {
      "epoch": 0.4217252396166134,
      "grad_norm": 0.2189665138721466,
      "learning_rate": 9.950183748602165e-05,
      "loss": 1.0095,
      "step": 660
    },
    {
      "epoch": 0.4281150159744409,
      "grad_norm": 0.20181377232074738,
      "learning_rate": 9.944811858768782e-05,
      "loss": 0.9931,
      "step": 670
    },
    {
      "epoch": 0.43450479233226835,
      "grad_norm": 0.23328359425067902,
      "learning_rate": 9.939166571718086e-05,
      "loss": 1.0183,
      "step": 680
    },
    {
      "epoch": 0.44089456869009586,
      "grad_norm": 0.22203552722930908,
      "learning_rate": 9.933248199576366e-05,
      "loss": 0.977,
      "step": 690
    },
    {
      "epoch": 0.4472843450479233,
      "grad_norm": 0.23012018203735352,
      "learning_rate": 9.927057069568704e-05,
      "loss": 0.9687,
      "step": 700
    },
    {
      "epoch": 0.4536741214057508,
      "grad_norm": 0.20914460718631744,
      "learning_rate": 9.920593524000886e-05,
      "loss": 0.9988,
      "step": 710
    },
    {
      "epoch": 0.46006389776357826,
      "grad_norm": 0.21012860536575317,
      "learning_rate": 9.91385792024048e-05,
      "loss": 0.9678,
      "step": 720
    },
    {
      "epoch": 0.46645367412140576,
      "grad_norm": 0.2227972149848938,
      "learning_rate": 9.906850630697068e-05,
      "loss": 0.9924,
      "step": 730
    },
    {
      "epoch": 0.4728434504792332,
      "grad_norm": 0.22776533663272858,
      "learning_rate": 9.899572042801661e-05,
      "loss": 0.9666,
      "step": 740
    },
    {
      "epoch": 0.4792332268370607,
      "grad_norm": 0.21285416185855865,
      "learning_rate": 9.89202255898528e-05,
      "loss": 0.9769,
      "step": 750
    },
    {
      "epoch": 0.48562300319488816,
      "grad_norm": 0.2253626585006714,
      "learning_rate": 9.8842025966567e-05,
      "loss": 0.9858,
      "step": 760
    },
    {
      "epoch": 0.49201277955271566,
      "grad_norm": 0.24020132422447205,
      "learning_rate": 9.876112588179378e-05,
      "loss": 1.0087,
      "step": 770
    },
    {
      "epoch": 0.4984025559105431,
      "grad_norm": 0.20706839859485626,
      "learning_rate": 9.86775298084754e-05,
      "loss": 1.0371,
      "step": 780
    },
    {
      "epoch": 0.5047923322683706,
      "grad_norm": 0.22177907824516296,
      "learning_rate": 9.859124236861459e-05,
      "loss": 0.9655,
      "step": 790
    },
    {
      "epoch": 0.5111821086261981,
      "grad_norm": 0.23075979948043823,
      "learning_rate": 9.850226833301893e-05,
      "loss": 0.9846,
      "step": 800
    },
    {
      "epoch": 0.5175718849840255,
      "grad_norm": 0.21622611582279205,
      "learning_rate": 9.841061262103713e-05,
      "loss": 1.0115,
      "step": 810
    },
    {
      "epoch": 0.5239616613418531,
      "grad_norm": 0.23045289516448975,
      "learning_rate": 9.831628030028697e-05,
      "loss": 0.9609,
      "step": 820
    },
    {
      "epoch": 0.5303514376996805,
      "grad_norm": 0.22133317589759827,
      "learning_rate": 9.821927658637517e-05,
      "loss": 0.9437,
      "step": 830
    },
    {
      "epoch": 0.536741214057508,
      "grad_norm": 0.2133764922618866,
      "learning_rate": 9.811960684260905e-05,
      "loss": 0.9542,
      "step": 840
    },
    {
      "epoch": 0.5431309904153354,
      "grad_norm": 0.22244276106357574,
      "learning_rate": 9.801727657969988e-05,
      "loss": 0.98,
      "step": 850
    },
    {
      "epoch": 0.549520766773163,
      "grad_norm": 0.23872512578964233,
      "learning_rate": 9.791229145545831e-05,
      "loss": 0.9645,
      "step": 860
    },
    {
      "epoch": 0.5559105431309904,
      "grad_norm": 0.22064383327960968,
      "learning_rate": 9.780465727448149e-05,
      "loss": 0.9822,
      "step": 870
    },
    {
      "epoch": 0.5623003194888179,
      "grad_norm": 0.228435218334198,
      "learning_rate": 9.769437998783215e-05,
      "loss": 0.9789,
      "step": 880
    },
    {
      "epoch": 0.5686900958466453,
      "grad_norm": 0.21754494309425354,
      "learning_rate": 9.758146569270956e-05,
      "loss": 0.9985,
      "step": 890
    },
    {
      "epoch": 0.5750798722044729,
      "grad_norm": 0.23071835935115814,
      "learning_rate": 9.746592063211246e-05,
      "loss": 1.0141,
      "step": 900
    },
    {
      "epoch": 0.5814696485623003,
      "grad_norm": 0.22099103033542633,
      "learning_rate": 9.734775119449379e-05,
      "loss": 0.9877,
      "step": 910
    },
    {
      "epoch": 0.5878594249201278,
      "grad_norm": 0.20787549018859863,
      "learning_rate": 9.722696391340761e-05,
      "loss": 0.9296,
      "step": 920
    },
    {
      "epoch": 0.5942492012779552,
      "grad_norm": 0.21619689464569092,
      "learning_rate": 9.710356546714772e-05,
      "loss": 1.0192,
      "step": 930
    },
    {
      "epoch": 0.6006389776357828,
      "grad_norm": 0.21689492464065552,
      "learning_rate": 9.697756267837856e-05,
      "loss": 1.0155,
      "step": 940
    },
    {
      "epoch": 0.6070287539936102,
      "grad_norm": 0.2244279831647873,
      "learning_rate": 9.684896251375783e-05,
      "loss": 0.9833,
      "step": 950
    },
    {
      "epoch": 0.6134185303514377,
      "grad_norm": 0.22242146730422974,
      "learning_rate": 9.671777208355146e-05,
      "loss": 0.9658,
      "step": 960
    },
    {
      "epoch": 0.6198083067092651,
      "grad_norm": 0.2295496165752411,
      "learning_rate": 9.658399864124037e-05,
      "loss": 1.0098,
      "step": 970
    },
    {
      "epoch": 0.6261980830670927,
      "grad_norm": 0.2262108027935028,
      "learning_rate": 9.644764958311949e-05,
      "loss": 0.9389,
      "step": 980
    },
    {
      "epoch": 0.6325878594249201,
      "grad_norm": 0.23545391857624054,
      "learning_rate": 9.630873244788883e-05,
      "loss": 0.9907,
      "step": 990
    },
    {
      "epoch": 0.6389776357827476,
      "grad_norm": 0.2384229302406311,
      "learning_rate": 9.616725491623659e-05,
      "loss": 0.9573,
      "step": 1000
    },
    {
      "epoch": 0.6389776357827476,
      "eval_loss": 0.9790657162666321,
      "eval_runtime": 291.242,
      "eval_samples_per_second": 38.209,
      "eval_steps_per_second": 1.195,
      "step": 1000
    },
    {
      "epoch": 0.645367412140575,
      "grad_norm": 0.20496074855327606,
      "learning_rate": 9.602322481041457e-05,
      "loss": 1.0016,
      "step": 1010
    },
    {
      "epoch": 0.6517571884984026,
      "grad_norm": 0.20942449569702148,
      "learning_rate": 9.587665009380565e-05,
      "loss": 0.9467,
      "step": 1020
    },
    {
      "epoch": 0.65814696485623,
      "grad_norm": 0.22398439049720764,
      "learning_rate": 9.572753887048354e-05,
      "loss": 0.9927,
      "step": 1030
    },
    {
      "epoch": 0.6645367412140575,
      "grad_norm": 0.21317331492900848,
      "learning_rate": 9.557589938476463e-05,
      "loss": 0.9573,
      "step": 1040
    },
    {
      "epoch": 0.670926517571885,
      "grad_norm": 0.22433972358703613,
      "learning_rate": 9.54217400207522e-05,
      "loss": 0.9986,
      "step": 1050
    },
    {
      "epoch": 0.6773162939297125,
      "grad_norm": 0.23387950658798218,
      "learning_rate": 9.526506930187293e-05,
      "loss": 0.9845,
      "step": 1060
    },
    {
      "epoch": 0.6837060702875399,
      "grad_norm": 0.21232536435127258,
      "learning_rate": 9.510589589040553e-05,
      "loss": 0.9863,
      "step": 1070
    },
    {
      "epoch": 0.6900958466453674,
      "grad_norm": 0.23316240310668945,
      "learning_rate": 9.494422858700188e-05,
      "loss": 1.005,
      "step": 1080
    },
    {
      "epoch": 0.6964856230031949,
      "grad_norm": 0.20200088620185852,
      "learning_rate": 9.478007633020043e-05,
      "loss": 0.9759,
      "step": 1090
    },
    {
      "epoch": 0.7028753993610224,
      "grad_norm": 0.21656711399555206,
      "learning_rate": 9.461344819593194e-05,
      "loss": 0.9609,
      "step": 1100
    },
    {
      "epoch": 0.7092651757188498,
      "grad_norm": 0.2114223837852478,
      "learning_rate": 9.44443533970178e-05,
      "loss": 0.9673,
      "step": 1110
    },
    {
      "epoch": 0.7156549520766773,
      "grad_norm": 0.20542877912521362,
      "learning_rate": 9.42728012826605e-05,
      "loss": 1.0022,
      "step": 1120
    },
    {
      "epoch": 0.7220447284345048,
      "grad_norm": 0.23607540130615234,
      "learning_rate": 9.409880133792683e-05,
      "loss": 0.9821,
      "step": 1130
    },
    {
      "epoch": 0.7284345047923323,
      "grad_norm": 0.22401763498783112,
      "learning_rate": 9.392236318322338e-05,
      "loss": 0.9688,
      "step": 1140
    },
    {
      "epoch": 0.7348242811501597,
      "grad_norm": 0.22029481828212738,
      "learning_rate": 9.374349657376473e-05,
      "loss": 0.9933,
      "step": 1150
    },
    {
      "epoch": 0.7412140575079872,
      "grad_norm": 0.22033020853996277,
      "learning_rate": 9.356221139903394e-05,
      "loss": 0.9991,
      "step": 1160
    },
    {
      "epoch": 0.7476038338658147,
      "grad_norm": 0.21206682920455933,
      "learning_rate": 9.337851768223589e-05,
      "loss": 0.9798,
      "step": 1170
    },
    {
      "epoch": 0.7539936102236422,
      "grad_norm": 0.2273460477590561,
      "learning_rate": 9.319242557974306e-05,
      "loss": 0.9745,
      "step": 1180
    },
    {
      "epoch": 0.7603833865814696,
      "grad_norm": 0.23135420680046082,
      "learning_rate": 9.300394538053395e-05,
      "loss": 0.9882,
      "step": 1190
    },
    {
      "epoch": 0.7667731629392971,
      "grad_norm": 0.2340337336063385,
      "learning_rate": 9.281308750562427e-05,
      "loss": 0.9607,
      "step": 1200
    },
    {
      "epoch": 0.7731629392971247,
      "grad_norm": 0.22383509576320648,
      "learning_rate": 9.261986250749068e-05,
      "loss": 0.9816,
      "step": 1210
    },
    {
      "epoch": 0.7795527156549521,
      "grad_norm": 0.22180594503879547,
      "learning_rate": 9.242428106948749e-05,
      "loss": 0.9426,
      "step": 1220
    },
    {
      "epoch": 0.7859424920127795,
      "grad_norm": 0.2412000149488449,
      "learning_rate": 9.22263540052558e-05,
      "loss": 0.9616,
      "step": 1230
    },
    {
      "epoch": 0.792332268370607,
      "grad_norm": 0.22837646305561066,
      "learning_rate": 9.202609225812572e-05,
      "loss": 0.9693,
      "step": 1240
    },
    {
      "epoch": 0.7987220447284346,
      "grad_norm": 0.2181404083967209,
      "learning_rate": 9.182350690051133e-05,
      "loss": 0.9684,
      "step": 1250
    },
    {
      "epoch": 0.805111821086262,
      "grad_norm": 0.22071321308612823,
      "learning_rate": 9.161860913329849e-05,
      "loss": 0.9726,
      "step": 1260
    },
    {
      "epoch": 0.8115015974440895,
      "grad_norm": 0.22795097529888153,
      "learning_rate": 9.141141028522544e-05,
      "loss": 0.9442,
      "step": 1270
    },
    {
      "epoch": 0.8178913738019169,
      "grad_norm": 0.21401040256023407,
      "learning_rate": 9.120192181225657e-05,
      "loss": 0.9906,
      "step": 1280
    },
    {
      "epoch": 0.8242811501597445,
      "grad_norm": 0.2207076996564865,
      "learning_rate": 9.099015529694895e-05,
      "loss": 0.9776,
      "step": 1290
    },
    {
      "epoch": 0.8306709265175719,
      "grad_norm": 0.2084292471408844,
      "learning_rate": 9.077612244781195e-05,
      "loss": 1.0162,
      "step": 1300
    },
    {
      "epoch": 0.8370607028753994,
      "grad_norm": 0.22583547234535217,
      "learning_rate": 9.055983509865989e-05,
      "loss": 0.9599,
      "step": 1310
    },
    {
      "epoch": 0.8434504792332268,
      "grad_norm": 0.21718654036521912,
      "learning_rate": 9.034130520795774e-05,
      "loss": 0.962,
      "step": 1320
    },
    {
      "epoch": 0.8498402555910544,
      "grad_norm": 0.2039955109357834,
      "learning_rate": 9.012054485815994e-05,
      "loss": 0.9887,
      "step": 1330
    },
    {
      "epoch": 0.8562300319488818,
      "grad_norm": 0.2258319854736328,
      "learning_rate": 8.989756625504238e-05,
      "loss": 0.9836,
      "step": 1340
    },
    {
      "epoch": 0.8626198083067093,
      "grad_norm": 0.21973368525505066,
      "learning_rate": 8.967238172702753e-05,
      "loss": 0.9925,
      "step": 1350
    },
    {
      "epoch": 0.8690095846645367,
      "grad_norm": 0.20920142531394958,
      "learning_rate": 8.94450037245028e-05,
      "loss": 0.9606,
      "step": 1360
    },
    {
      "epoch": 0.8753993610223643,
      "grad_norm": 0.21739688515663147,
      "learning_rate": 8.921544481913218e-05,
      "loss": 0.9562,
      "step": 1370
    },
    {
      "epoch": 0.8817891373801917,
      "grad_norm": 0.20338702201843262,
      "learning_rate": 8.898371770316111e-05,
      "loss": 1.0007,
      "step": 1380
    },
    {
      "epoch": 0.8881789137380192,
      "grad_norm": 0.2171730399131775,
      "learning_rate": 8.874983518871487e-05,
      "loss": 0.9453,
      "step": 1390
    },
    {
      "epoch": 0.8945686900958466,
      "grad_norm": 0.21892863512039185,
      "learning_rate": 8.851381020708999e-05,
      "loss": 0.9782,
      "step": 1400
    },
    {
      "epoch": 0.9009584664536742,
      "grad_norm": 0.22521018981933594,
      "learning_rate": 8.827565580803943e-05,
      "loss": 0.9712,
      "step": 1410
    },
    {
      "epoch": 0.9073482428115016,
      "grad_norm": 0.21690090000629425,
      "learning_rate": 8.803538515905101e-05,
      "loss": 0.9904,
      "step": 1420
    },
    {
      "epoch": 0.9137380191693291,
      "grad_norm": 0.22872275114059448,
      "learning_rate": 8.779301154461946e-05,
      "loss": 0.969,
      "step": 1430
    },
    {
      "epoch": 0.9201277955271565,
      "grad_norm": 0.22388969361782074,
      "learning_rate": 8.754854836551174e-05,
      "loss": 0.9691,
      "step": 1440
    },
    {
      "epoch": 0.9265175718849841,
      "grad_norm": 0.20745474100112915,
      "learning_rate": 8.730200913802638e-05,
      "loss": 0.9824,
      "step": 1450
    },
    {
      "epoch": 0.9329073482428115,
      "grad_norm": 0.19718065857887268,
      "learning_rate": 8.705340749324591e-05,
      "loss": 0.9722,
      "step": 1460
    },
    {
      "epoch": 0.939297124600639,
      "grad_norm": 0.21488656103610992,
      "learning_rate": 8.680275717628337e-05,
      "loss": 0.9913,
      "step": 1470
    },
    {
      "epoch": 0.9456869009584664,
      "grad_norm": 0.2176429033279419,
      "learning_rate": 8.655007204552227e-05,
      "loss": 0.9449,
      "step": 1480
    },
    {
      "epoch": 0.952076677316294,
      "grad_norm": 0.21617379784584045,
      "learning_rate": 8.629536607185043e-05,
      "loss": 0.9985,
      "step": 1490
    },
    {
      "epoch": 0.9584664536741214,
      "grad_norm": 0.23313815891742706,
      "learning_rate": 8.60386533378874e-05,
      "loss": 0.9683,
      "step": 1500
    },
    {
      "epoch": 0.9584664536741214,
      "eval_loss": 0.9707773923873901,
      "eval_runtime": 291.0457,
      "eval_samples_per_second": 38.235,
      "eval_steps_per_second": 1.196,
      "step": 1500
    },
    {
      "epoch": 0.9648562300319489,
      "grad_norm": 0.22435002028942108,
      "learning_rate": 8.577994803720606e-05,
      "loss": 0.9489,
      "step": 1510
    },
    {
      "epoch": 0.9712460063897763,
      "grad_norm": 0.211910218000412,
      "learning_rate": 8.551926447354759e-05,
      "loss": 0.9718,
      "step": 1520
    },
    {
      "epoch": 0.9776357827476039,
      "grad_norm": 0.22928844392299652,
      "learning_rate": 8.525661706003082e-05,
      "loss": 0.9512,
      "step": 1530
    },
    {
      "epoch": 0.9840255591054313,
      "grad_norm": 0.23587335646152496,
      "learning_rate": 8.499202031835532e-05,
      "loss": 1.0138,
      "step": 1540
    },
    {
      "epoch": 0.9904153354632588,
      "grad_norm": 0.21305757761001587,
      "learning_rate": 8.472548887799833e-05,
      "loss": 0.9913,
      "step": 1550
    },
    {
      "epoch": 0.9968051118210862,
      "grad_norm": 0.2124132364988327,
      "learning_rate": 8.445703747540613e-05,
      "loss": 0.9806,
      "step": 1560
    },
    {
      "epoch": 1.0031948881789137,
      "grad_norm": 0.2185613065958023,
      "learning_rate": 8.418668095317912e-05,
      "loss": 0.9382,
      "step": 1570
    },
    {
      "epoch": 1.0095846645367412,
      "grad_norm": 0.22487682104110718,
      "learning_rate": 8.391443425925118e-05,
      "loss": 0.9546,
      "step": 1580
    },
    {
      "epoch": 1.0159744408945688,
      "grad_norm": 0.2259834259748459,
      "learning_rate": 8.364031244606329e-05,
      "loss": 0.9503,
      "step": 1590
    },
    {
      "epoch": 1.0223642172523961,
      "grad_norm": 0.23076602816581726,
      "learning_rate": 8.336433066973122e-05,
      "loss": 0.9353,
      "step": 1600
    },
    {
      "epoch": 1.0287539936102237,
      "grad_norm": 0.2214239239692688,
      "learning_rate": 8.308650418920751e-05,
      "loss": 0.9449,
      "step": 1610
    },
    {
      "epoch": 1.035143769968051,
      "grad_norm": 0.22764110565185547,
      "learning_rate": 8.280684836543794e-05,
      "loss": 0.9242,
      "step": 1620
    },
    {
      "epoch": 1.0415335463258786,
      "grad_norm": 0.21381404995918274,
      "learning_rate": 8.252537866051209e-05,
      "loss": 0.9099,
      "step": 1630
    },
    {
      "epoch": 1.0479233226837061,
      "grad_norm": 0.22402384877204895,
      "learning_rate": 8.224211063680853e-05,
      "loss": 0.9272,
      "step": 1640
    },
    {
      "epoch": 1.0543130990415335,
      "grad_norm": 0.229522243142128,
      "learning_rate": 8.195705995613436e-05,
      "loss": 0.9372,
      "step": 1650
    },
    {
      "epoch": 1.060702875399361,
      "grad_norm": 0.23270799219608307,
      "learning_rate": 8.167024237885927e-05,
      "loss": 0.9096,
      "step": 1660
    },
    {
      "epoch": 1.0670926517571886,
      "grad_norm": 0.22030583024024963,
      "learning_rate": 8.138167376304411e-05,
      "loss": 0.941,
      "step": 1670
    },
    {
      "epoch": 1.073482428115016,
      "grad_norm": 0.23971737921237946,
      "learning_rate": 8.10913700635642e-05,
      "loss": 0.9133,
      "step": 1680
    },
    {
      "epoch": 1.0798722044728435,
      "grad_norm": 0.25113365054130554,
      "learning_rate": 8.079934733122708e-05,
      "loss": 0.9483,
      "step": 1690
    },
    {
      "epoch": 1.0862619808306708,
      "grad_norm": 0.23998698592185974,
      "learning_rate": 8.05056217118852e-05,
      "loss": 0.9435,
      "step": 1700
    },
    {
      "epoch": 1.0926517571884984,
      "grad_norm": 0.23969101905822754,
      "learning_rate": 8.021020944554306e-05,
      "loss": 0.9368,
      "step": 1710
    },
    {
      "epoch": 1.099041533546326,
      "grad_norm": 0.2263995260000229,
      "learning_rate": 7.991312686545937e-05,
      "loss": 0.8974,
      "step": 1720
    },
    {
      "epoch": 1.1054313099041533,
      "grad_norm": 0.23491503298282623,
      "learning_rate": 7.961439039724413e-05,
      "loss": 0.9028,
      "step": 1730
    },
    {
      "epoch": 1.1118210862619808,
      "grad_norm": 0.23820209503173828,
      "learning_rate": 7.931401655795021e-05,
      "loss": 0.9284,
      "step": 1740
    },
    {
      "epoch": 1.1182108626198084,
      "grad_norm": 0.23377910256385803,
      "learning_rate": 7.901202195516029e-05,
      "loss": 0.9263,
      "step": 1750
    },
    {
      "epoch": 1.1246006389776357,
      "grad_norm": 0.24248537421226501,
      "learning_rate": 7.870842328606862e-05,
      "loss": 0.8909,
      "step": 1760
    },
    {
      "epoch": 1.1309904153354633,
      "grad_norm": 0.24948611855506897,
      "learning_rate": 7.840323733655778e-05,
      "loss": 0.9315,
      "step": 1770
    },
    {
      "epoch": 1.1373801916932909,
      "grad_norm": 0.2288467139005661,
      "learning_rate": 7.809648098027067e-05,
      "loss": 0.9371,
      "step": 1780
    },
    {
      "epoch": 1.1437699680511182,
      "grad_norm": 0.28908100724220276,
      "learning_rate": 7.778817117767747e-05,
      "loss": 0.9134,
      "step": 1790
    },
    {
      "epoch": 1.1501597444089458,
      "grad_norm": 0.24185381829738617,
      "learning_rate": 7.747832497513797e-05,
      "loss": 0.937,
      "step": 1800
    },
    {
      "epoch": 1.156549520766773,
      "grad_norm": 0.25165992975234985,
      "learning_rate": 7.716695950395909e-05,
      "loss": 0.948,
      "step": 1810
    },
    {
      "epoch": 1.1629392971246006,
      "grad_norm": 0.24539907276630402,
      "learning_rate": 7.685409197944768e-05,
      "loss": 0.9638,
      "step": 1820
    },
    {
      "epoch": 1.1693290734824282,
      "grad_norm": 0.2612525224685669,
      "learning_rate": 7.653973969995865e-05,
      "loss": 0.9421,
      "step": 1830
    },
    {
      "epoch": 1.1757188498402555,
      "grad_norm": 0.2422924041748047,
      "learning_rate": 7.622392004593861e-05,
      "loss": 0.9436,
      "step": 1840
    },
    {
      "epoch": 1.182108626198083,
      "grad_norm": 0.24453184008598328,
      "learning_rate": 7.59066504789649e-05,
      "loss": 0.9332,
      "step": 1850
    },
    {
      "epoch": 1.1884984025559104,
      "grad_norm": 0.2660824954509735,
      "learning_rate": 7.558794854078007e-05,
      "loss": 0.9446,
      "step": 1860
    },
    {
      "epoch": 1.194888178913738,
      "grad_norm": 0.2362726628780365,
      "learning_rate": 7.526783185232207e-05,
      "loss": 0.9136,
      "step": 1870
    },
    {
      "epoch": 1.2012779552715656,
      "grad_norm": 0.25792691111564636,
      "learning_rate": 7.494631811275007e-05,
      "loss": 0.9451,
      "step": 1880
    },
    {
      "epoch": 1.207667731629393,
      "grad_norm": 0.25431492924690247,
      "learning_rate": 7.46234250984657e-05,
      "loss": 0.9464,
      "step": 1890
    },
    {
      "epoch": 1.2140575079872205,
      "grad_norm": 0.23911546170711517,
      "learning_rate": 7.42991706621303e-05,
      "loss": 0.9289,
      "step": 1900
    },
    {
      "epoch": 1.220447284345048,
      "grad_norm": 0.2667873799800873,
      "learning_rate": 7.397357273167788e-05,
      "loss": 0.9252,
      "step": 1910
    },
    {
      "epoch": 1.2268370607028753,
      "grad_norm": 0.2437986582517624,
      "learning_rate": 7.364664930932384e-05,
      "loss": 0.9251,
      "step": 1920
    },
    {
      "epoch": 1.233226837060703,
      "grad_norm": 0.22574299573898315,
      "learning_rate": 7.331841847056962e-05,
      "loss": 0.9279,
      "step": 1930
    },
    {
      "epoch": 1.2396166134185305,
      "grad_norm": 0.233590766787529,
      "learning_rate": 7.298889836320334e-05,
      "loss": 0.9226,
      "step": 1940
    },
    {
      "epoch": 1.2460063897763578,
      "grad_norm": 0.25184449553489685,
      "learning_rate": 7.265810720629642e-05,
      "loss": 0.9456,
      "step": 1950
    },
    {
      "epoch": 1.2523961661341854,
      "grad_norm": 0.23453117907047272,
      "learning_rate": 7.232606328919627e-05,
      "loss": 0.9183,
      "step": 1960
    },
    {
      "epoch": 1.2587859424920127,
      "grad_norm": 0.26071277260780334,
      "learning_rate": 7.199278497051498e-05,
      "loss": 0.9299,
      "step": 1970
    },
    {
      "epoch": 1.2651757188498403,
      "grad_norm": 0.25269633531570435,
      "learning_rate": 7.165829067711439e-05,
      "loss": 0.9321,
      "step": 1980
    },
    {
      "epoch": 1.2715654952076676,
      "grad_norm": 0.2471066266298294,
      "learning_rate": 7.132259890308726e-05,
      "loss": 0.9104,
      "step": 1990
    },
    {
      "epoch": 1.2779552715654952,
      "grad_norm": 0.2540559470653534,
      "learning_rate": 7.098572820873462e-05,
      "loss": 0.9564,
      "step": 2000
    },
    {
      "epoch": 1.2779552715654952,
      "eval_loss": 0.9695252776145935,
      "eval_runtime": 290.903,
      "eval_samples_per_second": 38.253,
      "eval_steps_per_second": 1.196,
      "step": 2000
    },
    {
      "epoch": 1.2843450479233227,
      "grad_norm": 0.23922093212604523,
      "learning_rate": 7.064769721953976e-05,
      "loss": 0.9331,
      "step": 2010
    },
    {
      "epoch": 1.29073482428115,
      "grad_norm": 0.24620221555233002,
      "learning_rate": 7.030852462513826e-05,
      "loss": 0.9196,
      "step": 2020
    },
    {
      "epoch": 1.2971246006389776,
      "grad_norm": 0.24969786405563354,
      "learning_rate": 6.996822917828477e-05,
      "loss": 0.9164,
      "step": 2030
    },
    {
      "epoch": 1.3035143769968052,
      "grad_norm": 0.2484583705663681,
      "learning_rate": 6.962682969381613e-05,
      "loss": 0.9355,
      "step": 2040
    },
    {
      "epoch": 1.3099041533546325,
      "grad_norm": 0.2522776126861572,
      "learning_rate": 6.928434504761106e-05,
      "loss": 0.9181,
      "step": 2050
    },
    {
      "epoch": 1.31629392971246,
      "grad_norm": 0.2490818351507187,
      "learning_rate": 6.894079417554656e-05,
      "loss": 0.9308,
      "step": 2060
    },
    {
      "epoch": 1.3226837060702876,
      "grad_norm": 0.2312830537557602,
      "learning_rate": 6.859619607245102e-05,
      "loss": 0.9424,
      "step": 2070
    },
    {
      "epoch": 1.329073482428115,
      "grad_norm": 0.2646547257900238,
      "learning_rate": 6.825056979105382e-05,
      "loss": 0.9457,
      "step": 2080
    },
    {
      "epoch": 1.3354632587859425,
      "grad_norm": 0.2450844794511795,
      "learning_rate": 6.790393444093213e-05,
      "loss": 0.9222,
      "step": 2090
    },
    {
      "epoch": 1.34185303514377,
      "grad_norm": 0.22082984447479248,
      "learning_rate": 6.755630918745418e-05,
      "loss": 0.9184,
      "step": 2100
    },
    {
      "epoch": 1.3482428115015974,
      "grad_norm": 0.25806450843811035,
      "learning_rate": 6.720771325071964e-05,
      "loss": 0.9395,
      "step": 2110
    },
    {
      "epoch": 1.354632587859425,
      "grad_norm": 0.24641932547092438,
      "learning_rate": 6.685816590449708e-05,
      "loss": 0.9224,
      "step": 2120
    },
    {
      "epoch": 1.3610223642172525,
      "grad_norm": 0.24396151304244995,
      "learning_rate": 6.650768647515812e-05,
      "loss": 0.9367,
      "step": 2130
    },
    {
      "epoch": 1.3674121405750799,
      "grad_norm": 0.25903478264808655,
      "learning_rate": 6.615629434060902e-05,
      "loss": 0.9034,
      "step": 2140
    },
    {
      "epoch": 1.3738019169329074,
      "grad_norm": 0.2391565591096878,
      "learning_rate": 6.580400892921928e-05,
      "loss": 0.9854,
      "step": 2150
    },
    {
      "epoch": 1.3801916932907348,
      "grad_norm": 0.2557939887046814,
      "learning_rate": 6.545084971874738e-05,
      "loss": 0.9289,
      "step": 2160
    },
    {
      "epoch": 1.3865814696485623,
      "grad_norm": 0.25763335824012756,
      "learning_rate": 6.50968362352639e-05,
      "loss": 0.9236,
      "step": 2170
    },
    {
      "epoch": 1.3929712460063897,
      "grad_norm": 0.2404000610113144,
      "learning_rate": 6.474198805207197e-05,
      "loss": 0.9223,
      "step": 2180
    },
    {
      "epoch": 1.3993610223642172,
      "grad_norm": 0.24704086780548096,
      "learning_rate": 6.438632478862494e-05,
      "loss": 0.9264,
      "step": 2190
    },
    {
      "epoch": 1.4057507987220448,
      "grad_norm": 0.24861331284046173,
      "learning_rate": 6.402986610944182e-05,
      "loss": 0.9118,
      "step": 2200
    },
    {
      "epoch": 1.4121405750798721,
      "grad_norm": 0.2463243305683136,
      "learning_rate": 6.367263172301985e-05,
      "loss": 0.9527,
      "step": 2210
    },
    {
      "epoch": 1.4185303514376997,
      "grad_norm": 0.24560107290744781,
      "learning_rate": 6.331464138074493e-05,
      "loss": 0.9258,
      "step": 2220
    },
    {
      "epoch": 1.4249201277955272,
      "grad_norm": 0.26122811436653137,
      "learning_rate": 6.29559148757995e-05,
      "loss": 0.9276,
      "step": 2230
    },
    {
      "epoch": 1.4313099041533546,
      "grad_norm": 0.2427089661359787,
      "learning_rate": 6.259647204206827e-05,
      "loss": 0.9243,
      "step": 2240
    },
    {
      "epoch": 1.4376996805111821,
      "grad_norm": 0.24114453792572021,
      "learning_rate": 6.223633275304157e-05,
      "loss": 0.9315,
      "step": 2250
    },
    {
      "epoch": 1.4440894568690097,
      "grad_norm": 0.23135952651500702,
      "learning_rate": 6.187551692071648e-05,
      "loss": 0.9153,
      "step": 2260
    },
    {
      "epoch": 1.450479233226837,
      "grad_norm": 0.2371661216020584,
      "learning_rate": 6.151404449449599e-05,
      "loss": 0.9262,
      "step": 2270
    },
    {
      "epoch": 1.4568690095846646,
      "grad_norm": 0.2587081789970398,
      "learning_rate": 6.115193546008602e-05,
      "loss": 0.9163,
      "step": 2280
    },
    {
      "epoch": 1.4632587859424921,
      "grad_norm": 0.25805172324180603,
      "learning_rate": 6.078920983839031e-05,
      "loss": 0.9283,
      "step": 2290
    },
    {
      "epoch": 1.4696485623003195,
      "grad_norm": 0.23599906265735626,
      "learning_rate": 6.042588768440358e-05,
      "loss": 0.9093,
      "step": 2300
    },
    {
      "epoch": 1.476038338658147,
      "grad_norm": 0.23290029168128967,
      "learning_rate": 6.006198908610261e-05,
      "loss": 0.9266,
      "step": 2310
    },
    {
      "epoch": 1.4824281150159744,
      "grad_norm": 0.2434331327676773,
      "learning_rate": 5.969753416333564e-05,
      "loss": 0.9047,
      "step": 2320
    },
    {
      "epoch": 1.488817891373802,
      "grad_norm": 0.25545942783355713,
      "learning_rate": 5.933254306670994e-05,
      "loss": 0.9653,
      "step": 2330
    },
    {
      "epoch": 1.4952076677316293,
      "grad_norm": 0.26612618565559387,
      "learning_rate": 5.896703597647765e-05,
      "loss": 0.9252,
      "step": 2340
    },
    {
      "epoch": 1.5015974440894568,
      "grad_norm": 0.2433769702911377,
      "learning_rate": 5.860103310142005e-05,
      "loss": 0.9256,
      "step": 2350
    },
    {
      "epoch": 1.5079872204472844,
      "grad_norm": 0.24996986985206604,
      "learning_rate": 5.8234554677730266e-05,
      "loss": 0.9265,
      "step": 2360
    },
    {
      "epoch": 1.5143769968051117,
      "grad_norm": 0.2471144050359726,
      "learning_rate": 5.786762096789431e-05,
      "loss": 0.9528,
      "step": 2370
    },
    {
      "epoch": 1.5207667731629393,
      "grad_norm": 0.2572903037071228,
      "learning_rate": 5.750025225957085e-05,
      "loss": 0.9264,
      "step": 2380
    },
    {
      "epoch": 1.5271565495207668,
      "grad_norm": 0.23463748395442963,
      "learning_rate": 5.7132468864469535e-05,
      "loss": 0.9501,
      "step": 2390
    },
    {
      "epoch": 1.5335463258785942,
      "grad_norm": 0.2585728168487549,
      "learning_rate": 5.676429111722785e-05,
      "loss": 0.935,
      "step": 2400
    },
    {
      "epoch": 1.5399361022364217,
      "grad_norm": 0.22888951003551483,
      "learning_rate": 5.639573937428698e-05,
      "loss": 0.9008,
      "step": 2410
    },
    {
      "epoch": 1.5463258785942493,
      "grad_norm": 0.23321181535720825,
      "learning_rate": 5.602683401276615e-05,
      "loss": 0.9151,
      "step": 2420
    },
    {
      "epoch": 1.5527156549520766,
      "grad_norm": 0.24317902326583862,
      "learning_rate": 5.565759542933612e-05,
      "loss": 0.9325,
      "step": 2430
    },
    {
      "epoch": 1.5591054313099042,
      "grad_norm": 0.2493544965982437,
      "learning_rate": 5.528804403909133e-05,
      "loss": 0.9571,
      "step": 2440
    },
    {
      "epoch": 1.5654952076677318,
      "grad_norm": 0.23850466310977936,
      "learning_rate": 5.491820027442126e-05,
      "loss": 0.9165,
      "step": 2450
    },
    {
      "epoch": 1.571884984025559,
      "grad_norm": 0.24905268847942352,
      "learning_rate": 5.4548084583880685e-05,
      "loss": 0.9117,
      "step": 2460
    },
    {
      "epoch": 1.5782747603833864,
      "grad_norm": 0.24651683866977692,
      "learning_rate": 5.417771743105907e-05,
      "loss": 0.9293,
      "step": 2470
    },
    {
      "epoch": 1.5846645367412142,
      "grad_norm": 0.24877199530601501,
      "learning_rate": 5.380711929344915e-05,
      "loss": 0.9094,
      "step": 2480
    },
    {
      "epoch": 1.5910543130990416,
      "grad_norm": 0.2492211014032364,
      "learning_rate": 5.3436310661314756e-05,
      "loss": 0.9429,
      "step": 2490
    },
    {
      "epoch": 1.5974440894568689,
      "grad_norm": 0.234056293964386,
      "learning_rate": 5.30653120365579e-05,
      "loss": 0.9047,
      "step": 2500
    },
    {
      "epoch": 1.5974440894568689,
      "eval_loss": 0.9656950235366821,
      "eval_runtime": 290.9362,
      "eval_samples_per_second": 38.249,
      "eval_steps_per_second": 1.196,
      "step": 2500
    },
    {
      "epoch": 1.6038338658146964,
      "grad_norm": 0.2692307233810425,
      "learning_rate": 5.2694143931585225e-05,
      "loss": 0.8997,
      "step": 2510
    },
    {
      "epoch": 1.610223642172524,
      "grad_norm": 0.24905654788017273,
      "learning_rate": 5.232282686817391e-05,
      "loss": 0.9159,
      "step": 2520
    },
    {
      "epoch": 1.6166134185303513,
      "grad_norm": 0.25591087341308594,
      "learning_rate": 5.195138137633695e-05,
      "loss": 0.9002,
      "step": 2530
    },
    {
      "epoch": 1.623003194888179,
      "grad_norm": 0.26981210708618164,
      "learning_rate": 5.157982799318817e-05,
      "loss": 0.9316,
      "step": 2540
    },
    {
      "epoch": 1.6293929712460065,
      "grad_norm": 0.24318388104438782,
      "learning_rate": 5.1208187261806615e-05,
      "loss": 0.9008,
      "step": 2550
    },
    {
      "epoch": 1.6357827476038338,
      "grad_norm": 0.25468847155570984,
      "learning_rate": 5.083647973010085e-05,
      "loss": 0.9253,
      "step": 2560
    },
    {
      "epoch": 1.6421725239616614,
      "grad_norm": 0.2445395439863205,
      "learning_rate": 5.046472594967279e-05,
      "loss": 0.9382,
      "step": 2570
    },
    {
      "epoch": 1.648562300319489,
      "grad_norm": 0.2620985805988312,
      "learning_rate": 5.0092946474681365e-05,
      "loss": 0.9578,
      "step": 2580
    },
    {
      "epoch": 1.6549520766773163,
      "grad_norm": 0.24761363863945007,
      "learning_rate": 4.9721161860706255e-05,
      "loss": 0.9227,
      "step": 2590
    },
    {
      "epoch": 1.6613418530351438,
      "grad_norm": 0.24846068024635315,
      "learning_rate": 4.934939266361123e-05,
      "loss": 0.9224,
      "step": 2600
    },
    {
      "epoch": 1.6677316293929714,
      "grad_norm": 0.25665226578712463,
      "learning_rate": 4.8977659438407616e-05,
      "loss": 0.9133,
      "step": 2610
    },
    {
      "epoch": 1.6741214057507987,
      "grad_norm": 0.2531121075153351,
      "learning_rate": 4.860598273811792e-05,
      "loss": 0.9414,
      "step": 2620
    },
    {
      "epoch": 1.680511182108626,
      "grad_norm": 0.25113704800605774,
      "learning_rate": 4.8234383112639424e-05,
      "loss": 0.9211,
      "step": 2630
    },
    {
      "epoch": 1.6869009584664538,
      "grad_norm": 0.25973960757255554,
      "learning_rate": 4.786288110760787e-05,
      "loss": 0.9307,
      "step": 2640
    },
    {
      "epoch": 1.6932907348242812,
      "grad_norm": 0.2319308966398239,
      "learning_rate": 4.749149726326169e-05,
      "loss": 0.9062,
      "step": 2650
    },
    {
      "epoch": 1.6996805111821085,
      "grad_norm": 0.2544383406639099,
      "learning_rate": 4.7120252113306214e-05,
      "loss": 0.9193,
      "step": 2660
    },
    {
      "epoch": 1.706070287539936,
      "grad_norm": 0.26294267177581787,
      "learning_rate": 4.674916618377837e-05,
      "loss": 0.9137,
      "step": 2670
    },
    {
      "epoch": 1.7124600638977636,
      "grad_norm": 0.24749840795993805,
      "learning_rate": 4.6378259991911886e-05,
      "loss": 0.9111,
      "step": 2680
    },
    {
      "epoch": 1.718849840255591,
      "grad_norm": 0.26932820677757263,
      "learning_rate": 4.600755404500281e-05,
      "loss": 0.9515,
      "step": 2690
    },
    {
      "epoch": 1.7252396166134185,
      "grad_norm": 0.2557198405265808,
      "learning_rate": 4.563706883927571e-05,
      "loss": 0.938,
      "step": 2700
    },
    {
      "epoch": 1.731629392971246,
      "grad_norm": 0.25674352049827576,
      "learning_rate": 4.526682485875043e-05,
      "loss": 0.9117,
      "step": 2710
    },
    {
      "epoch": 1.7380191693290734,
      "grad_norm": 0.2808297276496887,
      "learning_rate": 4.489684257410958e-05,
      "loss": 0.9586,
      "step": 2720
    },
    {
      "epoch": 1.744408945686901,
      "grad_norm": 0.26020511984825134,
      "learning_rate": 4.452714244156667e-05,
      "loss": 0.9124,
      "step": 2730
    },
    {
      "epoch": 1.7507987220447285,
      "grad_norm": 0.27142494916915894,
      "learning_rate": 4.415774490173504e-05,
      "loss": 0.9452,
      "step": 2740
    },
    {
      "epoch": 1.7571884984025559,
      "grad_norm": 0.25870245695114136,
      "learning_rate": 4.378867037849783e-05,
      "loss": 0.928,
      "step": 2750
    },
    {
      "epoch": 1.7635782747603834,
      "grad_norm": 0.24876239895820618,
      "learning_rate": 4.341993927787871e-05,
      "loss": 0.9459,
      "step": 2760
    },
    {
      "epoch": 1.769968051118211,
      "grad_norm": 0.2581951320171356,
      "learning_rate": 4.305157198691351e-05,
      "loss": 0.9255,
      "step": 2770
    },
    {
      "epoch": 1.7763578274760383,
      "grad_norm": 0.25075972080230713,
      "learning_rate": 4.268358887252322e-05,
      "loss": 0.8979,
      "step": 2780
    },
    {
      "epoch": 1.7827476038338657,
      "grad_norm": 0.24985328316688538,
      "learning_rate": 4.231601028038781e-05,
      "loss": 0.9531,
      "step": 2790
    },
    {
      "epoch": 1.7891373801916934,
      "grad_norm": 0.2586948871612549,
      "learning_rate": 4.194885653382127e-05,
      "loss": 0.9108,
      "step": 2800
    },
    {
      "epoch": 1.7955271565495208,
      "grad_norm": 0.2599389851093292,
      "learning_rate": 4.1582147932648074e-05,
      "loss": 0.9366,
      "step": 2810
    },
    {
      "epoch": 1.8019169329073481,
      "grad_norm": 0.25697487592697144,
      "learning_rate": 4.121590475208071e-05,
      "loss": 0.9239,
      "step": 2820
    },
    {
      "epoch": 1.8083067092651757,
      "grad_norm": 0.2639111578464508,
      "learning_rate": 4.085014724159866e-05,
      "loss": 0.8924,
      "step": 2830
    },
    {
      "epoch": 1.8146964856230032,
      "grad_norm": 0.2590433359146118,
      "learning_rate": 4.0484895623828906e-05,
      "loss": 0.9039,
      "step": 2840
    },
    {
      "epoch": 1.8210862619808306,
      "grad_norm": 0.25636982917785645,
      "learning_rate": 4.0120170093427735e-05,
      "loss": 0.9325,
      "step": 2850
    },
    {
      "epoch": 1.8274760383386581,
      "grad_norm": 0.2639010548591614,
      "learning_rate": 3.9755990815964195e-05,
      "loss": 0.9429,
      "step": 2860
    },
    {
      "epoch": 1.8338658146964857,
      "grad_norm": 0.2507879137992859,
      "learning_rate": 3.9392377926805226e-05,
      "loss": 0.9066,
      "step": 2870
    },
    {
      "epoch": 1.840255591054313,
      "grad_norm": 0.24783654510974884,
      "learning_rate": 3.9029351530002266e-05,
      "loss": 0.9082,
      "step": 2880
    },
    {
      "epoch": 1.8466453674121406,
      "grad_norm": 0.24929983913898468,
      "learning_rate": 3.866693169717982e-05,
      "loss": 0.9165,
      "step": 2890
    },
    {
      "epoch": 1.8530351437699681,
      "grad_norm": 0.2684578001499176,
      "learning_rate": 3.830513846642556e-05,
      "loss": 0.904,
      "step": 2900
    },
    {
      "epoch": 1.8594249201277955,
      "grad_norm": 0.25069382786750793,
      "learning_rate": 3.794399184118259e-05,
      "loss": 0.9307,
      "step": 2910
    },
    {
      "epoch": 1.865814696485623,
      "grad_norm": 0.2510557472705841,
      "learning_rate": 3.758351178914336e-05,
      "loss": 0.9621,
      "step": 2920
    },
    {
      "epoch": 1.8722044728434506,
      "grad_norm": 0.2680441737174988,
      "learning_rate": 3.722371824114564e-05,
      "loss": 0.9051,
      "step": 2930
    },
    {
      "epoch": 1.878594249201278,
      "grad_norm": 0.25260645151138306,
      "learning_rate": 3.6864631090070655e-05,
      "loss": 0.9466,
      "step": 2940
    },
    {
      "epoch": 1.8849840255591053,
      "grad_norm": 0.2494201511144638,
      "learning_rate": 3.6506270189743116e-05,
      "loss": 0.947,
      "step": 2950
    },
    {
      "epoch": 1.891373801916933,
      "grad_norm": 0.2515002191066742,
      "learning_rate": 3.614865535383352e-05,
      "loss": 0.9022,
      "step": 2960
    },
    {
      "epoch": 1.8977635782747604,
      "grad_norm": 0.27058911323547363,
      "learning_rate": 3.57918063547627e-05,
      "loss": 0.9167,
      "step": 2970
    },
    {
      "epoch": 1.9041533546325877,
      "grad_norm": 0.26386362314224243,
      "learning_rate": 3.543574292260862e-05,
      "loss": 0.9302,
      "step": 2980
    },
    {
      "epoch": 1.9105431309904153,
      "grad_norm": 0.2647424340248108,
      "learning_rate": 3.5080484744015405e-05,
      "loss": 0.8971,
      "step": 2990
    },
    {
      "epoch": 1.9169329073482428,
      "grad_norm": 0.24879953265190125,
      "learning_rate": 3.4726051461105016e-05,
      "loss": 0.8991,
      "step": 3000
    },
    {
      "epoch": 1.9169329073482428,
      "eval_loss": 0.9616478085517883,
      "eval_runtime": 291.0223,
      "eval_samples_per_second": 38.238,
      "eval_steps_per_second": 1.196,
      "step": 3000
    },
    {
      "epoch": 1.9233226837060702,
      "grad_norm": 0.2989354133605957,
      "learning_rate": 3.437246267039115e-05,
      "loss": 0.9246,
      "step": 3010
    },
    {
      "epoch": 1.9297124600638977,
      "grad_norm": 0.23487447202205658,
      "learning_rate": 3.401973792169574e-05,
      "loss": 0.9169,
      "step": 3020
    },
    {
      "epoch": 1.9361022364217253,
      "grad_norm": 0.28516075015068054,
      "learning_rate": 3.36678967170681e-05,
      "loss": 0.9315,
      "step": 3030
    },
    {
      "epoch": 1.9424920127795526,
      "grad_norm": 0.26519498229026794,
      "learning_rate": 3.3316958509706696e-05,
      "loss": 0.9184,
      "step": 3040
    },
    {
      "epoch": 1.9488817891373802,
      "grad_norm": 0.26408079266548157,
      "learning_rate": 3.296694270288349e-05,
      "loss": 0.9001,
      "step": 3050
    },
    {
      "epoch": 1.9552715654952078,
      "grad_norm": 0.25657033920288086,
      "learning_rate": 3.261786864887117e-05,
      "loss": 0.8845,
      "step": 3060
    },
    {
      "epoch": 1.961661341853035,
      "grad_norm": 0.25025033950805664,
      "learning_rate": 3.226975564787322e-05,
      "loss": 0.9196,
      "step": 3070
    },
    {
      "epoch": 1.9680511182108626,
      "grad_norm": 0.24586722254753113,
      "learning_rate": 3.1922622946956785e-05,
      "loss": 0.8955,
      "step": 3080
    },
    {
      "epoch": 1.9744408945686902,
      "grad_norm": 0.26254403591156006,
      "learning_rate": 3.1576489738988455e-05,
      "loss": 0.8887,
      "step": 3090
    },
    {
      "epoch": 1.9808306709265175,
      "grad_norm": 0.26823970675468445,
      "learning_rate": 3.1231375161573194e-05,
      "loss": 0.9288,
      "step": 3100
    },
    {
      "epoch": 1.9872204472843449,
      "grad_norm": 0.2650967240333557,
      "learning_rate": 3.088729829599618e-05,
      "loss": 0.9737,
      "step": 3110
    },
    {
      "epoch": 1.9936102236421727,
      "grad_norm": 0.2690238654613495,
      "learning_rate": 3.054427816616773e-05,
      "loss": 0.9416,
      "step": 3120
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2646315097808838,
      "learning_rate": 3.020233373757162e-05,
      "loss": 0.9428,
      "step": 3130
    },
    {
      "epoch": 2.0063897763578273,
      "grad_norm": 0.2699684798717499,
      "learning_rate": 2.9861483916216405e-05,
      "loss": 0.8941,
      "step": 3140
    },
    {
      "epoch": 2.012779552715655,
      "grad_norm": 0.2634425163269043,
      "learning_rate": 2.9521747547590118e-05,
      "loss": 0.841,
      "step": 3150
    },
    {
      "epoch": 2.0191693290734825,
      "grad_norm": 0.2636459767818451,
      "learning_rate": 2.9183143415618297e-05,
      "loss": 0.862,
      "step": 3160
    },
    {
      "epoch": 2.02555910543131,
      "grad_norm": 0.26843371987342834,
      "learning_rate": 2.8845690241625435e-05,
      "loss": 0.882,
      "step": 3170
    },
    {
      "epoch": 2.0319488817891376,
      "grad_norm": 0.28754544258117676,
      "learning_rate": 2.8509406683299955e-05,
      "loss": 0.8725,
      "step": 3180
    },
    {
      "epoch": 2.038338658146965,
      "grad_norm": 0.2874925434589386,
      "learning_rate": 2.8174311333662462e-05,
      "loss": 0.8518,
      "step": 3190
    },
    {
      "epoch": 2.0447284345047922,
      "grad_norm": 0.26325365900993347,
      "learning_rate": 2.784042272003794e-05,
      "loss": 0.8858,
      "step": 3200
    },
    {
      "epoch": 2.0511182108626196,
      "grad_norm": 0.27015990018844604,
      "learning_rate": 2.7507759303031257e-05,
      "loss": 0.8794,
      "step": 3210
    },
    {
      "epoch": 2.0575079872204474,
      "grad_norm": 0.27441710233688354,
      "learning_rate": 2.717633947550651e-05,
      "loss": 0.8767,
      "step": 3220
    },
    {
      "epoch": 2.0638977635782747,
      "grad_norm": 0.2594762444496155,
      "learning_rate": 2.6846181561570083e-05,
      "loss": 0.8609,
      "step": 3230
    },
    {
      "epoch": 2.070287539936102,
      "grad_norm": 0.25948986411094666,
      "learning_rate": 2.6517303815557538e-05,
      "loss": 0.8513,
      "step": 3240
    },
    {
      "epoch": 2.07667731629393,
      "grad_norm": 0.2756735384464264,
      "learning_rate": 2.618972442102432e-05,
      "loss": 0.8853,
      "step": 3250
    },
    {
      "epoch": 2.083067092651757,
      "grad_norm": 0.26790910959243774,
      "learning_rate": 2.5863461489740404e-05,
      "loss": 0.8565,
      "step": 3260
    },
    {
      "epoch": 2.0894568690095845,
      "grad_norm": 0.25490084290504456,
      "learning_rate": 2.553853306068888e-05,
      "loss": 0.8843,
      "step": 3270
    },
    {
      "epoch": 2.0958466453674123,
      "grad_norm": 0.26735812425613403,
      "learning_rate": 2.5214957099068615e-05,
      "loss": 0.8784,
      "step": 3280
    },
    {
      "epoch": 2.1022364217252396,
      "grad_norm": 0.29232701659202576,
      "learning_rate": 2.4892751495300892e-05,
      "loss": 0.8841,
      "step": 3290
    },
    {
      "epoch": 2.108626198083067,
      "grad_norm": 0.27723345160484314,
      "learning_rate": 2.4571934064040364e-05,
      "loss": 0.8824,
      "step": 3300
    },
    {
      "epoch": 2.1150159744408947,
      "grad_norm": 0.28497010469436646,
      "learning_rate": 2.425252254319002e-05,
      "loss": 0.8821,
      "step": 3310
    },
    {
      "epoch": 2.121405750798722,
      "grad_norm": 0.26380103826522827,
      "learning_rate": 2.3934534592920416e-05,
      "loss": 0.8538,
      "step": 3320
    },
    {
      "epoch": 2.1277955271565494,
      "grad_norm": 0.28753092885017395,
      "learning_rate": 2.361798779469336e-05,
      "loss": 0.86,
      "step": 3330
    },
    {
      "epoch": 2.134185303514377,
      "grad_norm": 0.26377350091934204,
      "learning_rate": 2.3302899650289773e-05,
      "loss": 0.8342,
      "step": 3340
    },
    {
      "epoch": 2.1405750798722045,
      "grad_norm": 0.283295214176178,
      "learning_rate": 2.2989287580841983e-05,
      "loss": 0.8691,
      "step": 3350
    },
    {
      "epoch": 2.146964856230032,
      "grad_norm": 0.26294174790382385,
      "learning_rate": 2.2677168925870616e-05,
      "loss": 0.8707,
      "step": 3360
    },
    {
      "epoch": 2.1533546325878596,
      "grad_norm": 0.30489522218704224,
      "learning_rate": 2.2366560942325832e-05,
      "loss": 0.8653,
      "step": 3370
    },
    {
      "epoch": 2.159744408945687,
      "grad_norm": 0.2729284167289734,
      "learning_rate": 2.2057480803633156e-05,
      "loss": 0.8668,
      "step": 3380
    },
    {
      "epoch": 2.1661341853035143,
      "grad_norm": 0.29038864374160767,
      "learning_rate": 2.1749945598744076e-05,
      "loss": 0.8529,
      "step": 3390
    },
    {
      "epoch": 2.1725239616613417,
      "grad_norm": 0.26758164167404175,
      "learning_rate": 2.144397233119112e-05,
      "loss": 0.8734,
      "step": 3400
    },
    {
      "epoch": 2.1789137380191694,
      "grad_norm": 0.27213186025619507,
      "learning_rate": 2.1139577918147713e-05,
      "loss": 0.8452,
      "step": 3410
    },
    {
      "epoch": 2.1853035143769968,
      "grad_norm": 0.28954175114631653,
      "learning_rate": 2.083677918949292e-05,
      "loss": 0.9025,
      "step": 3420
    },
    {
      "epoch": 2.191693290734824,
      "grad_norm": 0.26198074221611023,
      "learning_rate": 2.0535592886880862e-05,
      "loss": 0.8968,
      "step": 3430
    },
    {
      "epoch": 2.198083067092652,
      "grad_norm": 0.2746649384498596,
      "learning_rate": 2.02360356628151e-05,
      "loss": 0.8648,
      "step": 3440
    },
    {
      "epoch": 2.2044728434504792,
      "grad_norm": 0.2929013967514038,
      "learning_rate": 1.993812407972787e-05,
      "loss": 0.8995,
      "step": 3450
    },
    {
      "epoch": 2.2108626198083066,
      "grad_norm": 0.2593346834182739,
      "learning_rate": 1.9641874609064443e-05,
      "loss": 0.8676,
      "step": 3460
    },
    {
      "epoch": 2.2172523961661343,
      "grad_norm": 0.2785012722015381,
      "learning_rate": 1.934730363037237e-05,
      "loss": 0.873,
      "step": 3470
    },
    {
      "epoch": 2.2236421725239617,
      "grad_norm": 0.2894919514656067,
      "learning_rate": 1.9054427430395827e-05,
      "loss": 0.882,
      "step": 3480
    },
    {
      "epoch": 2.230031948881789,
      "grad_norm": 0.26897120475769043,
      "learning_rate": 1.8763262202175204e-05,
      "loss": 0.8621,
      "step": 3490
    },
    {
      "epoch": 2.236421725239617,
      "grad_norm": 0.2715565264225006,
      "learning_rate": 1.847382404415176e-05,
      "loss": 0.8625,
      "step": 3500
    },
    {
      "epoch": 2.236421725239617,
      "eval_loss": 0.969992995262146,
      "eval_runtime": 290.9795,
      "eval_samples_per_second": 38.243,
      "eval_steps_per_second": 1.196,
      "step": 3500
    },
    {
      "epoch": 2.242811501597444,
      "grad_norm": 0.2718171775341034,
      "learning_rate": 1.81861289592775e-05,
      "loss": 0.8586,
      "step": 3510
    },
    {
      "epoch": 2.2492012779552715,
      "grad_norm": 0.2863433361053467,
      "learning_rate": 1.7900192854130467e-05,
      "loss": 0.8669,
      "step": 3520
    },
    {
      "epoch": 2.255591054313099,
      "grad_norm": 0.28199392557144165,
      "learning_rate": 1.761603153803519e-05,
      "loss": 0.8594,
      "step": 3530
    },
    {
      "epoch": 2.2619808306709266,
      "grad_norm": 0.2854424715042114,
      "learning_rate": 1.7333660722188667e-05,
      "loss": 0.8963,
      "step": 3540
    },
    {
      "epoch": 2.268370607028754,
      "grad_norm": 0.2824346125125885,
      "learning_rate": 1.7053096018791585e-05,
      "loss": 0.8742,
      "step": 3550
    },
    {
      "epoch": 2.2747603833865817,
      "grad_norm": 0.2841264605522156,
      "learning_rate": 1.677435294018527e-05,
      "loss": 0.8762,
      "step": 3560
    },
    {
      "epoch": 2.281150159744409,
      "grad_norm": 0.286357581615448,
      "learning_rate": 1.6497446897993883e-05,
      "loss": 0.8479,
      "step": 3570
    },
    {
      "epoch": 2.2875399361022364,
      "grad_norm": 0.2862420976161957,
      "learning_rate": 1.6222393202272413e-05,
      "loss": 0.8531,
      "step": 3580
    },
    {
      "epoch": 2.2939297124600637,
      "grad_norm": 0.2899746894836426,
      "learning_rate": 1.5949207060660138e-05,
      "loss": 0.8715,
      "step": 3590
    },
    {
      "epoch": 2.3003194888178915,
      "grad_norm": 0.2907244861125946,
      "learning_rate": 1.5677903577539806e-05,
      "loss": 0.8534,
      "step": 3600
    },
    {
      "epoch": 2.306709265175719,
      "grad_norm": 0.28558677434921265,
      "learning_rate": 1.5408497753202498e-05,
      "loss": 0.8645,
      "step": 3610
    },
    {
      "epoch": 2.313099041533546,
      "grad_norm": 0.2978692352771759,
      "learning_rate": 1.5141004483018323e-05,
      "loss": 0.84,
      "step": 3620
    },
    {
      "epoch": 2.319488817891374,
      "grad_norm": 0.2970718443393707,
      "learning_rate": 1.4875438556612836e-05,
      "loss": 0.8678,
      "step": 3630
    },
    {
      "epoch": 2.3258785942492013,
      "grad_norm": 0.29052790999412537,
      "learning_rate": 1.4611814657049256e-05,
      "loss": 0.9115,
      "step": 3640
    },
    {
      "epoch": 2.3322683706070286,
      "grad_norm": 0.2832261919975281,
      "learning_rate": 1.4350147360016742e-05,
      "loss": 0.8574,
      "step": 3650
    },
    {
      "epoch": 2.3386581469648564,
      "grad_norm": 0.2912304997444153,
      "learning_rate": 1.4090451133024474e-05,
      "loss": 0.925,
      "step": 3660
    },
    {
      "epoch": 2.3450479233226837,
      "grad_norm": 0.28533661365509033,
      "learning_rate": 1.383274033460169e-05,
      "loss": 0.8692,
      "step": 3670
    },
    {
      "epoch": 2.351437699680511,
      "grad_norm": 0.2835496962070465,
      "learning_rate": 1.357702921350391e-05,
      "loss": 0.9065,
      "step": 3680
    },
    {
      "epoch": 2.357827476038339,
      "grad_norm": 0.2805232107639313,
      "learning_rate": 1.3323331907925046e-05,
      "loss": 0.8552,
      "step": 3690
    },
    {
      "epoch": 2.364217252396166,
      "grad_norm": 0.2969912588596344,
      "learning_rate": 1.307166244471576e-05,
      "loss": 0.8704,
      "step": 3700
    },
    {
      "epoch": 2.3706070287539935,
      "grad_norm": 0.2822449505329132,
      "learning_rate": 1.282203473860783e-05,
      "loss": 0.8538,
      "step": 3710
    },
    {
      "epoch": 2.376996805111821,
      "grad_norm": 0.28603705763816833,
      "learning_rate": 1.257446259144494e-05,
      "loss": 0.8743,
      "step": 3720
    },
    {
      "epoch": 2.3833865814696487,
      "grad_norm": 0.27493011951446533,
      "learning_rate": 1.2328959691419516e-05,
      "loss": 0.8881,
      "step": 3730
    },
    {
      "epoch": 2.389776357827476,
      "grad_norm": 0.2925710678100586,
      "learning_rate": 1.2085539612315843e-05,
      "loss": 0.8802,
      "step": 3740
    },
    {
      "epoch": 2.3961661341853033,
      "grad_norm": 0.2640359103679657,
      "learning_rate": 1.1844215812759707e-05,
      "loss": 0.851,
      "step": 3750
    },
    {
      "epoch": 2.402555910543131,
      "grad_norm": 0.2970721125602722,
      "learning_rate": 1.1605001635474183e-05,
      "loss": 0.852,
      "step": 3760
    },
    {
      "epoch": 2.4089456869009584,
      "grad_norm": 0.2745356857776642,
      "learning_rate": 1.1367910306541917e-05,
      "loss": 0.8654,
      "step": 3770
    },
    {
      "epoch": 2.415335463258786,
      "grad_norm": 0.29547008872032166,
      "learning_rate": 1.1132954934673912e-05,
      "loss": 0.8796,
      "step": 3780
    },
    {
      "epoch": 2.4217252396166136,
      "grad_norm": 0.28828495740890503,
      "learning_rate": 1.0900148510484732e-05,
      "loss": 0.8567,
      "step": 3790
    },
    {
      "epoch": 2.428115015974441,
      "grad_norm": 0.27122625708580017,
      "learning_rate": 1.0669503905774198e-05,
      "loss": 0.8706,
      "step": 3800
    },
    {
      "epoch": 2.4345047923322682,
      "grad_norm": 0.2570444941520691,
      "learning_rate": 1.0441033872815803e-05,
      "loss": 0.8685,
      "step": 3810
    },
    {
      "epoch": 2.440894568690096,
      "grad_norm": 0.270821213722229,
      "learning_rate": 1.0214751043651582e-05,
      "loss": 0.8527,
      "step": 3820
    },
    {
      "epoch": 2.4472843450479234,
      "grad_norm": 0.2681812047958374,
      "learning_rate": 9.990667929393715e-06,
      "loss": 0.8835,
      "step": 3830
    },
    {
      "epoch": 2.4536741214057507,
      "grad_norm": 0.27925512194633484,
      "learning_rate": 9.768796919532741e-06,
      "loss": 0.8811,
      "step": 3840
    },
    {
      "epoch": 2.460063897763578,
      "grad_norm": 0.283954381942749,
      "learning_rate": 9.549150281252633e-06,
      "loss": 0.8663,
      "step": 3850
    },
    {
      "epoch": 2.466453674121406,
      "grad_norm": 0.28029340505599976,
      "learning_rate": 9.331740158752494e-06,
      "loss": 0.8652,
      "step": 3860
    },
    {
      "epoch": 2.472843450479233,
      "grad_norm": 0.29660487174987793,
      "learning_rate": 9.11657857257509e-06,
      "loss": 0.8776,
      "step": 3870
    },
    {
      "epoch": 2.479233226837061,
      "grad_norm": 0.27837222814559937,
      "learning_rate": 8.90367741894229e-06,
      "loss": 0.8458,
      "step": 3880
    },
    {
      "epoch": 2.4856230031948883,
      "grad_norm": 0.28174012899398804,
      "learning_rate": 8.693048469097293e-06,
      "loss": 0.8465,
      "step": 3890
    },
    {
      "epoch": 2.4920127795527156,
      "grad_norm": 0.28194865584373474,
      "learning_rate": 8.484703368653813e-06,
      "loss": 0.8644,
      "step": 3900
    },
    {
      "epoch": 2.498402555910543,
      "grad_norm": 0.28004008531570435,
      "learning_rate": 8.278653636952177e-06,
      "loss": 0.8706,
      "step": 3910
    },
    {
      "epoch": 2.5047923322683707,
      "grad_norm": 0.2908726632595062,
      "learning_rate": 8.074910666422475e-06,
      "loss": 0.8647,
      "step": 3920
    },
    {
      "epoch": 2.511182108626198,
      "grad_norm": 0.3058490455150604,
      "learning_rate": 7.87348572195457e-06,
      "loss": 0.8457,
      "step": 3930
    },
    {
      "epoch": 2.5175718849840254,
      "grad_norm": 0.27407652139663696,
      "learning_rate": 7.674389940275405e-06,
      "loss": 0.9009,
      "step": 3940
    },
    {
      "epoch": 2.523961661341853,
      "grad_norm": 0.2785779535770416,
      "learning_rate": 7.47763432933315e-06,
      "loss": 0.8661,
      "step": 3950
    },
    {
      "epoch": 2.5303514376996805,
      "grad_norm": 0.2933237552642822,
      "learning_rate": 7.283229767688626e-06,
      "loss": 0.8719,
      "step": 3960
    },
    {
      "epoch": 2.536741214057508,
      "grad_norm": 0.29500406980514526,
      "learning_rate": 7.0911870039138015e-06,
      "loss": 0.8753,
      "step": 3970
    },
    {
      "epoch": 2.543130990415335,
      "grad_norm": 0.27988681197166443,
      "learning_rate": 6.901516655997536e-06,
      "loss": 0.8708,
      "step": 3980
    },
    {
      "epoch": 2.549520766773163,
      "grad_norm": 0.29505205154418945,
      "learning_rate": 6.714229210758516e-06,
      "loss": 0.8684,
      "step": 3990
    },
    {
      "epoch": 2.5559105431309903,
      "grad_norm": 0.2804200053215027,
      "learning_rate": 6.529335023265387e-06,
      "loss": 0.8846,
      "step": 4000
    },
    {
      "epoch": 2.5559105431309903,
      "eval_loss": 0.9686636924743652,
      "eval_runtime": 291.0444,
      "eval_samples_per_second": 38.235,
      "eval_steps_per_second": 1.196,
      "step": 4000
    },
    {
      "epoch": 2.562300319488818,
      "grad_norm": 0.2683858573436737,
      "learning_rate": 6.346844316264311e-06,
      "loss": 0.8426,
      "step": 4010
    },
    {
      "epoch": 2.5686900958466454,
      "grad_norm": 0.2839629352092743,
      "learning_rate": 6.166767179613692e-06,
      "loss": 0.838,
      "step": 4020
    },
    {
      "epoch": 2.5750798722044728,
      "grad_norm": 0.29712003469467163,
      "learning_rate": 5.9891135697263125e-06,
      "loss": 0.8562,
      "step": 4030
    },
    {
      "epoch": 2.5814696485623,
      "grad_norm": 0.28366991877555847,
      "learning_rate": 5.813893309018881e-06,
      "loss": 0.8604,
      "step": 4040
    },
    {
      "epoch": 2.587859424920128,
      "grad_norm": 0.29461807012557983,
      "learning_rate": 5.64111608536893e-06,
      "loss": 0.8873,
      "step": 4050
    },
    {
      "epoch": 2.594249201277955,
      "grad_norm": 0.29177358746528625,
      "learning_rate": 5.470791451579171e-06,
      "loss": 0.8733,
      "step": 4060
    },
    {
      "epoch": 2.600638977635783,
      "grad_norm": 0.25575900077819824,
      "learning_rate": 5.302928824849334e-06,
      "loss": 0.8483,
      "step": 4070
    },
    {
      "epoch": 2.6070287539936103,
      "grad_norm": 0.2876461446285248,
      "learning_rate": 5.137537486255517e-06,
      "loss": 0.8496,
      "step": 4080
    },
    {
      "epoch": 2.6134185303514377,
      "grad_norm": 0.2842155992984772,
      "learning_rate": 4.9746265802369575e-06,
      "loss": 0.8996,
      "step": 4090
    },
    {
      "epoch": 2.619808306709265,
      "grad_norm": 0.2644229233264923,
      "learning_rate": 4.814205114090542e-06,
      "loss": 0.8813,
      "step": 4100
    },
    {
      "epoch": 2.626198083067093,
      "grad_norm": 0.2907552123069763,
      "learning_rate": 4.65628195747273e-06,
      "loss": 0.8972,
      "step": 4110
    },
    {
      "epoch": 2.63258785942492,
      "grad_norm": 0.2706671953201294,
      "learning_rate": 4.500865841909168e-06,
      "loss": 0.8609,
      "step": 4120
    },
    {
      "epoch": 2.6389776357827475,
      "grad_norm": 0.2974990904331207,
      "learning_rate": 4.347965360311929e-06,
      "loss": 0.8892,
      "step": 4130
    },
    {
      "epoch": 2.6453674121405752,
      "grad_norm": 0.2852054536342621,
      "learning_rate": 4.197588966504401e-06,
      "loss": 0.8735,
      "step": 4140
    },
    {
      "epoch": 2.6517571884984026,
      "grad_norm": 0.28945034742355347,
      "learning_rate": 4.049744974753921e-06,
      "loss": 0.871,
      "step": 4150
    },
    {
      "epoch": 2.65814696485623,
      "grad_norm": 0.31356897950172424,
      "learning_rate": 3.904441559312005e-06,
      "loss": 0.8884,
      "step": 4160
    },
    {
      "epoch": 2.6645367412140573,
      "grad_norm": 0.2861325740814209,
      "learning_rate": 3.7616867539624734e-06,
      "loss": 0.8905,
      "step": 4170
    },
    {
      "epoch": 2.670926517571885,
      "grad_norm": 0.30535680055618286,
      "learning_rate": 3.621488451577221e-06,
      "loss": 0.8975,
      "step": 4180
    },
    {
      "epoch": 2.6773162939297124,
      "grad_norm": 0.27858126163482666,
      "learning_rate": 3.4838544036798317e-06,
      "loss": 0.8905,
      "step": 4190
    },
    {
      "epoch": 2.68370607028754,
      "grad_norm": 0.2933747172355652,
      "learning_rate": 3.348792220016994e-06,
      "loss": 0.8572,
      "step": 4200
    },
    {
      "epoch": 2.6900958466453675,
      "grad_norm": 0.29340362548828125,
      "learning_rate": 3.2163093681377764e-06,
      "loss": 0.8769,
      "step": 4210
    },
    {
      "epoch": 2.696485623003195,
      "grad_norm": 0.28074297308921814,
      "learning_rate": 3.0864131729807398e-06,
      "loss": 0.892,
      "step": 4220
    },
    {
      "epoch": 2.702875399361022,
      "grad_norm": 0.2819015681743622,
      "learning_rate": 2.9591108164689353e-06,
      "loss": 0.8656,
      "step": 4230
    },
    {
      "epoch": 2.70926517571885,
      "grad_norm": 0.30151233077049255,
      "learning_rate": 2.8344093371128424e-06,
      "loss": 0.8728,
      "step": 4240
    },
    {
      "epoch": 2.7156549520766773,
      "grad_norm": 0.29090794920921326,
      "learning_rate": 2.712315629621176e-06,
      "loss": 0.8991,
      "step": 4250
    },
    {
      "epoch": 2.722044728434505,
      "grad_norm": 0.3066655695438385,
      "learning_rate": 2.592836444519697e-06,
      "loss": 0.8719,
      "step": 4260
    },
    {
      "epoch": 2.7284345047923324,
      "grad_norm": 0.2762013077735901,
      "learning_rate": 2.4759783877779995e-06,
      "loss": 0.8485,
      "step": 4270
    },
    {
      "epoch": 2.7348242811501597,
      "grad_norm": 0.29662972688674927,
      "learning_rate": 2.3617479204442463e-06,
      "loss": 0.8684,
      "step": 4280
    },
    {
      "epoch": 2.741214057507987,
      "grad_norm": 0.2849913537502289,
      "learning_rate": 2.2501513582879108e-06,
      "loss": 0.8571,
      "step": 4290
    },
    {
      "epoch": 2.747603833865815,
      "grad_norm": 0.2938566207885742,
      "learning_rate": 2.1411948714506415e-06,
      "loss": 0.8338,
      "step": 4300
    },
    {
      "epoch": 2.753993610223642,
      "grad_norm": 0.30299192667007446,
      "learning_rate": 2.034884484105093e-06,
      "loss": 0.8545,
      "step": 4310
    },
    {
      "epoch": 2.7603833865814695,
      "grad_norm": 0.2724585235118866,
      "learning_rate": 1.931226074121811e-06,
      "loss": 0.835,
      "step": 4320
    },
    {
      "epoch": 2.7667731629392973,
      "grad_norm": 0.3003793954849243,
      "learning_rate": 1.8302253727443041e-06,
      "loss": 0.8609,
      "step": 4330
    },
    {
      "epoch": 2.7731629392971247,
      "grad_norm": 0.28628161549568176,
      "learning_rate": 1.7318879642721441e-06,
      "loss": 0.8396,
      "step": 4340
    },
    {
      "epoch": 2.779552715654952,
      "grad_norm": 0.306625097990036,
      "learning_rate": 1.6362192857521941e-06,
      "loss": 0.8776,
      "step": 4350
    },
    {
      "epoch": 2.7859424920127793,
      "grad_norm": 0.2785678803920746,
      "learning_rate": 1.5432246266780082e-06,
      "loss": 0.8468,
      "step": 4360
    },
    {
      "epoch": 2.792332268370607,
      "grad_norm": 0.27568668127059937,
      "learning_rate": 1.4529091286973995e-06,
      "loss": 0.8603,
      "step": 4370
    },
    {
      "epoch": 2.7987220447284344,
      "grad_norm": 0.28255051374435425,
      "learning_rate": 1.3652777853281228e-06,
      "loss": 0.8888,
      "step": 4380
    },
    {
      "epoch": 2.8051118210862622,
      "grad_norm": 0.28029873967170715,
      "learning_rate": 1.2803354416817958e-06,
      "loss": 0.8745,
      "step": 4390
    },
    {
      "epoch": 2.8115015974440896,
      "grad_norm": 0.3087801933288574,
      "learning_rate": 1.198086794196035e-06,
      "loss": 0.8967,
      "step": 4400
    },
    {
      "epoch": 2.817891373801917,
      "grad_norm": 0.2741745412349701,
      "learning_rate": 1.1185363903747749e-06,
      "loss": 0.8838,
      "step": 4410
    },
    {
      "epoch": 2.8242811501597442,
      "grad_norm": 0.2874603271484375,
      "learning_rate": 1.0416886285368187e-06,
      "loss": 0.8629,
      "step": 4420
    },
    {
      "epoch": 2.830670926517572,
      "grad_norm": 0.2744494378566742,
      "learning_rate": 9.675477575726955e-07,
      "loss": 0.8721,
      "step": 4430
    },
    {
      "epoch": 2.8370607028753994,
      "grad_norm": 0.3030591309070587,
      "learning_rate": 8.961178767097178e-07,
      "loss": 0.8671,
      "step": 4440
    },
    {
      "epoch": 2.8434504792332267,
      "grad_norm": 0.28650814294815063,
      "learning_rate": 8.274029352853263e-07,
      "loss": 0.879,
      "step": 4450
    },
    {
      "epoch": 2.8498402555910545,
      "grad_norm": 0.25287526845932007,
      "learning_rate": 7.614067325287633e-07,
      "loss": 0.8418,
      "step": 4460
    },
    {
      "epoch": 2.856230031948882,
      "grad_norm": 0.2870739996433258,
      "learning_rate": 6.98132917350991e-07,
      "loss": 0.8537,
      "step": 4470
    },
    {
      "epoch": 2.862619808306709,
      "grad_norm": 0.2720504403114319,
      "learning_rate": 6.375849881429419e-07,
      "loss": 0.8423,
      "step": 4480
    },
    {
      "epoch": 2.8690095846645365,
      "grad_norm": 0.2629035413265228,
      "learning_rate": 5.797662925821068e-07,
      "loss": 0.8663,
      "step": 4490
    },
    {
      "epoch": 2.8753993610223643,
      "grad_norm": 0.28707313537597656,
      "learning_rate": 5.246800274474439e-07,
      "loss": 0.872,
      "step": 4500
    },
    {
      "epoch": 2.8753993610223643,
      "eval_loss": 0.9684935808181763,
      "eval_runtime": 291.1048,
      "eval_samples_per_second": 38.227,
      "eval_steps_per_second": 1.195,
      "step": 4500
    },
    {
      "epoch": 2.8817891373801916,
      "grad_norm": 0.2974375784397125,
      "learning_rate": 4.7232923844262033e-07,
      "loss": 0.8546,
      "step": 4510
    },
    {
      "epoch": 2.8881789137380194,
      "grad_norm": 0.309094101190567,
      "learning_rate": 4.227168200276077e-07,
      "loss": 0.8961,
      "step": 4520
    },
    {
      "epoch": 2.8945686900958467,
      "grad_norm": 0.2794800102710724,
      "learning_rate": 3.7584551525867153e-07,
      "loss": 0.8655,
      "step": 4530
    },
    {
      "epoch": 2.900958466453674,
      "grad_norm": 0.3083367645740509,
      "learning_rate": 3.3171791563669785e-07,
      "loss": 0.8646,
      "step": 4540
    },
    {
      "epoch": 2.9073482428115014,
      "grad_norm": 0.31013885140419006,
      "learning_rate": 2.9033646096390254e-07,
      "loss": 0.8692,
      "step": 4550
    },
    {
      "epoch": 2.913738019169329,
      "grad_norm": 0.2875990867614746,
      "learning_rate": 2.5170343920894454e-07,
      "loss": 0.8593,
      "step": 4560
    },
    {
      "epoch": 2.9201277955271565,
      "grad_norm": 0.2717428207397461,
      "learning_rate": 2.158209863804217e-07,
      "loss": 0.9064,
      "step": 4570
    },
    {
      "epoch": 2.9265175718849843,
      "grad_norm": 0.2961931526660919,
      "learning_rate": 1.826910864087761e-07,
      "loss": 0.8532,
      "step": 4580
    },
    {
      "epoch": 2.9329073482428116,
      "grad_norm": 0.263370156288147,
      "learning_rate": 1.5231557103658757e-07,
      "loss": 0.8562,
      "step": 4590
    },
    {
      "epoch": 2.939297124600639,
      "grad_norm": 0.2976776957511902,
      "learning_rate": 1.2469611971731576e-07,
      "loss": 0.8744,
      "step": 4600
    },
    {
      "epoch": 2.9456869009584663,
      "grad_norm": 0.2830747067928314,
      "learning_rate": 9.983425952243553e-08,
      "loss": 0.8347,
      "step": 4610
    },
    {
      "epoch": 2.952076677316294,
      "grad_norm": 0.286816269159317,
      "learning_rate": 7.773136505700995e-08,
      "loss": 0.8657,
      "step": 4620
    },
    {
      "epoch": 2.9584664536741214,
      "grad_norm": 0.29436230659484863,
      "learning_rate": 5.838865838366792e-08,
      "loss": 0.8543,
      "step": 4630
    },
    {
      "epoch": 2.9648562300319488,
      "grad_norm": 0.3100464344024658,
      "learning_rate": 4.1807208955080277e-08,
      "loss": 0.8592,
      "step": 4640
    },
    {
      "epoch": 2.9712460063897765,
      "grad_norm": 0.3066916763782501,
      "learning_rate": 2.7987933554785018e-08,
      "loss": 0.8708,
      "step": 4650
    },
    {
      "epoch": 2.977635782747604,
      "grad_norm": 0.294672429561615,
      "learning_rate": 1.6931596246516633e-08,
      "loss": 0.8648,
      "step": 4660
    },
    {
      "epoch": 2.984025559105431,
      "grad_norm": 0.2962048649787903,
      "learning_rate": 8.63880833197328e-09,
      "loss": 0.8813,
      "step": 4670
    },
    {
      "epoch": 2.9904153354632586,
      "grad_norm": 0.2956472635269165,
      "learning_rate": 3.110028316993807e-09,
      "loss": 0.879,
      "step": 4680
    },
    {
      "epoch": 2.9968051118210863,
      "grad_norm": 0.29726117849349976,
      "learning_rate": 3.4556188622802966e-10,
      "loss": 0.8822,
      "step": 4690
    },
    {
      "epoch": 3.0,
      "step": 4695,
      "total_flos": 1.2272065452422726e+19,
      "train_loss": 0.9314867145591142,
      "train_runtime": 27369.4212,
      "train_samples_per_second": 10.977,
      "train_steps_per_second": 0.172
    }
  ],
  "logging_steps": 10,
  "max_steps": 4695,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2272065452422726e+19,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
