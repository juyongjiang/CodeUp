{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 6033,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004972650422675286,
      "grad_norm": 0.7583911418914795,
      "learning_rate": 1.6556291390728478e-06,
      "loss": 0.7334,
      "step": 10
    },
    {
      "epoch": 0.009945300845350571,
      "grad_norm": 0.49174827337265015,
      "learning_rate": 3.3112582781456956e-06,
      "loss": 0.7362,
      "step": 20
    },
    {
      "epoch": 0.014917951268025857,
      "grad_norm": 0.48186761140823364,
      "learning_rate": 4.966887417218543e-06,
      "loss": 0.7287,
      "step": 30
    },
    {
      "epoch": 0.019890601690701143,
      "grad_norm": 0.32870304584503174,
      "learning_rate": 6.622516556291391e-06,
      "loss": 0.7151,
      "step": 40
    },
    {
      "epoch": 0.02486325211337643,
      "grad_norm": 0.289953351020813,
      "learning_rate": 8.27814569536424e-06,
      "loss": 0.695,
      "step": 50
    },
    {
      "epoch": 0.029835902536051714,
      "grad_norm": 0.30615267157554626,
      "learning_rate": 9.933774834437086e-06,
      "loss": 0.6912,
      "step": 60
    },
    {
      "epoch": 0.034808552958727,
      "grad_norm": 0.2590270936489105,
      "learning_rate": 1.1589403973509934e-05,
      "loss": 0.6739,
      "step": 70
    },
    {
      "epoch": 0.039781203381402286,
      "grad_norm": 0.2809750735759735,
      "learning_rate": 1.3245033112582782e-05,
      "loss": 0.6657,
      "step": 80
    },
    {
      "epoch": 0.04475385380407757,
      "grad_norm": 0.31743913888931274,
      "learning_rate": 1.490066225165563e-05,
      "loss": 0.6732,
      "step": 90
    },
    {
      "epoch": 0.04972650422675286,
      "grad_norm": 0.30986669659614563,
      "learning_rate": 1.655629139072848e-05,
      "loss": 0.6395,
      "step": 100
    },
    {
      "epoch": 0.05469915464942814,
      "grad_norm": 0.2878625690937042,
      "learning_rate": 1.8211920529801323e-05,
      "loss": 0.6527,
      "step": 110
    },
    {
      "epoch": 0.05967180507210343,
      "grad_norm": 0.285987913608551,
      "learning_rate": 1.9867549668874173e-05,
      "loss": 0.6188,
      "step": 120
    },
    {
      "epoch": 0.06464445549477872,
      "grad_norm": 0.27595317363739014,
      "learning_rate": 2.152317880794702e-05,
      "loss": 0.6566,
      "step": 130
    },
    {
      "epoch": 0.069617105917454,
      "grad_norm": 0.3106463551521301,
      "learning_rate": 2.317880794701987e-05,
      "loss": 0.6412,
      "step": 140
    },
    {
      "epoch": 0.07458975634012929,
      "grad_norm": 0.3103938400745392,
      "learning_rate": 2.4834437086092715e-05,
      "loss": 0.6129,
      "step": 150
    },
    {
      "epoch": 0.07956240676280457,
      "grad_norm": 0.28537753224372864,
      "learning_rate": 2.6490066225165565e-05,
      "loss": 0.6535,
      "step": 160
    },
    {
      "epoch": 0.08453505718547986,
      "grad_norm": 0.2876233160495758,
      "learning_rate": 2.814569536423841e-05,
      "loss": 0.6391,
      "step": 170
    },
    {
      "epoch": 0.08950770760815514,
      "grad_norm": 0.2884317934513092,
      "learning_rate": 2.980132450331126e-05,
      "loss": 0.6005,
      "step": 180
    },
    {
      "epoch": 0.09448035803083044,
      "grad_norm": 0.39717307686805725,
      "learning_rate": 3.145695364238411e-05,
      "loss": 0.6478,
      "step": 190
    },
    {
      "epoch": 0.09945300845350571,
      "grad_norm": 0.29732242226600647,
      "learning_rate": 3.311258278145696e-05,
      "loss": 0.628,
      "step": 200
    },
    {
      "epoch": 0.10442565887618101,
      "grad_norm": 0.43414074182510376,
      "learning_rate": 3.47682119205298e-05,
      "loss": 0.6627,
      "step": 210
    },
    {
      "epoch": 0.10939830929885629,
      "grad_norm": 0.2926389276981354,
      "learning_rate": 3.6423841059602646e-05,
      "loss": 0.6528,
      "step": 220
    },
    {
      "epoch": 0.11437095972153158,
      "grad_norm": 0.30118289589881897,
      "learning_rate": 3.80794701986755e-05,
      "loss": 0.6425,
      "step": 230
    },
    {
      "epoch": 0.11934361014420686,
      "grad_norm": 0.2688448429107666,
      "learning_rate": 3.9735099337748346e-05,
      "loss": 0.614,
      "step": 240
    },
    {
      "epoch": 0.12431626056688215,
      "grad_norm": 0.28718358278274536,
      "learning_rate": 4.139072847682119e-05,
      "loss": 0.6361,
      "step": 250
    },
    {
      "epoch": 0.12928891098955744,
      "grad_norm": 0.31925398111343384,
      "learning_rate": 4.304635761589404e-05,
      "loss": 0.6335,
      "step": 260
    },
    {
      "epoch": 0.13426156141223272,
      "grad_norm": 0.2820103168487549,
      "learning_rate": 4.470198675496689e-05,
      "loss": 0.6271,
      "step": 270
    },
    {
      "epoch": 0.139234211834908,
      "grad_norm": 0.2985334098339081,
      "learning_rate": 4.635761589403974e-05,
      "loss": 0.6411,
      "step": 280
    },
    {
      "epoch": 0.14420686225758328,
      "grad_norm": 0.29363784193992615,
      "learning_rate": 4.8013245033112584e-05,
      "loss": 0.6194,
      "step": 290
    },
    {
      "epoch": 0.14917951268025859,
      "grad_norm": 0.29660433530807495,
      "learning_rate": 4.966887417218543e-05,
      "loss": 0.6403,
      "step": 300
    },
    {
      "epoch": 0.15415216310293386,
      "grad_norm": 0.2527576982975006,
      "learning_rate": 5.132450331125828e-05,
      "loss": 0.6457,
      "step": 310
    },
    {
      "epoch": 0.15912481352560914,
      "grad_norm": 0.24259009957313538,
      "learning_rate": 5.298013245033113e-05,
      "loss": 0.6185,
      "step": 320
    },
    {
      "epoch": 0.16409746394828442,
      "grad_norm": 0.24999715387821198,
      "learning_rate": 5.4635761589403976e-05,
      "loss": 0.6059,
      "step": 330
    },
    {
      "epoch": 0.16907011437095973,
      "grad_norm": 0.273794561624527,
      "learning_rate": 5.629139072847682e-05,
      "loss": 0.6402,
      "step": 340
    },
    {
      "epoch": 0.174042764793635,
      "grad_norm": 0.2555197775363922,
      "learning_rate": 5.794701986754967e-05,
      "loss": 0.6445,
      "step": 350
    },
    {
      "epoch": 0.1790154152163103,
      "grad_norm": 0.3118983805179596,
      "learning_rate": 5.960264900662252e-05,
      "loss": 0.6343,
      "step": 360
    },
    {
      "epoch": 0.1839880656389856,
      "grad_norm": 0.25641319155693054,
      "learning_rate": 6.125827814569538e-05,
      "loss": 0.593,
      "step": 370
    },
    {
      "epoch": 0.18896071606166087,
      "grad_norm": 0.2672797739505768,
      "learning_rate": 6.291390728476821e-05,
      "loss": 0.6114,
      "step": 380
    },
    {
      "epoch": 0.19393336648433615,
      "grad_norm": 0.2477806657552719,
      "learning_rate": 6.456953642384105e-05,
      "loss": 0.5966,
      "step": 390
    },
    {
      "epoch": 0.19890601690701143,
      "grad_norm": 0.2406494915485382,
      "learning_rate": 6.622516556291392e-05,
      "loss": 0.6279,
      "step": 400
    },
    {
      "epoch": 0.20387866732968674,
      "grad_norm": 0.23866286873817444,
      "learning_rate": 6.788079470198676e-05,
      "loss": 0.6216,
      "step": 410
    },
    {
      "epoch": 0.20885131775236201,
      "grad_norm": 0.2490798681974411,
      "learning_rate": 6.95364238410596e-05,
      "loss": 0.6073,
      "step": 420
    },
    {
      "epoch": 0.2138239681750373,
      "grad_norm": 0.2511085271835327,
      "learning_rate": 7.119205298013245e-05,
      "loss": 0.6152,
      "step": 430
    },
    {
      "epoch": 0.21879661859771257,
      "grad_norm": 0.2356184422969818,
      "learning_rate": 7.284768211920529e-05,
      "loss": 0.6188,
      "step": 440
    },
    {
      "epoch": 0.22376926902038788,
      "grad_norm": 0.24084462225437164,
      "learning_rate": 7.450331125827815e-05,
      "loss": 0.6241,
      "step": 450
    },
    {
      "epoch": 0.22874191944306316,
      "grad_norm": 0.22750677168369293,
      "learning_rate": 7.6158940397351e-05,
      "loss": 0.6225,
      "step": 460
    },
    {
      "epoch": 0.23371456986573844,
      "grad_norm": 0.2389407455921173,
      "learning_rate": 7.781456953642384e-05,
      "loss": 0.6263,
      "step": 470
    },
    {
      "epoch": 0.23868722028841372,
      "grad_norm": 0.24959444999694824,
      "learning_rate": 7.947019867549669e-05,
      "loss": 0.6127,
      "step": 480
    },
    {
      "epoch": 0.24365987071108902,
      "grad_norm": 0.2257971465587616,
      "learning_rate": 8.112582781456954e-05,
      "loss": 0.6076,
      "step": 490
    },
    {
      "epoch": 0.2486325211337643,
      "grad_norm": 0.2505078613758087,
      "learning_rate": 8.278145695364238e-05,
      "loss": 0.6206,
      "step": 500
    },
    {
      "epoch": 0.2486325211337643,
      "eval_loss": 0.6291035413742065,
      "eval_runtime": 291.1677,
      "eval_samples_per_second": 49.113,
      "eval_steps_per_second": 1.535,
      "step": 500
    },
    {
      "epoch": 0.2536051715564396,
      "grad_norm": 0.22412997484207153,
      "learning_rate": 8.443708609271524e-05,
      "loss": 0.6074,
      "step": 510
    },
    {
      "epoch": 0.2585778219791149,
      "grad_norm": 0.2189180552959442,
      "learning_rate": 8.609271523178808e-05,
      "loss": 0.6241,
      "step": 520
    },
    {
      "epoch": 0.26355047240179014,
      "grad_norm": 0.22456946969032288,
      "learning_rate": 8.774834437086093e-05,
      "loss": 0.5961,
      "step": 530
    },
    {
      "epoch": 0.26852312282446544,
      "grad_norm": 0.254947304725647,
      "learning_rate": 8.940397350993378e-05,
      "loss": 0.6282,
      "step": 540
    },
    {
      "epoch": 0.27349577324714075,
      "grad_norm": 0.23529976606369019,
      "learning_rate": 9.105960264900662e-05,
      "loss": 0.6008,
      "step": 550
    },
    {
      "epoch": 0.278468423669816,
      "grad_norm": 0.23568464815616608,
      "learning_rate": 9.271523178807948e-05,
      "loss": 0.6334,
      "step": 560
    },
    {
      "epoch": 0.2834410740924913,
      "grad_norm": 0.21079187095165253,
      "learning_rate": 9.437086092715233e-05,
      "loss": 0.6082,
      "step": 570
    },
    {
      "epoch": 0.28841372451516656,
      "grad_norm": 0.2181544303894043,
      "learning_rate": 9.602649006622517e-05,
      "loss": 0.6107,
      "step": 580
    },
    {
      "epoch": 0.29338637493784187,
      "grad_norm": 0.2554168105125427,
      "learning_rate": 9.768211920529802e-05,
      "loss": 0.5945,
      "step": 590
    },
    {
      "epoch": 0.29835902536051717,
      "grad_norm": 0.22729767858982086,
      "learning_rate": 9.933774834437086e-05,
      "loss": 0.6268,
      "step": 600
    },
    {
      "epoch": 0.3033316757831924,
      "grad_norm": 0.24022121727466583,
      "learning_rate": 9.999969862853087e-05,
      "loss": 0.6259,
      "step": 610
    },
    {
      "epoch": 0.30830432620586773,
      "grad_norm": 0.2240268588066101,
      "learning_rate": 9.99978569271537e-05,
      "loss": 0.61,
      "step": 620
    },
    {
      "epoch": 0.31327697662854304,
      "grad_norm": 0.2464195340871811,
      "learning_rate": 9.99943410145892e-05,
      "loss": 0.6094,
      "step": 630
    },
    {
      "epoch": 0.3182496270512183,
      "grad_norm": 0.22767336666584015,
      "learning_rate": 9.998915100856998e-05,
      "loss": 0.6229,
      "step": 640
    },
    {
      "epoch": 0.3232222774738936,
      "grad_norm": 0.25327783823013306,
      "learning_rate": 9.998228708288683e-05,
      "loss": 0.6322,
      "step": 650
    },
    {
      "epoch": 0.32819492789656884,
      "grad_norm": 0.2272561937570572,
      "learning_rate": 9.997374946738282e-05,
      "loss": 0.6283,
      "step": 660
    },
    {
      "epoch": 0.33316757831924415,
      "grad_norm": 0.2176915556192398,
      "learning_rate": 9.996353844794565e-05,
      "loss": 0.6267,
      "step": 670
    },
    {
      "epoch": 0.33814022874191946,
      "grad_norm": 0.2184370458126068,
      "learning_rate": 9.9951654366498e-05,
      "loss": 0.6283,
      "step": 680
    },
    {
      "epoch": 0.3431128791645947,
      "grad_norm": 0.21322721242904663,
      "learning_rate": 9.99380976209862e-05,
      "loss": 0.6378,
      "step": 690
    },
    {
      "epoch": 0.34808552958727,
      "grad_norm": 0.2412012219429016,
      "learning_rate": 9.992286866536678e-05,
      "loss": 0.6335,
      "step": 700
    },
    {
      "epoch": 0.3530581800099453,
      "grad_norm": 0.24098436534404755,
      "learning_rate": 9.990596800959138e-05,
      "loss": 0.6189,
      "step": 710
    },
    {
      "epoch": 0.3580308304326206,
      "grad_norm": 0.22389718890190125,
      "learning_rate": 9.988739621958956e-05,
      "loss": 0.6314,
      "step": 720
    },
    {
      "epoch": 0.3630034808552959,
      "grad_norm": 0.25766026973724365,
      "learning_rate": 9.986715391724998e-05,
      "loss": 0.6011,
      "step": 730
    },
    {
      "epoch": 0.3679761312779712,
      "grad_norm": 0.21512185037136078,
      "learning_rate": 9.984524178039948e-05,
      "loss": 0.6142,
      "step": 740
    },
    {
      "epoch": 0.37294878170064644,
      "grad_norm": 0.20717670023441315,
      "learning_rate": 9.982166054278038e-05,
      "loss": 0.5957,
      "step": 750
    },
    {
      "epoch": 0.37792143212332174,
      "grad_norm": 0.22393260896205902,
      "learning_rate": 9.979641099402597e-05,
      "loss": 0.6094,
      "step": 760
    },
    {
      "epoch": 0.382894082545997,
      "grad_norm": 0.22419770061969757,
      "learning_rate": 9.976949397963403e-05,
      "loss": 0.6431,
      "step": 770
    },
    {
      "epoch": 0.3878667329686723,
      "grad_norm": 0.20230576395988464,
      "learning_rate": 9.97409104009385e-05,
      "loss": 0.6129,
      "step": 780
    },
    {
      "epoch": 0.3928393833913476,
      "grad_norm": 0.21782585978507996,
      "learning_rate": 9.97106612150794e-05,
      "loss": 0.6255,
      "step": 790
    },
    {
      "epoch": 0.39781203381402286,
      "grad_norm": 0.25952181220054626,
      "learning_rate": 9.96787474349706e-05,
      "loss": 0.606,
      "step": 800
    },
    {
      "epoch": 0.40278468423669817,
      "grad_norm": 0.26866888999938965,
      "learning_rate": 9.964517012926609e-05,
      "loss": 0.61,
      "step": 810
    },
    {
      "epoch": 0.40775733465937347,
      "grad_norm": 0.22061662375926971,
      "learning_rate": 9.960993042232407e-05,
      "loss": 0.6084,
      "step": 820
    },
    {
      "epoch": 0.4127299850820487,
      "grad_norm": 0.21912196278572083,
      "learning_rate": 9.957302949416936e-05,
      "loss": 0.5906,
      "step": 830
    },
    {
      "epoch": 0.41770263550472403,
      "grad_norm": 0.21183998882770538,
      "learning_rate": 9.953446858045383e-05,
      "loss": 0.618,
      "step": 840
    },
    {
      "epoch": 0.4226752859273993,
      "grad_norm": 0.22619877755641937,
      "learning_rate": 9.949424897241512e-05,
      "loss": 0.6159,
      "step": 850
    },
    {
      "epoch": 0.4276479363500746,
      "grad_norm": 0.22613297402858734,
      "learning_rate": 9.945237201683328e-05,
      "loss": 0.6345,
      "step": 860
    },
    {
      "epoch": 0.4326205867727499,
      "grad_norm": 0.19940504431724548,
      "learning_rate": 9.940883911598577e-05,
      "loss": 0.5911,
      "step": 870
    },
    {
      "epoch": 0.43759323719542514,
      "grad_norm": 0.2428455948829651,
      "learning_rate": 9.93636517276005e-05,
      "loss": 0.6318,
      "step": 880
    },
    {
      "epoch": 0.44256588761810045,
      "grad_norm": 0.20904849469661713,
      "learning_rate": 9.931681136480689e-05,
      "loss": 0.6087,
      "step": 890
    },
    {
      "epoch": 0.44753853804077576,
      "grad_norm": 0.21247132122516632,
      "learning_rate": 9.926831959608541e-05,
      "loss": 0.6144,
      "step": 900
    },
    {
      "epoch": 0.452511188463451,
      "grad_norm": 0.2522631883621216,
      "learning_rate": 9.921817804521484e-05,
      "loss": 0.6108,
      "step": 910
    },
    {
      "epoch": 0.4574838388861263,
      "grad_norm": 0.24915967881679535,
      "learning_rate": 9.916638839121808e-05,
      "loss": 0.6177,
      "step": 920
    },
    {
      "epoch": 0.46245648930880157,
      "grad_norm": 0.2105652540922165,
      "learning_rate": 9.911295236830584e-05,
      "loss": 0.6218,
      "step": 930
    },
    {
      "epoch": 0.4674291397314769,
      "grad_norm": 0.20788884162902832,
      "learning_rate": 9.905787176581853e-05,
      "loss": 0.6046,
      "step": 940
    },
    {
      "epoch": 0.4724017901541522,
      "grad_norm": 0.2162894904613495,
      "learning_rate": 9.900114842816643e-05,
      "loss": 0.5922,
      "step": 950
    },
    {
      "epoch": 0.47737444057682743,
      "grad_norm": 0.23274075984954834,
      "learning_rate": 9.89427842547679e-05,
      "loss": 0.6191,
      "step": 960
    },
    {
      "epoch": 0.48234709099950274,
      "grad_norm": 0.2398393303155899,
      "learning_rate": 9.888278119998573e-05,
      "loss": 0.6077,
      "step": 970
    },
    {
      "epoch": 0.48731974142217804,
      "grad_norm": 0.19737181067466736,
      "learning_rate": 9.882114127306175e-05,
      "loss": 0.5928,
      "step": 980
    },
    {
      "epoch": 0.4922923918448533,
      "grad_norm": 0.22045399248600006,
      "learning_rate": 9.875786653804954e-05,
      "loss": 0.6312,
      "step": 990
    },
    {
      "epoch": 0.4972650422675286,
      "grad_norm": 0.23444637656211853,
      "learning_rate": 9.86929591137453e-05,
      "loss": 0.616,
      "step": 1000
    },
    {
      "epoch": 0.4972650422675286,
      "eval_loss": 0.6190850734710693,
      "eval_runtime": 290.892,
      "eval_samples_per_second": 49.159,
      "eval_steps_per_second": 1.537,
      "step": 1000
    },
    {
      "epoch": 0.5022376926902039,
      "grad_norm": 0.2219073325395584,
      "learning_rate": 9.862642117361688e-05,
      "loss": 0.624,
      "step": 1010
    },
    {
      "epoch": 0.5072103431128792,
      "grad_norm": 0.24559423327445984,
      "learning_rate": 9.855825494573113e-05,
      "loss": 0.6157,
      "step": 1020
    },
    {
      "epoch": 0.5121829935355544,
      "grad_norm": 0.2075725942850113,
      "learning_rate": 9.848846271267901e-05,
      "loss": 0.6006,
      "step": 1030
    },
    {
      "epoch": 0.5171556439582298,
      "grad_norm": 0.21707996726036072,
      "learning_rate": 9.84170468114995e-05,
      "loss": 0.5982,
      "step": 1040
    },
    {
      "epoch": 0.522128294380905,
      "grad_norm": 0.21934498846530914,
      "learning_rate": 9.83440096336011e-05,
      "loss": 0.6123,
      "step": 1050
    },
    {
      "epoch": 0.5271009448035803,
      "grad_norm": 0.25334978103637695,
      "learning_rate": 9.826935362468184e-05,
      "loss": 0.6147,
      "step": 1060
    },
    {
      "epoch": 0.5320735952262556,
      "grad_norm": 0.19450673460960388,
      "learning_rate": 9.819308128464737e-05,
      "loss": 0.6034,
      "step": 1070
    },
    {
      "epoch": 0.5370462456489309,
      "grad_norm": 0.2308066189289093,
      "learning_rate": 9.811519516752729e-05,
      "loss": 0.6152,
      "step": 1080
    },
    {
      "epoch": 0.5420188960716061,
      "grad_norm": 0.24330992996692657,
      "learning_rate": 9.803569788138951e-05,
      "loss": 0.6117,
      "step": 1090
    },
    {
      "epoch": 0.5469915464942815,
      "grad_norm": 0.22843465209007263,
      "learning_rate": 9.795459208825308e-05,
      "loss": 0.5947,
      "step": 1100
    },
    {
      "epoch": 0.5519641969169568,
      "grad_norm": 0.23037007451057434,
      "learning_rate": 9.787188050399891e-05,
      "loss": 0.5972,
      "step": 1110
    },
    {
      "epoch": 0.556936847339632,
      "grad_norm": 0.23364995419979095,
      "learning_rate": 9.778756589827894e-05,
      "loss": 0.6157,
      "step": 1120
    },
    {
      "epoch": 0.5619094977623074,
      "grad_norm": 0.22342801094055176,
      "learning_rate": 9.770165109442324e-05,
      "loss": 0.6183,
      "step": 1130
    },
    {
      "epoch": 0.5668821481849826,
      "grad_norm": 0.22439980506896973,
      "learning_rate": 9.76141389693457e-05,
      "loss": 0.5933,
      "step": 1140
    },
    {
      "epoch": 0.5718547986076579,
      "grad_norm": 0.2313728928565979,
      "learning_rate": 9.752503245344747e-05,
      "loss": 0.6119,
      "step": 1150
    },
    {
      "epoch": 0.5768274490303331,
      "grad_norm": 0.19555707275867462,
      "learning_rate": 9.743433453051896e-05,
      "loss": 0.603,
      "step": 1160
    },
    {
      "epoch": 0.5818000994530085,
      "grad_norm": 0.22092008590698242,
      "learning_rate": 9.734204823763987e-05,
      "loss": 0.6085,
      "step": 1170
    },
    {
      "epoch": 0.5867727498756837,
      "grad_norm": 0.19961491227149963,
      "learning_rate": 9.724817666507755e-05,
      "loss": 0.5974,
      "step": 1180
    },
    {
      "epoch": 0.591745400298359,
      "grad_norm": 0.20091769099235535,
      "learning_rate": 9.715272295618348e-05,
      "loss": 0.6087,
      "step": 1190
    },
    {
      "epoch": 0.5967180507210343,
      "grad_norm": 0.19466254115104675,
      "learning_rate": 9.705569030728799e-05,
      "loss": 0.6073,
      "step": 1200
    },
    {
      "epoch": 0.6016907011437096,
      "grad_norm": 0.20210666954517365,
      "learning_rate": 9.695708196759325e-05,
      "loss": 0.5944,
      "step": 1210
    },
    {
      "epoch": 0.6066633515663848,
      "grad_norm": 0.21410685777664185,
      "learning_rate": 9.685690123906455e-05,
      "loss": 0.602,
      "step": 1220
    },
    {
      "epoch": 0.6116360019890602,
      "grad_norm": 0.19816617667675018,
      "learning_rate": 9.675515147631957e-05,
      "loss": 0.5827,
      "step": 1230
    },
    {
      "epoch": 0.6166086524117355,
      "grad_norm": 0.21483127772808075,
      "learning_rate": 9.665183608651616e-05,
      "loss": 0.6026,
      "step": 1240
    },
    {
      "epoch": 0.6215813028344107,
      "grad_norm": 0.2098771184682846,
      "learning_rate": 9.654695852923825e-05,
      "loss": 0.5997,
      "step": 1250
    },
    {
      "epoch": 0.6265539532570861,
      "grad_norm": 0.22116273641586304,
      "learning_rate": 9.644052231637994e-05,
      "loss": 0.6354,
      "step": 1260
    },
    {
      "epoch": 0.6315266036797613,
      "grad_norm": 0.22216813266277313,
      "learning_rate": 9.633253101202797e-05,
      "loss": 0.621,
      "step": 1270
    },
    {
      "epoch": 0.6364992541024366,
      "grad_norm": 0.20216995477676392,
      "learning_rate": 9.622298823234235e-05,
      "loss": 0.606,
      "step": 1280
    },
    {
      "epoch": 0.6414719045251119,
      "grad_norm": 0.21417517960071564,
      "learning_rate": 9.611189764543521e-05,
      "loss": 0.5994,
      "step": 1290
    },
    {
      "epoch": 0.6464445549477872,
      "grad_norm": 0.22097311913967133,
      "learning_rate": 9.599926297124808e-05,
      "loss": 0.6037,
      "step": 1300
    },
    {
      "epoch": 0.6514172053704624,
      "grad_norm": 0.21304303407669067,
      "learning_rate": 9.588508798142726e-05,
      "loss": 0.5879,
      "step": 1310
    },
    {
      "epoch": 0.6563898557931377,
      "grad_norm": 0.19630712270736694,
      "learning_rate": 9.57693764991975e-05,
      "loss": 0.5978,
      "step": 1320
    },
    {
      "epoch": 0.661362506215813,
      "grad_norm": 0.20830506086349487,
      "learning_rate": 9.565213239923404e-05,
      "loss": 0.5918,
      "step": 1330
    },
    {
      "epoch": 0.6663351566384883,
      "grad_norm": 0.22162021696567535,
      "learning_rate": 9.553335960753285e-05,
      "loss": 0.5981,
      "step": 1340
    },
    {
      "epoch": 0.6713078070611636,
      "grad_norm": 0.21380044519901276,
      "learning_rate": 9.541306210127912e-05,
      "loss": 0.6116,
      "step": 1350
    },
    {
      "epoch": 0.6762804574838389,
      "grad_norm": 0.2118985801935196,
      "learning_rate": 9.52912439087141e-05,
      "loss": 0.6132,
      "step": 1360
    },
    {
      "epoch": 0.6812531079065142,
      "grad_norm": 0.2269270271062851,
      "learning_rate": 9.516790910900028e-05,
      "loss": 0.6202,
      "step": 1370
    },
    {
      "epoch": 0.6862257583291894,
      "grad_norm": 0.22459763288497925,
      "learning_rate": 9.504306183208469e-05,
      "loss": 0.5969,
      "step": 1380
    },
    {
      "epoch": 0.6911984087518648,
      "grad_norm": 0.20033258199691772,
      "learning_rate": 9.491670625856066e-05,
      "loss": 0.6081,
      "step": 1390
    },
    {
      "epoch": 0.69617105917454,
      "grad_norm": 0.2215948849916458,
      "learning_rate": 9.478884661952785e-05,
      "loss": 0.5974,
      "step": 1400
    },
    {
      "epoch": 0.7011437095972153,
      "grad_norm": 0.229745551943779,
      "learning_rate": 9.465948719645054e-05,
      "loss": 0.6012,
      "step": 1410
    },
    {
      "epoch": 0.7061163600198906,
      "grad_norm": 0.21851937472820282,
      "learning_rate": 9.452863232101423e-05,
      "loss": 0.6262,
      "step": 1420
    },
    {
      "epoch": 0.7110890104425659,
      "grad_norm": 0.22469304502010345,
      "learning_rate": 9.439628637498068e-05,
      "loss": 0.6053,
      "step": 1430
    },
    {
      "epoch": 0.7160616608652411,
      "grad_norm": 0.21384990215301514,
      "learning_rate": 9.426245379004111e-05,
      "loss": 0.6072,
      "step": 1440
    },
    {
      "epoch": 0.7210343112879165,
      "grad_norm": 0.2243058681488037,
      "learning_rate": 9.412713904766782e-05,
      "loss": 0.6179,
      "step": 1450
    },
    {
      "epoch": 0.7260069617105918,
      "grad_norm": 0.24073044955730438,
      "learning_rate": 9.399034667896409e-05,
      "loss": 0.615,
      "step": 1460
    },
    {
      "epoch": 0.730979612133267,
      "grad_norm": 0.24430632591247559,
      "learning_rate": 9.385208126451258e-05,
      "loss": 0.6079,
      "step": 1470
    },
    {
      "epoch": 0.7359522625559424,
      "grad_norm": 0.21280072629451752,
      "learning_rate": 9.371234743422179e-05,
      "loss": 0.6111,
      "step": 1480
    },
    {
      "epoch": 0.7409249129786176,
      "grad_norm": 0.20753875374794006,
      "learning_rate": 9.357114986717111e-05,
      "loss": 0.6033,
      "step": 1490
    },
    {
      "epoch": 0.7458975634012929,
      "grad_norm": 0.20954209566116333,
      "learning_rate": 9.342849329145414e-05,
      "loss": 0.6021,
      "step": 1500
    },
    {
      "epoch": 0.7458975634012929,
      "eval_loss": 0.6129375696182251,
      "eval_runtime": 290.9297,
      "eval_samples_per_second": 49.153,
      "eval_steps_per_second": 1.536,
      "step": 1500
    },
    {
      "epoch": 0.7508702138239681,
      "grad_norm": 0.23205570876598358,
      "learning_rate": 9.328438248402028e-05,
      "loss": 0.6107,
      "step": 1510
    },
    {
      "epoch": 0.7558428642466435,
      "grad_norm": 0.26398447155952454,
      "learning_rate": 9.313882227051493e-05,
      "loss": 0.5858,
      "step": 1520
    },
    {
      "epoch": 0.7608155146693187,
      "grad_norm": 0.20661552250385284,
      "learning_rate": 9.299181752511774e-05,
      "loss": 0.6214,
      "step": 1530
    },
    {
      "epoch": 0.765788165091994,
      "grad_norm": 0.2125537097454071,
      "learning_rate": 9.28433731703795e-05,
      "loss": 0.6071,
      "step": 1540
    },
    {
      "epoch": 0.7707608155146694,
      "grad_norm": 0.18636615574359894,
      "learning_rate": 9.269349417705724e-05,
      "loss": 0.5999,
      "step": 1550
    },
    {
      "epoch": 0.7757334659373446,
      "grad_norm": 0.21794553101062775,
      "learning_rate": 9.254218556394783e-05,
      "loss": 0.5891,
      "step": 1560
    },
    {
      "epoch": 0.7807061163600199,
      "grad_norm": 0.26061269640922546,
      "learning_rate": 9.238945239771988e-05,
      "loss": 0.5964,
      "step": 1570
    },
    {
      "epoch": 0.7856787667826952,
      "grad_norm": 0.23173846304416656,
      "learning_rate": 9.22352997927441e-05,
      "loss": 0.5994,
      "step": 1580
    },
    {
      "epoch": 0.7906514172053705,
      "grad_norm": 0.22475673258304596,
      "learning_rate": 9.20797329109221e-05,
      "loss": 0.5996,
      "step": 1590
    },
    {
      "epoch": 0.7956240676280457,
      "grad_norm": 0.19404637813568115,
      "learning_rate": 9.192275696151337e-05,
      "loss": 0.6006,
      "step": 1600
    },
    {
      "epoch": 0.8005967180507211,
      "grad_norm": 0.20103290677070618,
      "learning_rate": 9.176437720096107e-05,
      "loss": 0.5909,
      "step": 1610
    },
    {
      "epoch": 0.8055693684733963,
      "grad_norm": 0.22613002359867096,
      "learning_rate": 9.160459893271584e-05,
      "loss": 0.6155,
      "step": 1620
    },
    {
      "epoch": 0.8105420188960716,
      "grad_norm": 0.21782982349395752,
      "learning_rate": 9.144342750705828e-05,
      "loss": 0.6161,
      "step": 1630
    },
    {
      "epoch": 0.8155146693187469,
      "grad_norm": 0.24704916775226593,
      "learning_rate": 9.128086832091979e-05,
      "loss": 0.6198,
      "step": 1640
    },
    {
      "epoch": 0.8204873197414222,
      "grad_norm": 0.29415497183799744,
      "learning_rate": 9.111692681770185e-05,
      "loss": 0.5918,
      "step": 1650
    },
    {
      "epoch": 0.8254599701640974,
      "grad_norm": 0.20106226205825806,
      "learning_rate": 9.095160848709372e-05,
      "loss": 0.5977,
      "step": 1660
    },
    {
      "epoch": 0.8304326205867727,
      "grad_norm": 0.21700675785541534,
      "learning_rate": 9.078491886488864e-05,
      "loss": 0.5895,
      "step": 1670
    },
    {
      "epoch": 0.8354052710094481,
      "grad_norm": 0.22858978807926178,
      "learning_rate": 9.061686353279848e-05,
      "loss": 0.6047,
      "step": 1680
    },
    {
      "epoch": 0.8403779214321233,
      "grad_norm": 0.23277881741523743,
      "learning_rate": 9.044744811826675e-05,
      "loss": 0.5918,
      "step": 1690
    },
    {
      "epoch": 0.8453505718547986,
      "grad_norm": 0.19808639585971832,
      "learning_rate": 9.02766782942803e-05,
      "loss": 0.6007,
      "step": 1700
    },
    {
      "epoch": 0.8503232222774739,
      "grad_norm": 0.20758236944675446,
      "learning_rate": 9.010455977917916e-05,
      "loss": 0.6146,
      "step": 1710
    },
    {
      "epoch": 0.8552958727001492,
      "grad_norm": 0.2132992297410965,
      "learning_rate": 8.993109833646526e-05,
      "loss": 0.5965,
      "step": 1720
    },
    {
      "epoch": 0.8602685231228244,
      "grad_norm": 0.20149070024490356,
      "learning_rate": 8.975629977460934e-05,
      "loss": 0.5967,
      "step": 1730
    },
    {
      "epoch": 0.8652411735454998,
      "grad_norm": 0.21445557475090027,
      "learning_rate": 8.958016994685641e-05,
      "loss": 0.6041,
      "step": 1740
    },
    {
      "epoch": 0.870213823968175,
      "grad_norm": 0.251550555229187,
      "learning_rate": 8.940271475102981e-05,
      "loss": 0.6191,
      "step": 1750
    },
    {
      "epoch": 0.8751864743908503,
      "grad_norm": 0.21696244180202484,
      "learning_rate": 8.922394012933375e-05,
      "loss": 0.5933,
      "step": 1760
    },
    {
      "epoch": 0.8801591248135257,
      "grad_norm": 0.22891025245189667,
      "learning_rate": 8.904385206815421e-05,
      "loss": 0.6087,
      "step": 1770
    },
    {
      "epoch": 0.8851317752362009,
      "grad_norm": 0.21238002181053162,
      "learning_rate": 8.886245659785861e-05,
      "loss": 0.5984,
      "step": 1780
    },
    {
      "epoch": 0.8901044256588762,
      "grad_norm": 0.24479037523269653,
      "learning_rate": 8.867975979259381e-05,
      "loss": 0.6212,
      "step": 1790
    },
    {
      "epoch": 0.8950770760815515,
      "grad_norm": 0.23304800689220428,
      "learning_rate": 8.849576777008277e-05,
      "loss": 0.5879,
      "step": 1800
    },
    {
      "epoch": 0.9000497265042268,
      "grad_norm": 0.23187844455242157,
      "learning_rate": 8.831048669141955e-05,
      "loss": 0.6033,
      "step": 1810
    },
    {
      "epoch": 0.905022376926902,
      "grad_norm": 0.20673957467079163,
      "learning_rate": 8.812392276086319e-05,
      "loss": 0.6051,
      "step": 1820
    },
    {
      "epoch": 0.9099950273495774,
      "grad_norm": 0.21425023674964905,
      "learning_rate": 8.793608222562986e-05,
      "loss": 0.6068,
      "step": 1830
    },
    {
      "epoch": 0.9149676777722526,
      "grad_norm": 0.25077396631240845,
      "learning_rate": 8.774697137568363e-05,
      "loss": 0.6014,
      "step": 1840
    },
    {
      "epoch": 0.9199403281949279,
      "grad_norm": 0.20612677931785583,
      "learning_rate": 8.755659654352599e-05,
      "loss": 0.6265,
      "step": 1850
    },
    {
      "epoch": 0.9249129786176031,
      "grad_norm": 0.21735700964927673,
      "learning_rate": 8.736496410398363e-05,
      "loss": 0.5923,
      "step": 1860
    },
    {
      "epoch": 0.9298856290402785,
      "grad_norm": 0.20119525492191315,
      "learning_rate": 8.717208047399506e-05,
      "loss": 0.595,
      "step": 1870
    },
    {
      "epoch": 0.9348582794629537,
      "grad_norm": 0.21819980442523956,
      "learning_rate": 8.697795211239574e-05,
      "loss": 0.6069,
      "step": 1880
    },
    {
      "epoch": 0.939830929885629,
      "grad_norm": 0.22096049785614014,
      "learning_rate": 8.678258551970177e-05,
      "loss": 0.5977,
      "step": 1890
    },
    {
      "epoch": 0.9448035803083044,
      "grad_norm": 0.20571275055408478,
      "learning_rate": 8.65859872378923e-05,
      "loss": 0.5962,
      "step": 1900
    },
    {
      "epoch": 0.9497762307309796,
      "grad_norm": 0.20558172464370728,
      "learning_rate": 8.638816385019032e-05,
      "loss": 0.6114,
      "step": 1910
    },
    {
      "epoch": 0.9547488811536549,
      "grad_norm": 0.216663658618927,
      "learning_rate": 8.618912198084232e-05,
      "loss": 0.62,
      "step": 1920
    },
    {
      "epoch": 0.9597215315763302,
      "grad_norm": 0.20527216792106628,
      "learning_rate": 8.598886829489649e-05,
      "loss": 0.606,
      "step": 1930
    },
    {
      "epoch": 0.9646941819990055,
      "grad_norm": 0.21422672271728516,
      "learning_rate": 8.578740949797945e-05,
      "loss": 0.5911,
      "step": 1940
    },
    {
      "epoch": 0.9696668324216807,
      "grad_norm": 0.2267020344734192,
      "learning_rate": 8.558475233607179e-05,
      "loss": 0.6132,
      "step": 1950
    },
    {
      "epoch": 0.9746394828443561,
      "grad_norm": 0.21316857635974884,
      "learning_rate": 8.538090359528212e-05,
      "loss": 0.6073,
      "step": 1960
    },
    {
      "epoch": 0.9796121332670313,
      "grad_norm": 0.2212306261062622,
      "learning_rate": 8.517587010161985e-05,
      "loss": 0.6029,
      "step": 1970
    },
    {
      "epoch": 0.9845847836897066,
      "grad_norm": 0.21098019182682037,
      "learning_rate": 8.496965872076665e-05,
      "loss": 0.5724,
      "step": 1980
    },
    {
      "epoch": 0.989557434112382,
      "grad_norm": 0.24267913401126862,
      "learning_rate": 8.476227635784646e-05,
      "loss": 0.6099,
      "step": 1990
    },
    {
      "epoch": 0.9945300845350572,
      "grad_norm": 0.21618038415908813,
      "learning_rate": 8.455372995719442e-05,
      "loss": 0.587,
      "step": 2000
    },
    {
      "epoch": 0.9945300845350572,
      "eval_loss": 0.6091002225875854,
      "eval_runtime": 290.7251,
      "eval_samples_per_second": 49.187,
      "eval_steps_per_second": 1.538,
      "step": 2000
    },
    {
      "epoch": 0.9995027349577325,
      "grad_norm": 0.21183599531650543,
      "learning_rate": 8.434402650212414e-05,
      "loss": 0.5812,
      "step": 2010
    },
    {
      "epoch": 1.0044753853804078,
      "grad_norm": 0.20965440571308136,
      "learning_rate": 8.413317301469403e-05,
      "loss": 0.5627,
      "step": 2020
    },
    {
      "epoch": 1.009448035803083,
      "grad_norm": 0.2024228870868683,
      "learning_rate": 8.392117655547206e-05,
      "loss": 0.5628,
      "step": 2030
    },
    {
      "epoch": 1.0144206862257583,
      "grad_norm": 0.22066035866737366,
      "learning_rate": 8.370804422329939e-05,
      "loss": 0.5645,
      "step": 2040
    },
    {
      "epoch": 1.0193933366484336,
      "grad_norm": 0.2412123680114746,
      "learning_rate": 8.349378315505259e-05,
      "loss": 0.546,
      "step": 2050
    },
    {
      "epoch": 1.0243659870711088,
      "grad_norm": 0.2351587563753128,
      "learning_rate": 8.327840052540472e-05,
      "loss": 0.5653,
      "step": 2060
    },
    {
      "epoch": 1.0293386374937843,
      "grad_norm": 0.2386116236448288,
      "learning_rate": 8.30619035465851e-05,
      "loss": 0.5672,
      "step": 2070
    },
    {
      "epoch": 1.0343112879164595,
      "grad_norm": 0.2079990953207016,
      "learning_rate": 8.28442994681377e-05,
      "loss": 0.561,
      "step": 2080
    },
    {
      "epoch": 1.0392839383391348,
      "grad_norm": 0.20078125596046448,
      "learning_rate": 8.262559557667851e-05,
      "loss": 0.5596,
      "step": 2090
    },
    {
      "epoch": 1.04425658876181,
      "grad_norm": 0.21836769580841064,
      "learning_rate": 8.240579919565145e-05,
      "loss": 0.5743,
      "step": 2100
    },
    {
      "epoch": 1.0492292391844853,
      "grad_norm": 0.2388937920331955,
      "learning_rate": 8.218491768508321e-05,
      "loss": 0.578,
      "step": 2110
    },
    {
      "epoch": 1.0542018896071605,
      "grad_norm": 0.23128259181976318,
      "learning_rate": 8.196295844133668e-05,
      "loss": 0.5641,
      "step": 2120
    },
    {
      "epoch": 1.0591745400298358,
      "grad_norm": 0.24050340056419373,
      "learning_rate": 8.173992889686345e-05,
      "loss": 0.5581,
      "step": 2130
    },
    {
      "epoch": 1.0641471904525113,
      "grad_norm": 0.22699560225009918,
      "learning_rate": 8.151583651995478e-05,
      "loss": 0.5662,
      "step": 2140
    },
    {
      "epoch": 1.0691198408751865,
      "grad_norm": 0.24847650527954102,
      "learning_rate": 8.129068881449156e-05,
      "loss": 0.5368,
      "step": 2150
    },
    {
      "epoch": 1.0740924912978618,
      "grad_norm": 0.22494061291217804,
      "learning_rate": 8.10644933196931e-05,
      "loss": 0.5714,
      "step": 2160
    },
    {
      "epoch": 1.079065141720537,
      "grad_norm": 0.22184866666793823,
      "learning_rate": 8.083725760986462e-05,
      "loss": 0.584,
      "step": 2170
    },
    {
      "epoch": 1.0840377921432123,
      "grad_norm": 0.2469789981842041,
      "learning_rate": 8.060898929414357e-05,
      "loss": 0.559,
      "step": 2180
    },
    {
      "epoch": 1.0890104425658875,
      "grad_norm": 0.24480858445167542,
      "learning_rate": 8.037969601624495e-05,
      "loss": 0.5603,
      "step": 2190
    },
    {
      "epoch": 1.093983092988563,
      "grad_norm": 0.2243434339761734,
      "learning_rate": 8.014938545420529e-05,
      "loss": 0.5658,
      "step": 2200
    },
    {
      "epoch": 1.0989557434112383,
      "grad_norm": 0.21506214141845703,
      "learning_rate": 7.99180653201255e-05,
      "loss": 0.5619,
      "step": 2210
    },
    {
      "epoch": 1.1039283938339135,
      "grad_norm": 0.21554142236709595,
      "learning_rate": 7.968574335991274e-05,
      "loss": 0.5504,
      "step": 2220
    },
    {
      "epoch": 1.1089010442565888,
      "grad_norm": 0.23822695016860962,
      "learning_rate": 7.94524273530209e-05,
      "loss": 0.5541,
      "step": 2230
    },
    {
      "epoch": 1.113873694679264,
      "grad_norm": 0.20938441157341003,
      "learning_rate": 7.921812511219029e-05,
      "loss": 0.5603,
      "step": 2240
    },
    {
      "epoch": 1.1188463451019393,
      "grad_norm": 0.23936384916305542,
      "learning_rate": 7.89828444831858e-05,
      "loss": 0.5556,
      "step": 2250
    },
    {
      "epoch": 1.1238189955246147,
      "grad_norm": 0.2887870967388153,
      "learning_rate": 7.874659334453433e-05,
      "loss": 0.5637,
      "step": 2260
    },
    {
      "epoch": 1.12879164594729,
      "grad_norm": 0.25506293773651123,
      "learning_rate": 7.850937960726098e-05,
      "loss": 0.5523,
      "step": 2270
    },
    {
      "epoch": 1.1337642963699652,
      "grad_norm": 0.24222469329833984,
      "learning_rate": 7.827121121462405e-05,
      "loss": 0.5568,
      "step": 2280
    },
    {
      "epoch": 1.1387369467926405,
      "grad_norm": 0.23947297036647797,
      "learning_rate": 7.803209614184912e-05,
      "loss": 0.5509,
      "step": 2290
    },
    {
      "epoch": 1.1437095972153157,
      "grad_norm": 0.2301110327243805,
      "learning_rate": 7.779204239586197e-05,
      "loss": 0.5445,
      "step": 2300
    },
    {
      "epoch": 1.148682247637991,
      "grad_norm": 0.23096928000450134,
      "learning_rate": 7.755105801502048e-05,
      "loss": 0.5547,
      "step": 2310
    },
    {
      "epoch": 1.1536548980606662,
      "grad_norm": 0.22187773883342743,
      "learning_rate": 7.730915106884546e-05,
      "loss": 0.5609,
      "step": 2320
    },
    {
      "epoch": 1.1586275484833417,
      "grad_norm": 0.2456478625535965,
      "learning_rate": 7.706632965775041e-05,
      "loss": 0.5705,
      "step": 2330
    },
    {
      "epoch": 1.163600198906017,
      "grad_norm": 0.2389870136976242,
      "learning_rate": 7.68226019127703e-05,
      "loss": 0.5571,
      "step": 2340
    },
    {
      "epoch": 1.1685728493286922,
      "grad_norm": 0.23017238080501556,
      "learning_rate": 7.657797599528926e-05,
      "loss": 0.56,
      "step": 2350
    },
    {
      "epoch": 1.1735454997513675,
      "grad_norm": 0.23002561926841736,
      "learning_rate": 7.633246009676738e-05,
      "loss": 0.5489,
      "step": 2360
    },
    {
      "epoch": 1.1785181501740427,
      "grad_norm": 0.24576623737812042,
      "learning_rate": 7.608606243846629e-05,
      "loss": 0.5518,
      "step": 2370
    },
    {
      "epoch": 1.183490800596718,
      "grad_norm": 0.21873897314071655,
      "learning_rate": 7.583879127117396e-05,
      "loss": 0.5484,
      "step": 2380
    },
    {
      "epoch": 1.1884634510193934,
      "grad_norm": 0.2523665726184845,
      "learning_rate": 7.55906548749284e-05,
      "loss": 0.5627,
      "step": 2390
    },
    {
      "epoch": 1.1934361014420687,
      "grad_norm": 0.2483251690864563,
      "learning_rate": 7.534166155874033e-05,
      "loss": 0.5441,
      "step": 2400
    },
    {
      "epoch": 1.198408751864744,
      "grad_norm": 0.2323571741580963,
      "learning_rate": 7.509181966031502e-05,
      "loss": 0.5649,
      "step": 2410
    },
    {
      "epoch": 1.2033814022874192,
      "grad_norm": 0.22741131484508514,
      "learning_rate": 7.484113754577311e-05,
      "loss": 0.537,
      "step": 2420
    },
    {
      "epoch": 1.2083540527100944,
      "grad_norm": 0.26979905366897583,
      "learning_rate": 7.458962360937039e-05,
      "loss": 0.5699,
      "step": 2430
    },
    {
      "epoch": 1.2133267031327697,
      "grad_norm": 0.24933798611164093,
      "learning_rate": 7.433728627321674e-05,
      "loss": 0.5553,
      "step": 2440
    },
    {
      "epoch": 1.218299353555445,
      "grad_norm": 0.24310804903507233,
      "learning_rate": 7.408413398699419e-05,
      "loss": 0.5622,
      "step": 2450
    },
    {
      "epoch": 1.2232720039781204,
      "grad_norm": 0.23795947432518005,
      "learning_rate": 7.383017522767386e-05,
      "loss": 0.5492,
      "step": 2460
    },
    {
      "epoch": 1.2282446544007957,
      "grad_norm": 0.2175283432006836,
      "learning_rate": 7.357541849923215e-05,
      "loss": 0.5484,
      "step": 2470
    },
    {
      "epoch": 1.233217304823471,
      "grad_norm": 0.26587679982185364,
      "learning_rate": 7.331987233236599e-05,
      "loss": 0.5512,
      "step": 2480
    },
    {
      "epoch": 1.2381899552461462,
      "grad_norm": 0.22229517996311188,
      "learning_rate": 7.306354528420721e-05,
      "loss": 0.5359,
      "step": 2490
    },
    {
      "epoch": 1.2431626056688214,
      "grad_norm": 0.22920292615890503,
      "learning_rate": 7.280644593803588e-05,
      "loss": 0.558,
      "step": 2500
    },
    {
      "epoch": 1.2431626056688214,
      "eval_loss": 0.6108912229537964,
      "eval_runtime": 290.5545,
      "eval_samples_per_second": 49.216,
      "eval_steps_per_second": 1.538,
      "step": 2500
    },
    {
      "epoch": 1.248135256091497,
      "grad_norm": 0.24664302170276642,
      "learning_rate": 7.25485829029931e-05,
      "loss": 0.5626,
      "step": 2510
    },
    {
      "epoch": 1.2531079065141721,
      "grad_norm": 0.2519402503967285,
      "learning_rate": 7.228996481379248e-05,
      "loss": 0.555,
      "step": 2520
    },
    {
      "epoch": 1.2580805569368474,
      "grad_norm": 0.2954673767089844,
      "learning_rate": 7.203060033043117e-05,
      "loss": 0.5918,
      "step": 2530
    },
    {
      "epoch": 1.2630532073595226,
      "grad_norm": 0.24158021807670593,
      "learning_rate": 7.177049813789984e-05,
      "loss": 0.5642,
      "step": 2540
    },
    {
      "epoch": 1.268025857782198,
      "grad_norm": 0.2669270932674408,
      "learning_rate": 7.15096669458918e-05,
      "loss": 0.5578,
      "step": 2550
    },
    {
      "epoch": 1.2729985082048731,
      "grad_norm": 0.23877952992916107,
      "learning_rate": 7.124811548851138e-05,
      "loss": 0.5591,
      "step": 2560
    },
    {
      "epoch": 1.2779711586275484,
      "grad_norm": 0.2358911782503128,
      "learning_rate": 7.098585252398152e-05,
      "loss": 0.5505,
      "step": 2570
    },
    {
      "epoch": 1.2829438090502236,
      "grad_norm": 0.24415673315525055,
      "learning_rate": 7.072288683435037e-05,
      "loss": 0.5672,
      "step": 2580
    },
    {
      "epoch": 1.2879164594728991,
      "grad_norm": 0.2482391744852066,
      "learning_rate": 7.04592272251974e-05,
      "loss": 0.5544,
      "step": 2590
    },
    {
      "epoch": 1.2928891098955744,
      "grad_norm": 0.2703028917312622,
      "learning_rate": 7.019488252533834e-05,
      "loss": 0.5584,
      "step": 2600
    },
    {
      "epoch": 1.2978617603182496,
      "grad_norm": 0.24110549688339233,
      "learning_rate": 6.992986158652966e-05,
      "loss": 0.5759,
      "step": 2610
    },
    {
      "epoch": 1.3028344107409249,
      "grad_norm": 0.23163723945617676,
      "learning_rate": 6.966417328317216e-05,
      "loss": 0.5689,
      "step": 2620
    },
    {
      "epoch": 1.3078070611636001,
      "grad_norm": 0.238838791847229,
      "learning_rate": 6.939782651201375e-05,
      "loss": 0.531,
      "step": 2630
    },
    {
      "epoch": 1.3127797115862756,
      "grad_norm": 0.23824867606163025,
      "learning_rate": 6.913083019185161e-05,
      "loss": 0.5535,
      "step": 2640
    },
    {
      "epoch": 1.3177523620089509,
      "grad_norm": 0.24516111612319946,
      "learning_rate": 6.886319326323341e-05,
      "loss": 0.5692,
      "step": 2650
    },
    {
      "epoch": 1.322725012431626,
      "grad_norm": 0.2516665756702423,
      "learning_rate": 6.859492468815813e-05,
      "loss": 0.5791,
      "step": 2660
    },
    {
      "epoch": 1.3276976628543014,
      "grad_norm": 0.24674756824970245,
      "learning_rate": 6.832603344977577e-05,
      "loss": 0.5545,
      "step": 2670
    },
    {
      "epoch": 1.3326703132769766,
      "grad_norm": 0.23592212796211243,
      "learning_rate": 6.805652855208666e-05,
      "loss": 0.5638,
      "step": 2680
    },
    {
      "epoch": 1.3376429636996519,
      "grad_norm": 0.22818540036678314,
      "learning_rate": 6.778641901963989e-05,
      "loss": 0.5781,
      "step": 2690
    },
    {
      "epoch": 1.342615614122327,
      "grad_norm": 0.24976958334445953,
      "learning_rate": 6.751571389723113e-05,
      "loss": 0.5484,
      "step": 2700
    },
    {
      "epoch": 1.3475882645450024,
      "grad_norm": 0.23739977180957794,
      "learning_rate": 6.724442224959984e-05,
      "loss": 0.5728,
      "step": 2710
    },
    {
      "epoch": 1.3525609149676778,
      "grad_norm": 0.2569745182991028,
      "learning_rate": 6.69725531611256e-05,
      "loss": 0.5606,
      "step": 2720
    },
    {
      "epoch": 1.357533565390353,
      "grad_norm": 0.22988741099834442,
      "learning_rate": 6.6700115735524e-05,
      "loss": 0.563,
      "step": 2730
    },
    {
      "epoch": 1.3625062158130283,
      "grad_norm": 0.23002289235591888,
      "learning_rate": 6.642711909554174e-05,
      "loss": 0.5577,
      "step": 2740
    },
    {
      "epoch": 1.3674788662357036,
      "grad_norm": 0.22783805429935455,
      "learning_rate": 6.615357238265126e-05,
      "loss": 0.5636,
      "step": 2750
    },
    {
      "epoch": 1.3724515166583788,
      "grad_norm": 0.23601371049880981,
      "learning_rate": 6.587948475674447e-05,
      "loss": 0.5529,
      "step": 2760
    },
    {
      "epoch": 1.3774241670810543,
      "grad_norm": 0.24301113188266754,
      "learning_rate": 6.560486539582617e-05,
      "loss": 0.5696,
      "step": 2770
    },
    {
      "epoch": 1.3823968175037296,
      "grad_norm": 0.24743753671646118,
      "learning_rate": 6.532972349570662e-05,
      "loss": 0.5505,
      "step": 2780
    },
    {
      "epoch": 1.3873694679264048,
      "grad_norm": 0.24376130104064941,
      "learning_rate": 6.505406826969367e-05,
      "loss": 0.5604,
      "step": 2790
    },
    {
      "epoch": 1.39234211834908,
      "grad_norm": 0.24257449805736542,
      "learning_rate": 6.477790894828421e-05,
      "loss": 0.5608,
      "step": 2800
    },
    {
      "epoch": 1.3973147687717553,
      "grad_norm": 0.24709919095039368,
      "learning_rate": 6.450125477885509e-05,
      "loss": 0.5668,
      "step": 2810
    },
    {
      "epoch": 1.4022874191944306,
      "grad_norm": 0.25261300802230835,
      "learning_rate": 6.42241150253535e-05,
      "loss": 0.5683,
      "step": 2820
    },
    {
      "epoch": 1.4072600696171058,
      "grad_norm": 0.23391777276992798,
      "learning_rate": 6.394649896798675e-05,
      "loss": 0.5702,
      "step": 2830
    },
    {
      "epoch": 1.4122327200397813,
      "grad_norm": 0.24597413837909698,
      "learning_rate": 6.366841590291141e-05,
      "loss": 0.5474,
      "step": 2840
    },
    {
      "epoch": 1.4172053704624565,
      "grad_norm": 0.24919192492961884,
      "learning_rate": 6.33898751419222e-05,
      "loss": 0.5531,
      "step": 2850
    },
    {
      "epoch": 1.4221780208851318,
      "grad_norm": 0.23592513799667358,
      "learning_rate": 6.311088601214006e-05,
      "loss": 0.5587,
      "step": 2860
    },
    {
      "epoch": 1.427150671307807,
      "grad_norm": 0.2340376079082489,
      "learning_rate": 6.283145785569981e-05,
      "loss": 0.5423,
      "step": 2870
    },
    {
      "epoch": 1.4321233217304823,
      "grad_norm": 0.24644707143306732,
      "learning_rate": 6.255160002943749e-05,
      "loss": 0.5768,
      "step": 2880
    },
    {
      "epoch": 1.4370959721531578,
      "grad_norm": 0.2443927377462387,
      "learning_rate": 6.227132190457678e-05,
      "loss": 0.5674,
      "step": 2890
    },
    {
      "epoch": 1.442068622575833,
      "grad_norm": 0.21271878480911255,
      "learning_rate": 6.199063286641538e-05,
      "loss": 0.5694,
      "step": 2900
    },
    {
      "epoch": 1.4470412729985083,
      "grad_norm": 0.2531777620315552,
      "learning_rate": 6.170954231401074e-05,
      "loss": 0.564,
      "step": 2910
    },
    {
      "epoch": 1.4520139234211835,
      "grad_norm": 0.19695428013801575,
      "learning_rate": 6.142805965986523e-05,
      "loss": 0.5664,
      "step": 2920
    },
    {
      "epoch": 1.4569865738438588,
      "grad_norm": 0.25533029437065125,
      "learning_rate": 6.114619432961101e-05,
      "loss": 0.5561,
      "step": 2930
    },
    {
      "epoch": 1.461959224266534,
      "grad_norm": 0.2850520610809326,
      "learning_rate": 6.0863955761694434e-05,
      "loss": 0.5561,
      "step": 2940
    },
    {
      "epoch": 1.4669318746892093,
      "grad_norm": 0.25704580545425415,
      "learning_rate": 6.0581353407059925e-05,
      "loss": 0.5503,
      "step": 2950
    },
    {
      "epoch": 1.4719045251118845,
      "grad_norm": 0.2556648552417755,
      "learning_rate": 6.029839672883355e-05,
      "loss": 0.5544,
      "step": 2960
    },
    {
      "epoch": 1.47687717553456,
      "grad_norm": 0.272244393825531,
      "learning_rate": 6.001509520200616e-05,
      "loss": 0.5684,
      "step": 2970
    },
    {
      "epoch": 1.4818498259572352,
      "grad_norm": 0.2701459527015686,
      "learning_rate": 5.9731458313116084e-05,
      "loss": 0.5691,
      "step": 2980
    },
    {
      "epoch": 1.4868224763799105,
      "grad_norm": 0.24357424676418304,
      "learning_rate": 5.9447495559931424e-05,
      "loss": 0.5693,
      "step": 2990
    },
    {
      "epoch": 1.4917951268025857,
      "grad_norm": 0.22459776699543,
      "learning_rate": 5.916321645113213e-05,
      "loss": 0.5517,
      "step": 3000
    },
    {
      "epoch": 1.4917951268025857,
      "eval_loss": 0.6085366606712341,
      "eval_runtime": 290.1662,
      "eval_samples_per_second": 49.282,
      "eval_steps_per_second": 1.54,
      "step": 3000
    },
    {
      "epoch": 1.496767777225261,
      "grad_norm": 0.2758364975452423,
      "learning_rate": 5.8878630505991514e-05,
      "loss": 0.5486,
      "step": 3010
    },
    {
      "epoch": 1.5017404276479365,
      "grad_norm": 0.2430497109889984,
      "learning_rate": 5.859374725405744e-05,
      "loss": 0.5562,
      "step": 3020
    },
    {
      "epoch": 1.5067130780706117,
      "grad_norm": 0.2624972462654114,
      "learning_rate": 5.8308576234833366e-05,
      "loss": 0.5446,
      "step": 3030
    },
    {
      "epoch": 1.511685728493287,
      "grad_norm": 0.24374167621135712,
      "learning_rate": 5.80231269974588e-05,
      "loss": 0.5801,
      "step": 3040
    },
    {
      "epoch": 1.5166583789159622,
      "grad_norm": 0.27251240611076355,
      "learning_rate": 5.773740910038954e-05,
      "loss": 0.5572,
      "step": 3050
    },
    {
      "epoch": 1.5216310293386375,
      "grad_norm": 0.26166510581970215,
      "learning_rate": 5.745143211107766e-05,
      "loss": 0.5568,
      "step": 3060
    },
    {
      "epoch": 1.5266036797613127,
      "grad_norm": 0.2765973210334778,
      "learning_rate": 5.716520560565113e-05,
      "loss": 0.5573,
      "step": 3070
    },
    {
      "epoch": 1.531576330183988,
      "grad_norm": 0.2736246883869171,
      "learning_rate": 5.687873916859309e-05,
      "loss": 0.5552,
      "step": 3080
    },
    {
      "epoch": 1.5365489806066632,
      "grad_norm": 0.2658323645591736,
      "learning_rate": 5.659204239242095e-05,
      "loss": 0.5525,
      "step": 3090
    },
    {
      "epoch": 1.5415216310293385,
      "grad_norm": 0.29301556944847107,
      "learning_rate": 5.6305124877365214e-05,
      "loss": 0.5658,
      "step": 3100
    },
    {
      "epoch": 1.546494281452014,
      "grad_norm": 0.24130095541477203,
      "learning_rate": 5.601799623104792e-05,
      "loss": 0.5612,
      "step": 3110
    },
    {
      "epoch": 1.5514669318746892,
      "grad_norm": 0.26352399587631226,
      "learning_rate": 5.5730666068161045e-05,
      "loss": 0.5523,
      "step": 3120
    },
    {
      "epoch": 1.5564395822973645,
      "grad_norm": 0.2521215081214905,
      "learning_rate": 5.54431440101444e-05,
      "loss": 0.5609,
      "step": 3130
    },
    {
      "epoch": 1.56141223272004,
      "grad_norm": 0.23942150175571442,
      "learning_rate": 5.5155439684863594e-05,
      "loss": 0.5707,
      "step": 3140
    },
    {
      "epoch": 1.5663848831427152,
      "grad_norm": 0.2547098994255066,
      "learning_rate": 5.486756272628756e-05,
      "loss": 0.5707,
      "step": 3150
    },
    {
      "epoch": 1.5713575335653904,
      "grad_norm": 0.24905218183994293,
      "learning_rate": 5.457952277416595e-05,
      "loss": 0.5474,
      "step": 3160
    },
    {
      "epoch": 1.5763301839880657,
      "grad_norm": 0.27683648467063904,
      "learning_rate": 5.429132947370637e-05,
      "loss": 0.5661,
      "step": 3170
    },
    {
      "epoch": 1.581302834410741,
      "grad_norm": 0.22422850131988525,
      "learning_rate": 5.400299247525143e-05,
      "loss": 0.5517,
      "step": 3180
    },
    {
      "epoch": 1.5862754848334162,
      "grad_norm": 0.24668647348880768,
      "learning_rate": 5.3714521433955524e-05,
      "loss": 0.5809,
      "step": 3190
    },
    {
      "epoch": 1.5912481352560914,
      "grad_norm": 0.23844756186008453,
      "learning_rate": 5.3425926009461545e-05,
      "loss": 0.5591,
      "step": 3200
    },
    {
      "epoch": 1.5962207856787667,
      "grad_norm": 0.240762859582901,
      "learning_rate": 5.313721586557749e-05,
      "loss": 0.5618,
      "step": 3210
    },
    {
      "epoch": 1.601193436101442,
      "grad_norm": 0.24110597372055054,
      "learning_rate": 5.284840066995279e-05,
      "loss": 0.57,
      "step": 3220
    },
    {
      "epoch": 1.6061660865241174,
      "grad_norm": 0.25021421909332275,
      "learning_rate": 5.2559490093754584e-05,
      "loss": 0.5347,
      "step": 3230
    },
    {
      "epoch": 1.6111387369467927,
      "grad_norm": 0.24663046002388,
      "learning_rate": 5.22704938113439e-05,
      "loss": 0.5648,
      "step": 3240
    },
    {
      "epoch": 1.616111387369468,
      "grad_norm": 0.25270530581474304,
      "learning_rate": 5.198142149995171e-05,
      "loss": 0.5538,
      "step": 3250
    },
    {
      "epoch": 1.6210840377921432,
      "grad_norm": 0.234841451048851,
      "learning_rate": 5.1692282839354855e-05,
      "loss": 0.5633,
      "step": 3260
    },
    {
      "epoch": 1.6260566882148186,
      "grad_norm": 0.24865993857383728,
      "learning_rate": 5.140308751155193e-05,
      "loss": 0.5707,
      "step": 3270
    },
    {
      "epoch": 1.6310293386374939,
      "grad_norm": 0.2559191882610321,
      "learning_rate": 5.1113845200439046e-05,
      "loss": 0.5445,
      "step": 3280
    },
    {
      "epoch": 1.6360019890601691,
      "grad_norm": 0.23527629673480988,
      "learning_rate": 5.082456559148562e-05,
      "loss": 0.5669,
      "step": 3290
    },
    {
      "epoch": 1.6409746394828444,
      "grad_norm": 0.2490805685520172,
      "learning_rate": 5.053525837140998e-05,
      "loss": 0.5584,
      "step": 3300
    },
    {
      "epoch": 1.6459472899055196,
      "grad_norm": 0.25017374753952026,
      "learning_rate": 5.024593322785504e-05,
      "loss": 0.553,
      "step": 3310
    },
    {
      "epoch": 1.650919940328195,
      "grad_norm": 0.25310835242271423,
      "learning_rate": 4.99565998490639e-05,
      "loss": 0.5632,
      "step": 3320
    },
    {
      "epoch": 1.6558925907508701,
      "grad_norm": 0.22207145392894745,
      "learning_rate": 4.9667267923555416e-05,
      "loss": 0.5349,
      "step": 3330
    },
    {
      "epoch": 1.6608652411735454,
      "grad_norm": 0.21904906630516052,
      "learning_rate": 4.9377947139799775e-05,
      "loss": 0.5868,
      "step": 3340
    },
    {
      "epoch": 1.6658378915962206,
      "grad_norm": 0.2530174255371094,
      "learning_rate": 4.908864718589408e-05,
      "loss": 0.5543,
      "step": 3350
    },
    {
      "epoch": 1.6708105420188961,
      "grad_norm": 0.23793989419937134,
      "learning_rate": 4.879937774923795e-05,
      "loss": 0.5543,
      "step": 3360
    },
    {
      "epoch": 1.6757831924415714,
      "grad_norm": 0.26277464628219604,
      "learning_rate": 4.8510148516209084e-05,
      "loss": 0.5569,
      "step": 3370
    },
    {
      "epoch": 1.6807558428642466,
      "grad_norm": 0.25701388716697693,
      "learning_rate": 4.8220969171838956e-05,
      "loss": 0.5559,
      "step": 3380
    },
    {
      "epoch": 1.685728493286922,
      "grad_norm": 0.2797830104827881,
      "learning_rate": 4.793184939948847e-05,
      "loss": 0.5661,
      "step": 3390
    },
    {
      "epoch": 1.6907011437095973,
      "grad_norm": 0.24500441551208496,
      "learning_rate": 4.7642798880523734e-05,
      "loss": 0.5416,
      "step": 3400
    },
    {
      "epoch": 1.6956737941322726,
      "grad_norm": 0.264349102973938,
      "learning_rate": 4.735382729399184e-05,
      "loss": 0.5701,
      "step": 3410
    },
    {
      "epoch": 1.7006464445549478,
      "grad_norm": 0.23812489211559296,
      "learning_rate": 4.706494431629683e-05,
      "loss": 0.5581,
      "step": 3420
    },
    {
      "epoch": 1.705619094977623,
      "grad_norm": 0.24776776134967804,
      "learning_rate": 4.677615962087558e-05,
      "loss": 0.5546,
      "step": 3430
    },
    {
      "epoch": 1.7105917454002983,
      "grad_norm": 0.262942910194397,
      "learning_rate": 4.648748287787389e-05,
      "loss": 0.5757,
      "step": 3440
    },
    {
      "epoch": 1.7155643958229736,
      "grad_norm": 0.25829169154167175,
      "learning_rate": 4.619892375382276e-05,
      "loss": 0.5693,
      "step": 3450
    },
    {
      "epoch": 1.7205370462456488,
      "grad_norm": 0.2667950689792633,
      "learning_rate": 4.59104919113146e-05,
      "loss": 0.5534,
      "step": 3460
    },
    {
      "epoch": 1.725509696668324,
      "grad_norm": 0.23864877223968506,
      "learning_rate": 4.562219700867973e-05,
      "loss": 0.5515,
      "step": 3470
    },
    {
      "epoch": 1.7304823470909994,
      "grad_norm": 0.23190197348594666,
      "learning_rate": 4.533404869966297e-05,
      "loss": 0.5678,
      "step": 3480
    },
    {
      "epoch": 1.7354549975136748,
      "grad_norm": 0.23099973797798157,
      "learning_rate": 4.504605663310033e-05,
      "loss": 0.5467,
      "step": 3490
    },
    {
      "epoch": 1.74042764793635,
      "grad_norm": 0.24223321676254272,
      "learning_rate": 4.475823045259594e-05,
      "loss": 0.5544,
      "step": 3500
    },
    {
      "epoch": 1.74042764793635,
      "eval_loss": 0.606648325920105,
      "eval_runtime": 290.3041,
      "eval_samples_per_second": 49.259,
      "eval_steps_per_second": 1.54,
      "step": 3500
    },
    {
      "epoch": 1.7454002983590253,
      "grad_norm": 0.26115381717681885,
      "learning_rate": 4.4470579796199115e-05,
      "loss": 0.5578,
      "step": 3510
    },
    {
      "epoch": 1.7503729487817008,
      "grad_norm": 0.2359653115272522,
      "learning_rate": 4.418311429608164e-05,
      "loss": 0.5468,
      "step": 3520
    },
    {
      "epoch": 1.755345599204376,
      "grad_norm": 0.24509687721729279,
      "learning_rate": 4.389584357821525e-05,
      "loss": 0.5579,
      "step": 3530
    },
    {
      "epoch": 1.7603182496270513,
      "grad_norm": 0.21559499204158783,
      "learning_rate": 4.360877726204923e-05,
      "loss": 0.5723,
      "step": 3540
    },
    {
      "epoch": 1.7652909000497266,
      "grad_norm": 0.25145354866981506,
      "learning_rate": 4.332192496018835e-05,
      "loss": 0.5479,
      "step": 3550
    },
    {
      "epoch": 1.7702635504724018,
      "grad_norm": 0.28253409266471863,
      "learning_rate": 4.303529627807098e-05,
      "loss": 0.5626,
      "step": 3560
    },
    {
      "epoch": 1.775236200895077,
      "grad_norm": 0.22365088760852814,
      "learning_rate": 4.274890081364741e-05,
      "loss": 0.542,
      "step": 3570
    },
    {
      "epoch": 1.7802088513177523,
      "grad_norm": 0.2604009509086609,
      "learning_rate": 4.2462748157058496e-05,
      "loss": 0.5346,
      "step": 3580
    },
    {
      "epoch": 1.7851815017404276,
      "grad_norm": 0.2633488178253174,
      "learning_rate": 4.217684789031453e-05,
      "loss": 0.5718,
      "step": 3590
    },
    {
      "epoch": 1.7901541521631028,
      "grad_norm": 0.2649058997631073,
      "learning_rate": 4.189120958697435e-05,
      "loss": 0.5609,
      "step": 3600
    },
    {
      "epoch": 1.795126802585778,
      "grad_norm": 0.24600982666015625,
      "learning_rate": 4.160584281182477e-05,
      "loss": 0.5648,
      "step": 3610
    },
    {
      "epoch": 1.8000994530084535,
      "grad_norm": 0.24546316266059875,
      "learning_rate": 4.132075712056033e-05,
      "loss": 0.5601,
      "step": 3620
    },
    {
      "epoch": 1.8050721034311288,
      "grad_norm": 0.24807427823543549,
      "learning_rate": 4.103596205946323e-05,
      "loss": 0.5614,
      "step": 3630
    },
    {
      "epoch": 1.810044753853804,
      "grad_norm": 0.25078335404396057,
      "learning_rate": 4.075146716508378e-05,
      "loss": 0.5594,
      "step": 3640
    },
    {
      "epoch": 1.8150174042764795,
      "grad_norm": 0.2787635028362274,
      "learning_rate": 4.0467281963921034e-05,
      "loss": 0.5576,
      "step": 3650
    },
    {
      "epoch": 1.8199900546991548,
      "grad_norm": 0.25257471203804016,
      "learning_rate": 4.018341597210369e-05,
      "loss": 0.5577,
      "step": 3660
    },
    {
      "epoch": 1.82496270512183,
      "grad_norm": 0.24457067251205444,
      "learning_rate": 3.989987869507157e-05,
      "loss": 0.5594,
      "step": 3670
    },
    {
      "epoch": 1.8299353555445053,
      "grad_norm": 0.2541429102420807,
      "learning_rate": 3.9616679627257244e-05,
      "loss": 0.5568,
      "step": 3680
    },
    {
      "epoch": 1.8349080059671805,
      "grad_norm": 0.24213407933712006,
      "learning_rate": 3.933382825176811e-05,
      "loss": 0.5752,
      "step": 3690
    },
    {
      "epoch": 1.8398806563898558,
      "grad_norm": 0.25484228134155273,
      "learning_rate": 3.905133404006886e-05,
      "loss": 0.5619,
      "step": 3700
    },
    {
      "epoch": 1.844853306812531,
      "grad_norm": 0.24723020195960999,
      "learning_rate": 3.876920645166437e-05,
      "loss": 0.5356,
      "step": 3710
    },
    {
      "epoch": 1.8498259572352063,
      "grad_norm": 0.2637249231338501,
      "learning_rate": 3.8487454933782844e-05,
      "loss": 0.5607,
      "step": 3720
    },
    {
      "epoch": 1.8547986076578815,
      "grad_norm": 0.24486789107322693,
      "learning_rate": 3.820608892105952e-05,
      "loss": 0.5639,
      "step": 3730
    },
    {
      "epoch": 1.859771258080557,
      "grad_norm": 0.2668642997741699,
      "learning_rate": 3.7925117835220775e-05,
      "loss": 0.5623,
      "step": 3740
    },
    {
      "epoch": 1.8647439085032322,
      "grad_norm": 0.26785433292388916,
      "learning_rate": 3.7644551084768545e-05,
      "loss": 0.5518,
      "step": 3750
    },
    {
      "epoch": 1.8697165589259075,
      "grad_norm": 0.25532060861587524,
      "learning_rate": 3.736439806466536e-05,
      "loss": 0.5567,
      "step": 3760
    },
    {
      "epoch": 1.8746892093485827,
      "grad_norm": 0.2735738158226013,
      "learning_rate": 3.708466815601974e-05,
      "loss": 0.561,
      "step": 3770
    },
    {
      "epoch": 1.8796618597712582,
      "grad_norm": 0.2749525308609009,
      "learning_rate": 3.680537072577201e-05,
      "loss": 0.5453,
      "step": 3780
    },
    {
      "epoch": 1.8846345101939335,
      "grad_norm": 0.22980402410030365,
      "learning_rate": 3.652651512638068e-05,
      "loss": 0.5482,
      "step": 3790
    },
    {
      "epoch": 1.8896071606166087,
      "grad_norm": 0.25294920802116394,
      "learning_rate": 3.624811069550925e-05,
      "loss": 0.5603,
      "step": 3800
    },
    {
      "epoch": 1.894579811039284,
      "grad_norm": 0.2557538151741028,
      "learning_rate": 3.597016675571353e-05,
      "loss": 0.5377,
      "step": 3810
    },
    {
      "epoch": 1.8995524614619592,
      "grad_norm": 0.2751958966255188,
      "learning_rate": 3.569269261412956e-05,
      "loss": 0.5351,
      "step": 3820
    },
    {
      "epoch": 1.9045251118846345,
      "grad_norm": 0.2349625676870346,
      "learning_rate": 3.5415697562161787e-05,
      "loss": 0.5406,
      "step": 3830
    },
    {
      "epoch": 1.9094977623073097,
      "grad_norm": 0.26245927810668945,
      "learning_rate": 3.513919087517207e-05,
      "loss": 0.5483,
      "step": 3840
    },
    {
      "epoch": 1.914470412729985,
      "grad_norm": 0.21712175011634827,
      "learning_rate": 3.486318181216904e-05,
      "loss": 0.5451,
      "step": 3850
    },
    {
      "epoch": 1.9194430631526602,
      "grad_norm": 0.27464017271995544,
      "learning_rate": 3.4587679615498073e-05,
      "loss": 0.5645,
      "step": 3860
    },
    {
      "epoch": 1.9244157135753357,
      "grad_norm": 0.27541717886924744,
      "learning_rate": 3.4312693510531736e-05,
      "loss": 0.5674,
      "step": 3870
    },
    {
      "epoch": 1.929388363998011,
      "grad_norm": 0.267022967338562,
      "learning_rate": 3.403823270536101e-05,
      "loss": 0.5556,
      "step": 3880
    },
    {
      "epoch": 1.9343610144206862,
      "grad_norm": 0.257556289434433,
      "learning_rate": 3.3764306390486825e-05,
      "loss": 0.5465,
      "step": 3890
    },
    {
      "epoch": 1.9393336648433617,
      "grad_norm": 0.2719475030899048,
      "learning_rate": 3.3490923738512324e-05,
      "loss": 0.5688,
      "step": 3900
    },
    {
      "epoch": 1.944306315266037,
      "grad_norm": 0.23977458477020264,
      "learning_rate": 3.321809390383577e-05,
      "loss": 0.5434,
      "step": 3910
    },
    {
      "epoch": 1.9492789656887122,
      "grad_norm": 0.2312116175889969,
      "learning_rate": 3.294582602234399e-05,
      "loss": 0.5335,
      "step": 3920
    },
    {
      "epoch": 1.9542516161113874,
      "grad_norm": 0.31201478838920593,
      "learning_rate": 3.267412921110637e-05,
      "loss": 0.5882,
      "step": 3930
    },
    {
      "epoch": 1.9592242665340627,
      "grad_norm": 0.25377383828163147,
      "learning_rate": 3.2403012568069735e-05,
      "loss": 0.556,
      "step": 3940
    },
    {
      "epoch": 1.964196916956738,
      "grad_norm": 0.2291497439146042,
      "learning_rate": 3.213248517175353e-05,
      "loss": 0.5691,
      "step": 3950
    },
    {
      "epoch": 1.9691695673794132,
      "grad_norm": 0.23816226422786713,
      "learning_rate": 3.186255608094587e-05,
      "loss": 0.5405,
      "step": 3960
    },
    {
      "epoch": 1.9741422178020884,
      "grad_norm": 0.2766413688659668,
      "learning_rate": 3.159323433440026e-05,
      "loss": 0.5342,
      "step": 3970
    },
    {
      "epoch": 1.9791148682247637,
      "grad_norm": 0.2256559431552887,
      "learning_rate": 3.132452895053286e-05,
      "loss": 0.5653,
      "step": 3980
    },
    {
      "epoch": 1.984087518647439,
      "grad_norm": 0.27845320105552673,
      "learning_rate": 3.105644892712051e-05,
      "loss": 0.5403,
      "step": 3990
    },
    {
      "epoch": 1.9890601690701144,
      "grad_norm": 0.2810232937335968,
      "learning_rate": 3.078900324099948e-05,
      "loss": 0.5549,
      "step": 4000
    },
    {
      "epoch": 1.9890601690701144,
      "eval_loss": 0.6036802530288696,
      "eval_runtime": 290.5187,
      "eval_samples_per_second": 49.222,
      "eval_steps_per_second": 1.539,
      "step": 4000
    },
    {
      "epoch": 1.9940328194927897,
      "grad_norm": 0.24517907202243805,
      "learning_rate": 3.0522200847764815e-05,
      "loss": 0.5613,
      "step": 4010
    },
    {
      "epoch": 1.999005469915465,
      "grad_norm": 0.24830004572868347,
      "learning_rate": 3.0256050681470444e-05,
      "loss": 0.5624,
      "step": 4020
    },
    {
      "epoch": 2.0039781203381404,
      "grad_norm": 0.2649834454059601,
      "learning_rate": 2.9990561654330096e-05,
      "loss": 0.5212,
      "step": 4030
    },
    {
      "epoch": 2.0089507707608156,
      "grad_norm": 0.24090826511383057,
      "learning_rate": 2.972574265641879e-05,
      "loss": 0.5023,
      "step": 4040
    },
    {
      "epoch": 2.013923421183491,
      "grad_norm": 0.268297404050827,
      "learning_rate": 2.9461602555375202e-05,
      "loss": 0.5079,
      "step": 4050
    },
    {
      "epoch": 2.018896071606166,
      "grad_norm": 0.2828824818134308,
      "learning_rate": 2.919815019610467e-05,
      "loss": 0.5075,
      "step": 4060
    },
    {
      "epoch": 2.0238687220288414,
      "grad_norm": 0.2574903070926666,
      "learning_rate": 2.8935394400483067e-05,
      "loss": 0.5121,
      "step": 4070
    },
    {
      "epoch": 2.0288413724515166,
      "grad_norm": 0.24520628154277802,
      "learning_rate": 2.867334396706134e-05,
      "loss": 0.4882,
      "step": 4080
    },
    {
      "epoch": 2.033814022874192,
      "grad_norm": 0.27769720554351807,
      "learning_rate": 2.841200767077097e-05,
      "loss": 0.52,
      "step": 4090
    },
    {
      "epoch": 2.038786673296867,
      "grad_norm": 0.2538510859012604,
      "learning_rate": 2.8151394262630016e-05,
      "loss": 0.5169,
      "step": 4100
    },
    {
      "epoch": 2.0437593237195424,
      "grad_norm": 0.26773807406425476,
      "learning_rate": 2.7891512469450242e-05,
      "loss": 0.4993,
      "step": 4110
    },
    {
      "epoch": 2.0487319741422176,
      "grad_norm": 0.25544610619544983,
      "learning_rate": 2.7632370993544708e-05,
      "loss": 0.4876,
      "step": 4120
    },
    {
      "epoch": 2.053704624564893,
      "grad_norm": 0.2611348628997803,
      "learning_rate": 2.7373978512436548e-05,
      "loss": 0.4922,
      "step": 4130
    },
    {
      "epoch": 2.0586772749875686,
      "grad_norm": 0.2681955397129059,
      "learning_rate": 2.7116343678568222e-05,
      "loss": 0.5071,
      "step": 4140
    },
    {
      "epoch": 2.063649925410244,
      "grad_norm": 0.2674393951892853,
      "learning_rate": 2.685947511901198e-05,
      "loss": 0.4979,
      "step": 4150
    },
    {
      "epoch": 2.068622575832919,
      "grad_norm": 0.2647266983985901,
      "learning_rate": 2.6603381435180752e-05,
      "loss": 0.5086,
      "step": 4160
    },
    {
      "epoch": 2.0735952262555943,
      "grad_norm": 0.25701114535331726,
      "learning_rate": 2.6348071202540347e-05,
      "loss": 0.5089,
      "step": 4170
    },
    {
      "epoch": 2.0785678766782696,
      "grad_norm": 0.25491559505462646,
      "learning_rate": 2.6093552970322132e-05,
      "loss": 0.5016,
      "step": 4180
    },
    {
      "epoch": 2.083540527100945,
      "grad_norm": 0.2722747325897217,
      "learning_rate": 2.5839835261236855e-05,
      "loss": 0.4921,
      "step": 4190
    },
    {
      "epoch": 2.08851317752362,
      "grad_norm": 0.2723444700241089,
      "learning_rate": 2.5586926571189175e-05,
      "loss": 0.5086,
      "step": 4200
    },
    {
      "epoch": 2.0934858279462953,
      "grad_norm": 0.2692793607711792,
      "learning_rate": 2.533483536899328e-05,
      "loss": 0.5224,
      "step": 4210
    },
    {
      "epoch": 2.0984584783689706,
      "grad_norm": 0.27974265813827515,
      "learning_rate": 2.508357009608916e-05,
      "loss": 0.503,
      "step": 4220
    },
    {
      "epoch": 2.103431128791646,
      "grad_norm": 0.2491409033536911,
      "learning_rate": 2.4833139166260083e-05,
      "loss": 0.4818,
      "step": 4230
    },
    {
      "epoch": 2.108403779214321,
      "grad_norm": 0.2696782648563385,
      "learning_rate": 2.458355096535078e-05,
      "loss": 0.5117,
      "step": 4240
    },
    {
      "epoch": 2.1133764296369963,
      "grad_norm": 0.2405872344970703,
      "learning_rate": 2.4334813850986628e-05,
      "loss": 0.4961,
      "step": 4250
    },
    {
      "epoch": 2.1183490800596716,
      "grad_norm": 0.2633567154407501,
      "learning_rate": 2.4086936152293783e-05,
      "loss": 0.5163,
      "step": 4260
    },
    {
      "epoch": 2.1233217304823473,
      "grad_norm": 0.23266464471817017,
      "learning_rate": 2.3839926169620373e-05,
      "loss": 0.5065,
      "step": 4270
    },
    {
      "epoch": 2.1282943809050225,
      "grad_norm": 0.27688077092170715,
      "learning_rate": 2.3593792174258424e-05,
      "loss": 0.5021,
      "step": 4280
    },
    {
      "epoch": 2.133267031327698,
      "grad_norm": 0.2710873484611511,
      "learning_rate": 2.3348542408166973e-05,
      "loss": 0.508,
      "step": 4290
    },
    {
      "epoch": 2.138239681750373,
      "grad_norm": 0.2667008936405182,
      "learning_rate": 2.3104185083696085e-05,
      "loss": 0.5041,
      "step": 4300
    },
    {
      "epoch": 2.1432123321730483,
      "grad_norm": 0.27820876240730286,
      "learning_rate": 2.286072838331177e-05,
      "loss": 0.5169,
      "step": 4310
    },
    {
      "epoch": 2.1481849825957235,
      "grad_norm": 0.26015254855155945,
      "learning_rate": 2.2618180459322062e-05,
      "loss": 0.5115,
      "step": 4320
    },
    {
      "epoch": 2.153157633018399,
      "grad_norm": 0.2687617242336273,
      "learning_rate": 2.2376549433604056e-05,
      "loss": 0.5119,
      "step": 4330
    },
    {
      "epoch": 2.158130283441074,
      "grad_norm": 0.24853596091270447,
      "learning_rate": 2.2135843397331897e-05,
      "loss": 0.5207,
      "step": 4340
    },
    {
      "epoch": 2.1631029338637493,
      "grad_norm": 0.25958457589149475,
      "learning_rate": 2.1896070410705788e-05,
      "loss": 0.5029,
      "step": 4350
    },
    {
      "epoch": 2.1680755842864246,
      "grad_norm": 0.26082170009613037,
      "learning_rate": 2.1657238502682244e-05,
      "loss": 0.4989,
      "step": 4360
    },
    {
      "epoch": 2.1730482347091,
      "grad_norm": 0.27040648460388184,
      "learning_rate": 2.1419355670705066e-05,
      "loss": 0.5067,
      "step": 4370
    },
    {
      "epoch": 2.178020885131775,
      "grad_norm": 0.25709593296051025,
      "learning_rate": 2.118242988043763e-05,
      "loss": 0.5167,
      "step": 4380
    },
    {
      "epoch": 2.1829935355544503,
      "grad_norm": 0.25590214133262634,
      "learning_rate": 2.094646906549617e-05,
      "loss": 0.5105,
      "step": 4390
    },
    {
      "epoch": 2.187966185977126,
      "grad_norm": 0.2754916846752167,
      "learning_rate": 2.0711481127184095e-05,
      "loss": 0.5378,
      "step": 4400
    },
    {
      "epoch": 2.1929388363998013,
      "grad_norm": 0.30356931686401367,
      "learning_rate": 2.0477473934227337e-05,
      "loss": 0.4742,
      "step": 4410
    },
    {
      "epoch": 2.1979114868224765,
      "grad_norm": 0.2667084038257599,
      "learning_rate": 2.0244455322510996e-05,
      "loss": 0.5125,
      "step": 4420
    },
    {
      "epoch": 2.2028841372451518,
      "grad_norm": 0.2541135251522064,
      "learning_rate": 2.001243309481682e-05,
      "loss": 0.4879,
      "step": 4430
    },
    {
      "epoch": 2.207856787667827,
      "grad_norm": 0.24174368381500244,
      "learning_rate": 1.978141502056199e-05,
      "loss": 0.505,
      "step": 4440
    },
    {
      "epoch": 2.2128294380905023,
      "grad_norm": 0.25813785195350647,
      "learning_rate": 1.955140883553898e-05,
      "loss": 0.5207,
      "step": 4450
    },
    {
      "epoch": 2.2178020885131775,
      "grad_norm": 0.27867716550827026,
      "learning_rate": 1.932242224165648e-05,
      "loss": 0.507,
      "step": 4460
    },
    {
      "epoch": 2.2227747389358528,
      "grad_norm": 0.26078981161117554,
      "learning_rate": 1.909446290668146e-05,
      "loss": 0.5116,
      "step": 4470
    },
    {
      "epoch": 2.227747389358528,
      "grad_norm": 0.30479711294174194,
      "learning_rate": 1.8867538463982503e-05,
      "loss": 0.5083,
      "step": 4480
    },
    {
      "epoch": 2.2327200397812033,
      "grad_norm": 0.26661282777786255,
      "learning_rate": 1.8641656512274096e-05,
      "loss": 0.52,
      "step": 4490
    },
    {
      "epoch": 2.2376926902038785,
      "grad_norm": 0.2828208804130554,
      "learning_rate": 1.841682461536223e-05,
      "loss": 0.5117,
      "step": 4500
    },
    {
      "epoch": 2.2376926902038785,
      "eval_loss": 0.6128944158554077,
      "eval_runtime": 290.3359,
      "eval_samples_per_second": 49.253,
      "eval_steps_per_second": 1.54,
      "step": 4500
    },
    {
      "epoch": 2.2426653406265538,
      "grad_norm": 0.2881351113319397,
      "learning_rate": 1.8193050301891162e-05,
      "loss": 0.4987,
      "step": 4510
    },
    {
      "epoch": 2.2476379910492295,
      "grad_norm": 0.25107714533805847,
      "learning_rate": 1.7970341065091245e-05,
      "loss": 0.499,
      "step": 4520
    },
    {
      "epoch": 2.2526106414719047,
      "grad_norm": 0.2807937562465668,
      "learning_rate": 1.7748704362528017e-05,
      "loss": 0.5077,
      "step": 4530
    },
    {
      "epoch": 2.25758329189458,
      "grad_norm": 0.27164268493652344,
      "learning_rate": 1.752814761585254e-05,
      "loss": 0.5119,
      "step": 4540
    },
    {
      "epoch": 2.262555942317255,
      "grad_norm": 0.2747074365615845,
      "learning_rate": 1.730867821055282e-05,
      "loss": 0.4913,
      "step": 4550
    },
    {
      "epoch": 2.2675285927399305,
      "grad_norm": 0.26145997643470764,
      "learning_rate": 1.709030349570649e-05,
      "loss": 0.5149,
      "step": 4560
    },
    {
      "epoch": 2.2725012431626057,
      "grad_norm": 0.26682135462760925,
      "learning_rate": 1.687303078373481e-05,
      "loss": 0.5192,
      "step": 4570
    },
    {
      "epoch": 2.277473893585281,
      "grad_norm": 0.287547767162323,
      "learning_rate": 1.6656867350157735e-05,
      "loss": 0.5002,
      "step": 4580
    },
    {
      "epoch": 2.282446544007956,
      "grad_norm": 0.23434068262577057,
      "learning_rate": 1.644182043335026e-05,
      "loss": 0.4874,
      "step": 4590
    },
    {
      "epoch": 2.2874191944306315,
      "grad_norm": 0.2548583447933197,
      "learning_rate": 1.6227897234300128e-05,
      "loss": 0.5096,
      "step": 4600
    },
    {
      "epoch": 2.2923918448533067,
      "grad_norm": 0.27973026037216187,
      "learning_rate": 1.601510491636663e-05,
      "loss": 0.5088,
      "step": 4610
    },
    {
      "epoch": 2.297364495275982,
      "grad_norm": 0.28913092613220215,
      "learning_rate": 1.5803450605040722e-05,
      "loss": 0.4917,
      "step": 4620
    },
    {
      "epoch": 2.302337145698657,
      "grad_norm": 0.27600613236427307,
      "learning_rate": 1.559294138770656e-05,
      "loss": 0.5018,
      "step": 4630
    },
    {
      "epoch": 2.3073097961213325,
      "grad_norm": 0.25873562693595886,
      "learning_rate": 1.5383584313403982e-05,
      "loss": 0.5225,
      "step": 4640
    },
    {
      "epoch": 2.3122824465440077,
      "grad_norm": 0.3000876009464264,
      "learning_rate": 1.5175386392592567e-05,
      "loss": 0.4934,
      "step": 4650
    },
    {
      "epoch": 2.3172550969666834,
      "grad_norm": 0.2748938500881195,
      "learning_rate": 1.4968354596916928e-05,
      "loss": 0.5159,
      "step": 4660
    },
    {
      "epoch": 2.3222277473893587,
      "grad_norm": 0.3036569356918335,
      "learning_rate": 1.4762495858973152e-05,
      "loss": 0.5102,
      "step": 4670
    },
    {
      "epoch": 2.327200397812034,
      "grad_norm": 0.2908814251422882,
      "learning_rate": 1.4557817072076718e-05,
      "loss": 0.5103,
      "step": 4680
    },
    {
      "epoch": 2.332173048234709,
      "grad_norm": 0.2835443615913391,
      "learning_rate": 1.4354325090031744e-05,
      "loss": 0.5169,
      "step": 4690
    },
    {
      "epoch": 2.3371456986573844,
      "grad_norm": 0.2567477822303772,
      "learning_rate": 1.415202672690132e-05,
      "loss": 0.4994,
      "step": 4700
    },
    {
      "epoch": 2.3421183490800597,
      "grad_norm": 0.25338754057884216,
      "learning_rate": 1.3950928756779424e-05,
      "loss": 0.4999,
      "step": 4710
    },
    {
      "epoch": 2.347090999502735,
      "grad_norm": 0.2880970239639282,
      "learning_rate": 1.3751037913564147e-05,
      "loss": 0.5111,
      "step": 4720
    },
    {
      "epoch": 2.35206364992541,
      "grad_norm": 0.25493696331977844,
      "learning_rate": 1.355236089073208e-05,
      "loss": 0.5226,
      "step": 4730
    },
    {
      "epoch": 2.3570363003480854,
      "grad_norm": 0.26940587162971497,
      "learning_rate": 1.3354904341114233e-05,
      "loss": 0.497,
      "step": 4740
    },
    {
      "epoch": 2.3620089507707607,
      "grad_norm": 0.2658862769603729,
      "learning_rate": 1.315867487667335e-05,
      "loss": 0.5,
      "step": 4750
    },
    {
      "epoch": 2.366981601193436,
      "grad_norm": 0.3370078206062317,
      "learning_rate": 1.2963679068282331e-05,
      "loss": 0.4882,
      "step": 4760
    },
    {
      "epoch": 2.3719542516161116,
      "grad_norm": 0.26408374309539795,
      "learning_rate": 1.2769923445504306e-05,
      "loss": 0.512,
      "step": 4770
    },
    {
      "epoch": 2.376926902038787,
      "grad_norm": 0.2630299925804138,
      "learning_rate": 1.2577414496374019e-05,
      "loss": 0.5007,
      "step": 4780
    },
    {
      "epoch": 2.381899552461462,
      "grad_norm": 0.30724620819091797,
      "learning_rate": 1.2386158667180475e-05,
      "loss": 0.5097,
      "step": 4790
    },
    {
      "epoch": 2.3868722028841374,
      "grad_norm": 0.282086580991745,
      "learning_rate": 1.2196162362251124e-05,
      "loss": 0.5145,
      "step": 4800
    },
    {
      "epoch": 2.3918448533068126,
      "grad_norm": 0.26792073249816895,
      "learning_rate": 1.2007431943737495e-05,
      "loss": 0.5009,
      "step": 4810
    },
    {
      "epoch": 2.396817503729488,
      "grad_norm": 0.21959905326366425,
      "learning_rate": 1.1819973731402001e-05,
      "loss": 0.5012,
      "step": 4820
    },
    {
      "epoch": 2.401790154152163,
      "grad_norm": 0.30646592378616333,
      "learning_rate": 1.1633794002406396e-05,
      "loss": 0.5152,
      "step": 4830
    },
    {
      "epoch": 2.4067628045748384,
      "grad_norm": 0.2948431074619293,
      "learning_rate": 1.1448898991101631e-05,
      "loss": 0.5001,
      "step": 4840
    },
    {
      "epoch": 2.4117354549975136,
      "grad_norm": 0.2631058990955353,
      "learning_rate": 1.1265294888818984e-05,
      "loss": 0.5024,
      "step": 4850
    },
    {
      "epoch": 2.416708105420189,
      "grad_norm": 0.27911707758903503,
      "learning_rate": 1.108298784366279e-05,
      "loss": 0.5059,
      "step": 4860
    },
    {
      "epoch": 2.421680755842864,
      "grad_norm": 0.2518876791000366,
      "learning_rate": 1.0901983960304646e-05,
      "loss": 0.49,
      "step": 4870
    },
    {
      "epoch": 2.4266534062655394,
      "grad_norm": 0.2623322606086731,
      "learning_rate": 1.0722289299778843e-05,
      "loss": 0.5131,
      "step": 4880
    },
    {
      "epoch": 2.4316260566882146,
      "grad_norm": 0.25660884380340576,
      "learning_rate": 1.0543909879279485e-05,
      "loss": 0.4889,
      "step": 4890
    },
    {
      "epoch": 2.43659870711089,
      "grad_norm": 0.28744593262672424,
      "learning_rate": 1.0366851671959055e-05,
      "loss": 0.489,
      "step": 4900
    },
    {
      "epoch": 2.4415713575335656,
      "grad_norm": 0.3002946376800537,
      "learning_rate": 1.0191120606728271e-05,
      "loss": 0.5016,
      "step": 4910
    },
    {
      "epoch": 2.446544007956241,
      "grad_norm": 0.24646499752998352,
      "learning_rate": 1.0016722568057668e-05,
      "loss": 0.5033,
      "step": 4920
    },
    {
      "epoch": 2.451516658378916,
      "grad_norm": 0.2731454372406006,
      "learning_rate": 9.843663395780523e-06,
      "loss": 0.5039,
      "step": 4930
    },
    {
      "epoch": 2.4564893088015913,
      "grad_norm": 0.2734260857105255,
      "learning_rate": 9.671948884897242e-06,
      "loss": 0.514,
      "step": 4940
    },
    {
      "epoch": 2.4614619592242666,
      "grad_norm": 0.2687213718891144,
      "learning_rate": 9.501584785381368e-06,
      "loss": 0.5049,
      "step": 4950
    },
    {
      "epoch": 2.466434609646942,
      "grad_norm": 0.2699606418609619,
      "learning_rate": 9.332576801987065e-06,
      "loss": 0.4954,
      "step": 4960
    },
    {
      "epoch": 2.471407260069617,
      "grad_norm": 0.2712418735027313,
      "learning_rate": 9.164930594058014e-06,
      "loss": 0.5081,
      "step": 4970
    },
    {
      "epoch": 2.4763799104922923,
      "grad_norm": 0.2577880024909973,
      "learning_rate": 8.998651775337968e-06,
      "loss": 0.5084,
      "step": 4980
    },
    {
      "epoch": 2.4813525609149676,
      "grad_norm": 0.27888455986976624,
      "learning_rate": 8.83374591378277e-06,
      "loss": 0.5026,
      "step": 4990
    },
    {
      "epoch": 2.486325211337643,
      "grad_norm": 0.2720358371734619,
      "learning_rate": 8.670218531373852e-06,
      "loss": 0.5226,
      "step": 5000
    },
    {
      "epoch": 2.486325211337643,
      "eval_loss": 0.6127797365188599,
      "eval_runtime": 290.408,
      "eval_samples_per_second": 49.241,
      "eval_steps_per_second": 1.539,
      "step": 5000
    },
    {
      "epoch": 2.491297861760318,
      "grad_norm": 0.2707894444465637,
      "learning_rate": 8.508075103933356e-06,
      "loss": 0.4928,
      "step": 5010
    },
    {
      "epoch": 2.496270512182994,
      "grad_norm": 0.2667922377586365,
      "learning_rate": 8.347321060940832e-06,
      "loss": 0.5096,
      "step": 5020
    },
    {
      "epoch": 2.501243162605669,
      "grad_norm": 0.2509371042251587,
      "learning_rate": 8.187961785351322e-06,
      "loss": 0.5054,
      "step": 5030
    },
    {
      "epoch": 2.5062158130283443,
      "grad_norm": 0.2799440324306488,
      "learning_rate": 8.030002613415194e-06,
      "loss": 0.492,
      "step": 5040
    },
    {
      "epoch": 2.5111884634510195,
      "grad_norm": 0.28726479411125183,
      "learning_rate": 7.87344883449943e-06,
      "loss": 0.5002,
      "step": 5050
    },
    {
      "epoch": 2.516161113873695,
      "grad_norm": 0.28754839301109314,
      "learning_rate": 7.718305690910471e-06,
      "loss": 0.5117,
      "step": 5060
    },
    {
      "epoch": 2.52113376429637,
      "grad_norm": 0.25939488410949707,
      "learning_rate": 7.564578377718701e-06,
      "loss": 0.5093,
      "step": 5070
    },
    {
      "epoch": 2.5261064147190453,
      "grad_norm": 0.24405130743980408,
      "learning_rate": 7.412272042584539e-06,
      "loss": 0.4944,
      "step": 5080
    },
    {
      "epoch": 2.5310790651417205,
      "grad_norm": 0.3000432550907135,
      "learning_rate": 7.261391785585958e-06,
      "loss": 0.5154,
      "step": 5090
    },
    {
      "epoch": 2.536051715564396,
      "grad_norm": 0.2452707290649414,
      "learning_rate": 7.111942659047804e-06,
      "loss": 0.4968,
      "step": 5100
    },
    {
      "epoch": 2.541024365987071,
      "grad_norm": 0.27417802810668945,
      "learning_rate": 6.963929667372576e-06,
      "loss": 0.5101,
      "step": 5110
    },
    {
      "epoch": 2.5459970164097463,
      "grad_norm": 0.32696691155433655,
      "learning_rate": 6.817357766872823e-06,
      "loss": 0.5079,
      "step": 5120
    },
    {
      "epoch": 2.5509696668324215,
      "grad_norm": 0.25727930665016174,
      "learning_rate": 6.672231865605227e-06,
      "loss": 0.5086,
      "step": 5130
    },
    {
      "epoch": 2.555942317255097,
      "grad_norm": 0.26835447549819946,
      "learning_rate": 6.528556823206233e-06,
      "loss": 0.4972,
      "step": 5140
    },
    {
      "epoch": 2.560914967677772,
      "grad_norm": 0.23854957520961761,
      "learning_rate": 6.3863374507293075e-06,
      "loss": 0.5032,
      "step": 5150
    },
    {
      "epoch": 2.5658876181004473,
      "grad_norm": 0.2834913730621338,
      "learning_rate": 6.245578510483863e-06,
      "loss": 0.5087,
      "step": 5160
    },
    {
      "epoch": 2.5708602685231225,
      "grad_norm": 0.25269728899002075,
      "learning_rate": 6.106284715875787e-06,
      "loss": 0.5165,
      "step": 5170
    },
    {
      "epoch": 2.5758329189457982,
      "grad_norm": 0.2961980402469635,
      "learning_rate": 5.96846073124957e-06,
      "loss": 0.4915,
      "step": 5180
    },
    {
      "epoch": 2.5808055693684735,
      "grad_norm": 0.2669689357280731,
      "learning_rate": 5.832111171732157e-06,
      "loss": 0.5107,
      "step": 5190
    },
    {
      "epoch": 2.5857782197911487,
      "grad_norm": 0.27853354811668396,
      "learning_rate": 5.697240603078408e-06,
      "loss": 0.5171,
      "step": 5200
    },
    {
      "epoch": 2.590750870213824,
      "grad_norm": 0.28667497634887695,
      "learning_rate": 5.563853541518205e-06,
      "loss": 0.5138,
      "step": 5210
    },
    {
      "epoch": 2.5957235206364992,
      "grad_norm": 0.30574119091033936,
      "learning_rate": 5.431954453605181e-06,
      "loss": 0.486,
      "step": 5220
    },
    {
      "epoch": 2.6006961710591745,
      "grad_norm": 0.27965033054351807,
      "learning_rate": 5.301547756067243e-06,
      "loss": 0.5182,
      "step": 5230
    },
    {
      "epoch": 2.6056688214818498,
      "grad_norm": 0.2816709578037262,
      "learning_rate": 5.1726378156585816e-06,
      "loss": 0.4926,
      "step": 5240
    },
    {
      "epoch": 2.610641471904525,
      "grad_norm": 0.2822760045528412,
      "learning_rate": 5.045228949013492e-06,
      "loss": 0.4959,
      "step": 5250
    },
    {
      "epoch": 2.6156141223272003,
      "grad_norm": 0.29627496004104614,
      "learning_rate": 4.919325422501841e-06,
      "loss": 0.4953,
      "step": 5260
    },
    {
      "epoch": 2.620586772749876,
      "grad_norm": 0.2762458622455597,
      "learning_rate": 4.794931452086199e-06,
      "loss": 0.4895,
      "step": 5270
    },
    {
      "epoch": 2.625559423172551,
      "grad_norm": 0.2654806673526764,
      "learning_rate": 4.672051203180611e-06,
      "loss": 0.5197,
      "step": 5280
    },
    {
      "epoch": 2.6305320735952264,
      "grad_norm": 0.26943469047546387,
      "learning_rate": 4.5506887905112205e-06,
      "loss": 0.4939,
      "step": 5290
    },
    {
      "epoch": 2.6355047240179017,
      "grad_norm": 0.510022759437561,
      "learning_rate": 4.430848277978378e-06,
      "loss": 0.5253,
      "step": 5300
    },
    {
      "epoch": 2.640477374440577,
      "grad_norm": 0.26025500893592834,
      "learning_rate": 4.312533678520603e-06,
      "loss": 0.4822,
      "step": 5310
    },
    {
      "epoch": 2.645450024863252,
      "grad_norm": 0.29213595390319824,
      "learning_rate": 4.1957489539802445e-06,
      "loss": 0.5026,
      "step": 5320
    },
    {
      "epoch": 2.6504226752859275,
      "grad_norm": 0.2627408802509308,
      "learning_rate": 4.080498014970774e-06,
      "loss": 0.5258,
      "step": 5330
    },
    {
      "epoch": 2.6553953257086027,
      "grad_norm": 0.28870317339897156,
      "learning_rate": 3.966784720745809e-06,
      "loss": 0.516,
      "step": 5340
    },
    {
      "epoch": 2.660367976131278,
      "grad_norm": 0.28077831864356995,
      "learning_rate": 3.854612879069963e-06,
      "loss": 0.5226,
      "step": 5350
    },
    {
      "epoch": 2.665340626553953,
      "grad_norm": 0.2626206874847412,
      "learning_rate": 3.7439862460912635e-06,
      "loss": 0.5085,
      "step": 5360
    },
    {
      "epoch": 2.6703132769766285,
      "grad_norm": 0.27020543813705444,
      "learning_rate": 3.634908526215419e-06,
      "loss": 0.5046,
      "step": 5370
    },
    {
      "epoch": 2.6752859273993037,
      "grad_norm": 0.27951139211654663,
      "learning_rate": 3.527383371981757e-06,
      "loss": 0.5165,
      "step": 5380
    },
    {
      "epoch": 2.680258577821979,
      "grad_norm": 0.30644941329956055,
      "learning_rate": 3.4214143839409407e-06,
      "loss": 0.5,
      "step": 5390
    },
    {
      "epoch": 2.685231228244654,
      "grad_norm": 0.31135937571525574,
      "learning_rate": 3.3170051105343493e-06,
      "loss": 0.5293,
      "step": 5400
    },
    {
      "epoch": 2.6902038786673295,
      "grad_norm": 0.29328152537345886,
      "learning_rate": 3.2141590479753236e-06,
      "loss": 0.5038,
      "step": 5410
    },
    {
      "epoch": 2.6951765290900047,
      "grad_norm": 0.2890845239162445,
      "learning_rate": 3.1128796401320217e-06,
      "loss": 0.5061,
      "step": 5420
    },
    {
      "epoch": 2.7001491795126804,
      "grad_norm": 0.2702474892139435,
      "learning_rate": 3.0131702784121863e-06,
      "loss": 0.5199,
      "step": 5430
    },
    {
      "epoch": 2.7051218299353557,
      "grad_norm": 0.25457391142845154,
      "learning_rate": 2.9150343016494776e-06,
      "loss": 0.485,
      "step": 5440
    },
    {
      "epoch": 2.710094480358031,
      "grad_norm": 0.274604856967926,
      "learning_rate": 2.81847499599176e-06,
      "loss": 0.5061,
      "step": 5450
    },
    {
      "epoch": 2.715067130780706,
      "grad_norm": 0.26448941230773926,
      "learning_rate": 2.723495594791009e-06,
      "loss": 0.4848,
      "step": 5460
    },
    {
      "epoch": 2.7200397812033814,
      "grad_norm": 0.30457043647766113,
      "learning_rate": 2.630099278495074e-06,
      "loss": 0.5219,
      "step": 5470
    },
    {
      "epoch": 2.7250124316260567,
      "grad_norm": 0.27755922079086304,
      "learning_rate": 2.5382891745411365e-06,
      "loss": 0.5107,
      "step": 5480
    },
    {
      "epoch": 2.729985082048732,
      "grad_norm": 0.29889917373657227,
      "learning_rate": 2.448068357251049e-06,
      "loss": 0.5049,
      "step": 5490
    },
    {
      "epoch": 2.734957732471407,
      "grad_norm": 0.2557583749294281,
      "learning_rate": 2.359439847728323e-06,
      "loss": 0.5173,
      "step": 5500
    },
    {
      "epoch": 2.734957732471407,
      "eval_loss": 0.6118636727333069,
      "eval_runtime": 290.3091,
      "eval_samples_per_second": 49.258,
      "eval_steps_per_second": 1.54,
      "step": 5500
    },
    {
      "epoch": 2.7399303828940824,
      "grad_norm": 0.2896397113800049,
      "learning_rate": 2.272406613757011e-06,
      "loss": 0.5095,
      "step": 5510
    },
    {
      "epoch": 2.7449030333167577,
      "grad_norm": 0.3074077367782593,
      "learning_rate": 2.1869715697022954e-06,
      "loss": 0.5132,
      "step": 5520
    },
    {
      "epoch": 2.7498756837394334,
      "grad_norm": 0.2910832464694977,
      "learning_rate": 2.103137576412939e-06,
      "loss": 0.5051,
      "step": 5530
    },
    {
      "epoch": 2.7548483341621086,
      "grad_norm": 0.2594824433326721,
      "learning_rate": 2.0209074411254415e-06,
      "loss": 0.5093,
      "step": 5540
    },
    {
      "epoch": 2.759820984584784,
      "grad_norm": 0.28309738636016846,
      "learning_rate": 1.9402839173700783e-06,
      "loss": 0.5144,
      "step": 5550
    },
    {
      "epoch": 2.764793635007459,
      "grad_norm": 0.30665165185928345,
      "learning_rate": 1.861269704878682e-06,
      "loss": 0.5035,
      "step": 5560
    },
    {
      "epoch": 2.7697662854301344,
      "grad_norm": 0.3215963542461395,
      "learning_rate": 1.7838674494942198e-06,
      "loss": 0.5252,
      "step": 5570
    },
    {
      "epoch": 2.7747389358528096,
      "grad_norm": 0.27194127440452576,
      "learning_rate": 1.7080797430822083e-06,
      "loss": 0.5184,
      "step": 5580
    },
    {
      "epoch": 2.779711586275485,
      "grad_norm": 0.2923409938812256,
      "learning_rate": 1.6339091234439608e-06,
      "loss": 0.4958,
      "step": 5590
    },
    {
      "epoch": 2.78468423669816,
      "grad_norm": 0.2635901868343353,
      "learning_rate": 1.5613580742315392e-06,
      "loss": 0.4937,
      "step": 5600
    },
    {
      "epoch": 2.7896568871208354,
      "grad_norm": 0.27417492866516113,
      "learning_rate": 1.4904290248646368e-06,
      "loss": 0.5022,
      "step": 5610
    },
    {
      "epoch": 2.7946295375435106,
      "grad_norm": 0.29284828901290894,
      "learning_rate": 1.4211243504492267e-06,
      "loss": 0.5167,
      "step": 5620
    },
    {
      "epoch": 2.799602187966186,
      "grad_norm": 0.28159719705581665,
      "learning_rate": 1.3534463716979973e-06,
      "loss": 0.5062,
      "step": 5630
    },
    {
      "epoch": 2.804574838388861,
      "grad_norm": 0.3126291036605835,
      "learning_rate": 1.2873973548526542e-06,
      "loss": 0.4966,
      "step": 5640
    },
    {
      "epoch": 2.8095474888115364,
      "grad_norm": 0.26321175694465637,
      "learning_rate": 1.2229795116080634e-06,
      "loss": 0.4879,
      "step": 5650
    },
    {
      "epoch": 2.8145201392342116,
      "grad_norm": 0.24373865127563477,
      "learning_rate": 1.1601949990381555e-06,
      "loss": 0.5076,
      "step": 5660
    },
    {
      "epoch": 2.819492789656887,
      "grad_norm": 0.2743206024169922,
      "learning_rate": 1.0990459195237057e-06,
      "loss": 0.4871,
      "step": 5670
    },
    {
      "epoch": 2.8244654400795626,
      "grad_norm": 0.2800922691822052,
      "learning_rate": 1.0395343206819453e-06,
      "loss": 0.5092,
      "step": 5680
    },
    {
      "epoch": 2.829438090502238,
      "grad_norm": 0.2677896022796631,
      "learning_rate": 9.81662195297972e-07,
      "loss": 0.4958,
      "step": 5690
    },
    {
      "epoch": 2.834410740924913,
      "grad_norm": 0.34950798749923706,
      "learning_rate": 9.254314812580433e-07,
      "loss": 0.5046,
      "step": 5700
    },
    {
      "epoch": 2.8393833913475883,
      "grad_norm": 0.30497080087661743,
      "learning_rate": 8.708440614846769e-07,
      "loss": 0.5047,
      "step": 5710
    },
    {
      "epoch": 2.8443560417702636,
      "grad_norm": 0.2702748775482178,
      "learning_rate": 8.179017638735853e-07,
      "loss": 0.4921,
      "step": 5720
    },
    {
      "epoch": 2.849328692192939,
      "grad_norm": 0.2628372609615326,
      "learning_rate": 7.666063612325081e-07,
      "loss": 0.4867,
      "step": 5730
    },
    {
      "epoch": 2.854301342615614,
      "grad_norm": 0.276295006275177,
      "learning_rate": 7.16959571221798e-07,
      "loss": 0.4879,
      "step": 5740
    },
    {
      "epoch": 2.8592739930382893,
      "grad_norm": 0.2896604835987091,
      "learning_rate": 6.68963056296934e-07,
      "loss": 0.5116,
      "step": 5750
    },
    {
      "epoch": 2.8642466434609646,
      "grad_norm": 0.2765059471130371,
      "learning_rate": 6.226184236528542e-07,
      "loss": 0.4922,
      "step": 5760
    },
    {
      "epoch": 2.86921929388364,
      "grad_norm": 0.33348092436790466,
      "learning_rate": 5.779272251701218e-07,
      "loss": 0.4935,
      "step": 5770
    },
    {
      "epoch": 2.8741919443063155,
      "grad_norm": 0.2359444797039032,
      "learning_rate": 5.348909573629602e-07,
      "loss": 0.4798,
      "step": 5780
    },
    {
      "epoch": 2.879164594728991,
      "grad_norm": 0.25318992137908936,
      "learning_rate": 4.93511061329166e-07,
      "loss": 0.4942,
      "step": 5790
    },
    {
      "epoch": 2.884137245151666,
      "grad_norm": 0.28686487674713135,
      "learning_rate": 4.537889227018255e-07,
      "loss": 0.5353,
      "step": 5800
    },
    {
      "epoch": 2.8891098955743413,
      "grad_norm": 0.29630160331726074,
      "learning_rate": 4.1572587160292333e-07,
      "loss": 0.5058,
      "step": 5810
    },
    {
      "epoch": 2.8940825459970165,
      "grad_norm": 0.2563668191432953,
      "learning_rate": 3.793231825988175e-07,
      "loss": 0.5006,
      "step": 5820
    },
    {
      "epoch": 2.899055196419692,
      "grad_norm": 0.3192891776561737,
      "learning_rate": 3.4458207465753456e-07,
      "loss": 0.5075,
      "step": 5830
    },
    {
      "epoch": 2.904027846842367,
      "grad_norm": 0.28270187973976135,
      "learning_rate": 3.1150371110795776e-07,
      "loss": 0.5041,
      "step": 5840
    },
    {
      "epoch": 2.9090004972650423,
      "grad_norm": 0.3015688955783844,
      "learning_rate": 2.800891996009025e-07,
      "loss": 0.4944,
      "step": 5850
    },
    {
      "epoch": 2.9139731476877175,
      "grad_norm": 0.2848609685897827,
      "learning_rate": 2.5033959207197975e-07,
      "loss": 0.4981,
      "step": 5860
    },
    {
      "epoch": 2.918945798110393,
      "grad_norm": 0.2934485673904419,
      "learning_rate": 2.222558847064071e-07,
      "loss": 0.5107,
      "step": 5870
    },
    {
      "epoch": 2.923918448533068,
      "grad_norm": 0.26404955983161926,
      "learning_rate": 1.9583901790563574e-07,
      "loss": 0.497,
      "step": 5880
    },
    {
      "epoch": 2.9288910989557433,
      "grad_norm": 0.2511485517024994,
      "learning_rate": 1.7108987625585327e-07,
      "loss": 0.494,
      "step": 5890
    },
    {
      "epoch": 2.9338637493784185,
      "grad_norm": 0.26115891337394714,
      "learning_rate": 1.4800928849837415e-07,
      "loss": 0.5193,
      "step": 5900
    },
    {
      "epoch": 2.938836399801094,
      "grad_norm": 0.2722305953502655,
      "learning_rate": 1.265980275018952e-07,
      "loss": 0.5008,
      "step": 5910
    },
    {
      "epoch": 2.943809050223769,
      "grad_norm": 0.2825990319252014,
      "learning_rate": 1.0685681023660521e-07,
      "loss": 0.507,
      "step": 5920
    },
    {
      "epoch": 2.9487817006464443,
      "grad_norm": 0.2525772154331207,
      "learning_rate": 8.878629775015967e-08,
      "loss": 0.5112,
      "step": 5930
    },
    {
      "epoch": 2.95375435106912,
      "grad_norm": 0.27039292454719543,
      "learning_rate": 7.238709514559295e-08,
      "loss": 0.4894,
      "step": 5940
    },
    {
      "epoch": 2.9587270014917952,
      "grad_norm": 0.2820655405521393,
      "learning_rate": 5.7659751561001116e-08,
      "loss": 0.5185,
      "step": 5950
    },
    {
      "epoch": 2.9636996519144705,
      "grad_norm": 0.265997976064682,
      "learning_rate": 4.4604760151190085e-08,
      "loss": 0.5167,
      "step": 5960
    },
    {
      "epoch": 2.9686723023371457,
      "grad_norm": 0.28047633171081543,
      "learning_rate": 3.3222558071149825e-08,
      "loss": 0.5213,
      "step": 5970
    },
    {
      "epoch": 2.973644952759821,
      "grad_norm": 0.2600928544998169,
      "learning_rate": 2.351352646142724e-08,
      "loss": 0.4889,
      "step": 5980
    },
    {
      "epoch": 2.9786176031824962,
      "grad_norm": 0.26833850145339966,
      "learning_rate": 1.5477990435330824e-08,
      "loss": 0.4969,
      "step": 5990
    },
    {
      "epoch": 2.9835902536051715,
      "grad_norm": 0.26568254828453064,
      "learning_rate": 9.11621906808935e-09,
      "loss": 0.4824,
      "step": 6000
    },
    {
      "epoch": 2.9835902536051715,
      "eval_loss": 0.6121407151222229,
      "eval_runtime": 290.5854,
      "eval_samples_per_second": 49.211,
      "eval_steps_per_second": 1.538,
      "step": 6000
    },
    {
      "epoch": 2.9885629040278467,
      "grad_norm": 0.29089468717575073,
      "learning_rate": 4.428425387803525e-09,
      "loss": 0.4836,
      "step": 6010
    },
    {
      "epoch": 2.993535554450522,
      "grad_norm": 0.2831985354423523,
      "learning_rate": 1.414766368340592e-09,
      "loss": 0.5051,
      "step": 6020
    },
    {
      "epoch": 2.9985082048731977,
      "grad_norm": 0.2833578288555145,
      "learning_rate": 7.534292404964838e-11,
      "loss": 0.5045,
      "step": 6030
    },
    {
      "epoch": 3.0,
      "step": 6033,
      "total_flos": 1.4514634740901872e+19,
      "train_loss": 0.5599146615642824,
      "train_runtime": 28077.0688,
      "train_samples_per_second": 13.751,
      "train_steps_per_second": 0.215
    }
  ],
  "logging_steps": 10,
  "max_steps": 6033,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4514634740901872e+19,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
